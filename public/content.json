{"meta":{"title":"喵","subtitle":null,"description":null,"author":"Neo~喵","url":"http://www.huarenlab.com"},"pages":[{"title":"分类","date":"2018-05-05T05:21:17.000Z","updated":"2019-04-13T01:52:14.040Z","comments":true,"path":"categories/index.html","permalink":"http://www.huarenlab.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-05-05T09:27:09.000Z","updated":"2019-04-13T01:52:14.044Z","comments":true,"path":"tags/index.html","permalink":"http://www.huarenlab.com/tags/index.html","excerpt":"","text":""},{"title":"导航","date":"2018-09-14T11:21:17.000Z","updated":"2019-11-07T08:11:51.577Z","comments":true,"path":"navi/index.html","permalink":"http://www.huarenlab.com/navi/index.html","excerpt":"","text":"学术%%% 学术论文搜索hiqq:集合百度、谷歌、CNKI、SCI 专著下载Library Genesis:英文版，收录全 全能论文下载SCI-HUB:且用且珍惜 百度学术保持学习态度 专利检索需要登录，可下载全文 算法竞赛kaggle:最大的竞赛平台，奖金丰厚 生理数据数据库physionet:ECG信号下载 公开课教学coursera:快来学习，充实自己 优达学城udacity:硅谷前沿技术学习平台 b站视频资源neophack:过气up主 b站视频资源李沐:MXNET视频教程 b站视频资源宫帅USTC:很多最新深度学习分享 b站视频资源秋兰作佩:视频图像处理教学 莫凡python偏向于实践手把手教学 华东师范公开课陆吾生最优化和稀疏感知课程 小木虫学术交流 /%%% 技术%%% 慕课网程序员充电，包含深度学习 W3C学院w3cschool:例子丰富 Gayhubgithub:最大的开源社区 联合开发网上传一份代码有30次下载机会 CSDN博客CSDN:博客,咕咕咕 /%%% 资源%%% 网盘搜索盘多多:不是盘夕夕 网盘搜索特百度:和多多一起辅助找资料 手写latexmyscript:手写公式转latex 预训练模型百度云:keras模型（密码：3gs8） 吴恩达机器学习百度云:视频+讲义（密码：q46u） IDA7.0百度云:静态分析神器（密码：i5qf） 图书代码下载清华大学出版社:很多书有资源下载 cpu参数INTEL:详细参数和选型 微软订阅ITellYou:office、windows、vs2019 Linux软件包pkgs:安装低版本软件，下载方便 pipy软件包lfd.uci:numpy-mkl等python软件包 传图识色能识别图片的主要颜色值 坐标拾取支持谷歌、百度、腾讯/高德、图吧 wolfram统一符号语言读取的大量内置算法和知识 /%%% 我是购物狂%%% 百面机器学习京东:百面机器学习 教你设计CPU京东:RISC-V是当前比较火的架构 荔枝糖能跑RISC-V的FPGA的开发板 荔枝丹能跑yolo的risc-v的开发板，堪智K210 /%%%"}],"posts":[{"title":"深度学习环境镜像","slug":"neo-ai-lab","date":"2019-11-27T14:13:11.000Z","updated":"2019-11-28T02:00:47.111Z","comments":true,"path":"2019/11/27/neo-ai-lab/","link":"","permalink":"http://www.huarenlab.com/2019/11/27/neo-ai-lab/","excerpt":"随着深度学习新技术的出现，cuda版本越来越高，升级导致之前编译过的程序不可用。本文介绍个人修改的docker，基于nvidia的tensorrt镜像cuda10.1版本，添加opencv+contrib3.4.8，添加常用机器学习框架，添加simpledet版的mxnet等。","text":"随着深度学习新技术的出现，cuda版本越来越高，升级导致之前编译过的程序不可用。本文介绍个人修改的docker，基于nvidia的tensorrt镜像cuda10.1版本，添加opencv+contrib3.4.8，添加常用机器学习框架，添加simpledet版的mxnet等。 介绍理想的深度学习开发和导出工具，这个项目是为了创建一个新的开发环境，使用docker开发数据科学中的人工智能模型，特别是计算机视觉。 pull镜像镜像地址https://hub.docker.com/r/neoneone/neo-ai 使用docker123docker pull neoneone/neo-ai# mirrordocker pull registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai 使用singularity123singularity pull docker://neoneone/neo-ai# mirrorsingularity pull docker://registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai 运行dockerdocker运行 123456# 运行镜像docker run -it --rm --runtime=nvidia -v $(pwd):/workspace -w /workspace -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$DISPLAY -p 8888:8888 -p 6006:6006 registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai:latest# 查看运行的容器docker ps -a# shell访问容器docker exec -it a1d1dd53a7ba /bin/bash singularity运行1singularity shell --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg 测试程序yolo代码地址https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/restructure/yolo 在yolo/apps/trt-yolo目录下的CMakeLists.txt的36行修改cuda版本1find_package(CUDA 10.1 EXACT REQUIRED cudart cublas curand) 在data/test_images.txt修改测试图片路径 执行prebuild.sh安装依赖和下载模型 yolo目录下执行123456$ cd apps/trt-yolo$ mkdir build &amp;&amp; cd build$ cmake -D CMAKE_BUILD_TYPE=Release .. $ make &amp;&amp; cp trt-yolo-app ../../..$ cd ../../../$ trt-yolo-app --flagfile=config/yolov3-tiny.txt 测试输出123456789Building complete!Serializing the TensorRT Engine...Serialized plan file cached at location : data/yolov3-kFLOAT-kGPU-batch4.engineLoading TRT Engine...UNKNOWN: Deserialize required 1818080 microseconds.Loading Complete!Total number of images used for inference : 6[======================================================================] 100 %Network Type : yolov3 Precision : kFLOAT Batch Size : 4 Inference time per image : 75.239 ms 备份恢复docker镜像查看本地镜像1docker images 备份 1docker save -o ~/container-backup.tar container-backup 恢复1docker load -i ~/container-backup.tar","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.huarenlab.com/categories/深度学习/"}],"tags":[{"name":"镜像","slug":"镜像","permalink":"http://www.huarenlab.com/tags/镜像/"},{"name":"docker","slug":"docker","permalink":"http://www.huarenlab.com/tags/docker/"}]},{"title":"一种便携式容器","slug":"singularity-base","date":"2019-11-23T12:53:11.000Z","updated":"2019-11-28T01:47:31.383Z","comments":true,"path":"2019/11/23/singularity-base/","link":"","permalink":"http://www.huarenlab.com/2019/11/23/singularity-base/","excerpt":"内网环境安装docker和nvidia docker繁琐，本文介绍一种便携式容器singularity，安装简便（主要是2版本），仓库就可以直接安装。本文并介绍如何将docker镜像转换到singularity部署。","text":"内网环境安装docker和nvidia docker繁琐，本文介绍一种便携式容器singularity，安装简便（主要是2版本），仓库就可以直接安装。本文并介绍如何将docker镜像转换到singularity部署。 基本使用123456789101112131415161718192021222324252627282930313233343536373839USAGE: singularity [global options...] &lt;command&gt; [command options...] ...GLOBAL OPTIONS: -d|--debug 打印调试信息 -h|--help 显示使用帮助 -s|--silent 仅打印错误 -q|--quiet 关闭输出信息 --version 显示应用版本 -v|--verbose 啰嗦模式 -x|--sh-debug 打印shell调试信息GENERAL COMMANDS: help Show additional help for a command or container selftest Run some self tests for singularity install CONTAINER USAGE COMMANDS: exec 执行容器中的命令 run 运行容器中预设命令 shell 在容器中运行shell test 运行容器中test脚本 CONTAINER MANAGEMENT COMMANDS: apps List available apps within a container bootstrap *Deprecated* use build instead build Build a new Singularity container check Perform container lint checks inspect Display container&apos;s metadata pull Pull a Singularity/Docker container to $PWD COMMAND GROUPS: image Container image command group instance Persistent instance command group CONTAINER USAGE OPTIONS: see singularity help &lt;command&gt;For any additional help or support visit the Singularitywebsite: http://singularity.lbl.gov/ 转换docker镜像到singularity转换支持本地docker镜像，查看本地镜像列表通过docker images命令，其中quay.io/singularity/docker2singularity版本根据实际使用版本修改12345678910111213mkdir /tmp/test# convert ubuntu:14.04docker run -v /var/run/docker.sock:/var/run/docker.sock \\-v /tmp/test:/output \\--privileged -t --rm \\quay.io/singularity/docker2singularity:v2.4 \\ubuntu:14.04# convert neo-aidocker run -v /var/run/docker.sock:/var/run/docker.sock \\-v /tmp/test:/output \\--privileged -t --rm \\quay.io/singularity/docker2singularity:v2.4 \\registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai singularity运行镜像内jupyter程序1LANGUAGE=en sudo singularity run --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.huarenlab.com/categories/深度学习/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://www.huarenlab.com/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://www.huarenlab.com/tags/容器/"},{"name":"singularity","slug":"singularity","permalink":"http://www.huarenlab.com/tags/singularity/"}]},{"title":"图像视频标注工具","slug":"vott-neon","date":"2019-11-06T12:23:11.000Z","updated":"2019-11-07T07:59:27.801Z","comments":true,"path":"2019/11/06/vott-neon/","link":"","permalink":"http://www.huarenlab.com/2019/11/06/vott-neon/","excerpt":"网上开源的标注工具很多，但总是缺少很多功能。在生成中造成极大的困惑，本贴提供可标注矩形、点、线、多边形等的标注工具，具有缩放平移等功能。","text":"网上开源的标注工具很多，但总是缺少很多功能。在生成中造成极大的困惑，本贴提供可标注矩形、点、线、多边形等的标注工具，具有缩放平移等功能。 vott是微软旗下的标注工具，众所周知，微软大刀总会砍向好的项目，在步入2.0版本时候，开了倒车，没有增加图像缩放功能，还把多边形标注功能砍了。 我在1.7.2版本上添加了图像缩放功能，增加了多组标签功能，增加标签编辑和搜索功能。 1.7.2.2版本更新日志 12345678910添加标签编辑窗口，按E键编辑，按tab键切换标签按alt键可以使选中框外的其他框锁定修正图像缩放功能，能够标注一些小目标添加画人车3D功能，可调整大小修正鼠标停在目标区域导致下一张不能创建标注的问题点下一张图会自动保存，当前图s或者ctl+s保存多段线功能将原矩形拖动改为线条拖动，多边形将原矩形拖动改为多边形内部将原有的着色改为：1.默认为线条加0.5透明的边沿；2.鼠标悬停为0.8透明矩形；3.线条选中仅显示多段线多标签问题：由于Pascal导出只能使用一个类别，为了更加直观，以标注颜色为统一，选对应颜色的那个类别，为靠前的类别还存在的bug: Ctrl点击锚点会删除该点，要移动任意一点才能保存 在线演示github 下载链接Windows版本","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.huarenlab.com/categories/深度学习/"}],"tags":[{"name":"标注","slug":"标注","permalink":"http://www.huarenlab.com/tags/标注/"}]},{"title":"Ubuntu18.04LTS+cuda9.0+caffe(old repo老版本)安装踩坑","slug":"caffe-cuda9-ubuntu1804","date":"2018-10-30T12:15:51.000Z","updated":"2019-04-13T01:52:14.044Z","comments":true,"path":"2018/10/30/caffe-cuda9-ubuntu1804/","link":"","permalink":"http://www.huarenlab.com/2018/10/30/caffe-cuda9-ubuntu1804/","excerpt":"在Ubuntu上安装cuda9.0，并配置caffe环境，caffe为2016年的版本，由于改动太多，移植到新版麻烦，这里就安装教程和遇到问题做一些记录","text":"在Ubuntu上安装cuda9.0，并配置caffe环境，caffe为2016年的版本，由于改动太多，移植到新版麻烦，这里就安装教程和遇到问题做一些记录 1.常用编译需要的软件首先安装必要软件1sudo apt install make cmake 编译GPU版需要安装驱动123456chmod 777 NVIDIA-Linux-x86_64-410.73.runsudo ./NVIDIA-Linux-x86_64-410.73.run --no-opengl-files# --no-opengl-files适合笔记本用户安装，可以防止桌面分辨率异常，台式机可以不加chmod 777 cuda_9.0.176_384.81_linux.runsudo ./cuda_9.0.176_384.81_linux.run# cuda安装时候提示安装驱动，选n 2.安装caffe需要的库1234sudo apt install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compilersudo apt install --no-install-recommends libboost-all-devsudo apt install libatlas-base-devsudo apt install libgflags-dev libgoogle-glog-dev liblmdb-dev 3.根据自己配置修改Makefile.config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA_ARCH 中的20和21两行4.编译1make all 注意1 如果报错如下，protobuf版本不一致.build_release/src/caffe/proto/caffe.pb.h:17:2: error: #error This file was generated by an older version of protoc which is 默认protobuf为3.0版本，旧版2.5版本安装如下1234wget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf8_2.5.0-9ubuntu1_amd64.debwget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.debwget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-dev_2.5.0-9ubuntu1_amd64.debsudo dpkg -i libprotobuf8_2.5.0-9ubuntu1_amd64.deb libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb libprotobuf-dev_2.5.0-9ubuntu1_amd64.deb 更多库下载 https://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html 2 如果报错如下，为g++版本不兼容src/caffe/layers/contrastive_loss_layer.cpp:56:30: error: no matching function for call to ‘max(float, double)’ Dtype dist = std::max(margin - sqrt(dist_sq_.cpu_data()[i]), 0.0); 通过安装低版本gcc g++解决1234sudo apt install gcc-4.8 g++-4.8cd /usr/binsudo ln -s gcc-4.8 gccsudo ln -s g++-4.8 g++ 3 如果报错如下，anaconda库冲突CXX/LD -o .build_release/tools/upgrade_net_proto_text.bin .build_release/tools/upgrade_net_proto_text.o: In function `main&apos;: /usr/include/c++/5/bits/basic_string.tcc:219: undefined reference to `std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_create(unsigned long&amp;, unsigned long)&apos; /usr/lib/gcc/x86_64-linux-gnu/5/../../../x86_64-linux-gnu/libglog.so: undefined reference to `vtable for std::__cxx11::basic_stringbuf&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;@GLIBCXX_3.4.21&apos; 在makefile.config修改include路径lib路径等，编译pycaffe时再添加Python的include路径lib路径12345# Whatever else you find you need goes here.#INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include $(CUDNN_PATH)#LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib $(CUDNN_PATH)INCLUDE_DIRS := /usr/local/include /usr/include/hdf5/serial /usr/include/python2.7 $(CUDNN_PATH)LIBRARY_DIRS := /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial $(CUDNN_PATH) 4 cublas报错F1030 16:15:43.990840 1937 math_functions.cu:28] Check failed: status == CUBLAS_STATUS_SUCCESS (13 vs. 0) CUBLAS_STATUS_EXECUTION_FAILED 安装CUDA9.0会出现以上错误 通过安装补丁Patch 2 (Released Mar 5, 2018)解决 训练模型 caffe-train GPU 声明：如有错误或者侵权请邮箱联系我","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.huarenlab.com/categories/深度学习/"}],"tags":[{"name":"caffe配置","slug":"caffe配置","permalink":"http://www.huarenlab.com/tags/caffe配置/"}]},{"title":"yolo训练经验","slug":"yolo-train","date":"2018-09-17T11:25:51.000Z","updated":"2019-04-13T01:52:14.044Z","comments":true,"path":"2018/09/17/yolo-train/","link":"","permalink":"http://www.huarenlab.com/2018/09/17/yolo-train/","excerpt":"yolo太难训练了啊，动不动就nan，超参选择对模型是否收敛影响挺大的，本文分享我在训练yolo的一些经验","text":"yolo太难训练了啊，动不动就nan，超参选择对模型是否收敛影响挺大的，本文分享我在训练yolo的一些经验 YOLOv3为例先说yolov3首先要有张8GB以上的显卡，否则很难收敛。tiny-yolov3建议4G以上显存。 将batch设为64，subdivisions设为16，真实的batchsize为batch/subdivisions=4。显存主要是和真实的batchsize挂钩，设置大了要担心显存是否够用，但训练初期能够很好的收敛。 learning_rate设置过大训练会很快发散，在fine_tune模型时learning_rate为配置文件所设置的值，不是fine_tune模型时learning_rate为最大的学习率，训练过程真实的学习率会慢慢变大直到等于所设值。在训练一段时间后，loss值在很长的一段时间都在某个值附近徘徊，需要将learning_rate设置更小的值。总结learning_rate的值应该先增大再减小，可以通过steps和scales配置比率。 训练观察是否收敛，loss很快变小再在某个值附近徘徊；obj先变小后变大最后趋近1；召回率.5R会变大直到1，接着.75R也会有很多1；class和IOU会慢慢接近1。 训练测试1.\\darknet detector map .\\data\\voc.data .\\cfg\\yolov3.cfg .\\backup\\yolov3_271604.weights 结果包含每个类别的AP值，mAP值、精度、召回率、TP数量、FP数量、FN数量、平均IOU等。 模型输入图像尺寸和mask、anchors参数要对应，根据训练数据实际框大小的分布来确定值。在训练时候不会在某个尺度的框一直出现count:0的结果，才能最大化利用其尺度信息。 如果觉得三个scale不够用，可以将最后增加一个尺度，模仿原始模型文件写即可，注意合并要用第11层。mask、anchors参数也要添加更多的数据，9-&gt;12。 声明：如有错误或者侵权请邮箱联系我","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.huarenlab.com/categories/深度学习/"}],"tags":[{"name":"yolo","slug":"yolo","permalink":"http://www.huarenlab.com/tags/yolo/"}]},{"title":"深度学习常用标签转换","slug":"label-transfer","date":"2018-06-06T13:25:51.000Z","updated":"2019-04-13T01:52:14.044Z","comments":true,"path":"2018/06/06/label-transfer/","link":"","permalink":"http://www.huarenlab.com/2018/06/06/label-transfer/","excerpt":"在处理coco数据、imageNet、VOC数据时，需要对数据标签进行转换，本文即提供转换代码","text":"在处理coco数据、imageNet、VOC数据时，需要对数据标签进行转换，本文即提供转换代码 本文主要是对tencent 100k交通标志标记数据转换 临时写的，代码很乱，需要根据实际路径修改 数据下载： http://cg.cs.tsinghua.edu.cn/traffic-sign/tutorial.html 加载标签1234567891011121314import jsonimport pylab as plimport randomimport numpy as npimport cv2import anno_func%matplotlib inlinedatadir = \"../../data/\"filedir = datadir + \"/annotations.json\"ids = open(datadir + \"/test/ids.txt\").read().splitlines()annos = json.loads(open(filedir).read()) 分析结构12345imgid = random.sample(ids, 1)[0]img=annos[\"imgs\"][imgid]print (img)img=annos[\"types\"]print (img) 12&#123;u&apos;path&apos;: u&apos;test/2468.jpg&apos;, u&apos;objects&apos;: [&#123;u&apos;category&apos;: u&apos;pn&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 1343.2, u&apos;ymin&apos;: 911.2, u&apos;ymax&apos;: 964.0, u&apos;xmax&apos;: 1396.0&#125;, u&apos;ellipse_org&apos;: [[1367.87, 911.552], [1395.46, 937.913], [1368.33, 963.195], [1343.97, 936.988], [1353.99, 958.571], [1387.91, 957.183]], u&apos;ellipse&apos;: [[1369.0028076171875, 937.2377319335938], [51.76936721801758, 52.934967041015625], 139.54888916015625]&#125;, &#123;u&apos;category&apos;: u&apos;pn&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 1197.6, u&apos;ymin&apos;: 940.0, u&apos;ymax&apos;: 963.2, u&apos;xmax&apos;: 1220.8&#125;, u&apos;ellipse_org&apos;: [[1209.01, 940.921], [1219.11, 951.016], [1209.21, 961.043], [1199.25, 951.626], [1201.96, 944.986], [1201.22, 956.775], [1217.55, 945.799]], u&apos;ellipse&apos;: [[1209.0211181640625, 950.5414428710938], [19.53607940673828, 21.289642333984375], 153.71450805664062]&#125;, &#123;u&apos;category&apos;: u&apos;p11&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 229.6, u&apos;ymin&apos;: 963.2, u&apos;ymax&apos;: 1008.8000000000001, u&apos;xmax&apos;: 270.4&#125;, u&apos;ellipse_org&apos;: [[248.171, 963.658], [269.073, 986.158], [249.236, 1008.39], [231.395, 984.827], [262.816, 1002.0], [236.987, 1001.87], [263.881, 971.513]], u&apos;ellipse&apos;: [[249.62039184570312, 985.5843505859375], [37.6942024230957, 44.657630920410156], 177.4745330810547]&#125;, &#123;u&apos;category&apos;: u&apos;pl10&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 235.2, u&apos;ymin&apos;: 1009.6, u&apos;ymax&apos;: 1056.8, u&apos;xmax&apos;: 279.2&#125;, u&apos;ellipse_org&apos;: [[254.683, 1009.92], [277.41, 1032.51], [255.785, 1055.1], [235.813, 1031.96], [240.496, 1047.8], [239.945, 1018.6], [270.386, 1047.11], [271.488, 1017.49]], u&apos;ellipse&apos;: [[255.57847595214844, 1031.8031005859375], [41.567535400390625, 45.633445739746094], 3.8224732875823975]&#125;], u&apos;id&apos;: 2468&#125;[u&apos;i1&apos;, u&apos;i10&apos;, u&apos;i11&apos;, u&apos;i12&apos;, u&apos;i13&apos;, u&apos;i14&apos;, u&apos;i15&apos;, u&apos;i2&apos;, u&apos;i3&apos;, u&apos;i4&apos;, u&apos;i5&apos;, u&apos;il100&apos;, u&apos;il110&apos;, u&apos;il50&apos;, u&apos;il60&apos;, u&apos;il70&apos;, u&apos;il80&apos;, u&apos;il90&apos;, u&apos;io&apos;, u&apos;ip&apos;, u&apos;p1&apos;, u&apos;p10&apos;, u&apos;p11&apos;, u&apos;p12&apos;, u&apos;p13&apos;, u&apos;p14&apos;, u&apos;p15&apos;, u&apos;p16&apos;, u&apos;p17&apos;, u&apos;p18&apos;, u&apos;p19&apos;, u&apos;p2&apos;, u&apos;p20&apos;, u&apos;p21&apos;, u&apos;p22&apos;, u&apos;p23&apos;, u&apos;p24&apos;, u&apos;p25&apos;, u&apos;p26&apos;, u&apos;p27&apos;, u&apos;p28&apos;, u&apos;p3&apos;, u&apos;p4&apos;, u&apos;p5&apos;, u&apos;p6&apos;, u&apos;p7&apos;, u&apos;p8&apos;, u&apos;p9&apos;, u&apos;pa10&apos;, u&apos;pa12&apos;, u&apos;pa13&apos;, u&apos;pa14&apos;, u&apos;pa8&apos;, u&apos;pb&apos;, u&apos;pc&apos;, u&apos;pg&apos;, u&apos;ph1.5&apos;, u&apos;ph2&apos;, u&apos;ph2.1&apos;, u&apos;ph2.2&apos;, u&apos;ph2.4&apos;, u&apos;ph2.5&apos;, u&apos;ph2.8&apos;, u&apos;ph2.9&apos;, u&apos;ph3&apos;, u&apos;ph3.2&apos;, u&apos;ph3.5&apos;, u&apos;ph3.8&apos;, u&apos;ph4&apos;, u&apos;ph4.2&apos;, u&apos;ph4.3&apos;, u&apos;ph4.5&apos;, u&apos;ph4.8&apos;, u&apos;ph5&apos;, u&apos;ph5.3&apos;, u&apos;ph5.5&apos;, u&apos;pl10&apos;, u&apos;pl100&apos;, u&apos;pl110&apos;, u&apos;pl120&apos;, u&apos;pl15&apos;, u&apos;pl20&apos;, u&apos;pl25&apos;, u&apos;pl30&apos;, u&apos;pl35&apos;, u&apos;pl40&apos;, u&apos;pl5&apos;, u&apos;pl50&apos;, u&apos;pl60&apos;, u&apos;pl65&apos;, u&apos;pl70&apos;, u&apos;pl80&apos;, u&apos;pl90&apos;, u&apos;pm10&apos;, u&apos;pm13&apos;, u&apos;pm15&apos;, u&apos;pm1.5&apos;, u&apos;pm2&apos;, u&apos;pm20&apos;, u&apos;pm25&apos;, u&apos;pm30&apos;, u&apos;pm35&apos;, u&apos;pm40&apos;, u&apos;pm46&apos;, u&apos;pm5&apos;, u&apos;pm50&apos;, u&apos;pm55&apos;, u&apos;pm8&apos;, u&apos;pn&apos;, u&apos;pne&apos;, u&apos;po&apos;, u&apos;pr10&apos;, u&apos;pr100&apos;, u&apos;pr20&apos;, u&apos;pr30&apos;, u&apos;pr40&apos;, u&apos;pr45&apos;, u&apos;pr50&apos;, u&apos;pr60&apos;, u&apos;pr70&apos;, u&apos;pr80&apos;, u&apos;ps&apos;, u&apos;pw2&apos;, u&apos;pw2.5&apos;, u&apos;pw3&apos;, u&apos;pw3.2&apos;, u&apos;pw3.5&apos;, u&apos;pw4&apos;, u&apos;pw4.2&apos;, u&apos;pw4.5&apos;, u&apos;w1&apos;, u&apos;w10&apos;, u&apos;w12&apos;, u&apos;w13&apos;, u&apos;w16&apos;, u&apos;w18&apos;, u&apos;w20&apos;, u&apos;w21&apos;, u&apos;w22&apos;, u&apos;w24&apos;, u&apos;w28&apos;, u&apos;w3&apos;, u&apos;w30&apos;, u&apos;w31&apos;, u&apos;w32&apos;, u&apos;w34&apos;, u&apos;w35&apos;, u&apos;w37&apos;, u&apos;w38&apos;, u&apos;w41&apos;, u&apos;w42&apos;, u&apos;w43&apos;, u&apos;w44&apos;, u&apos;w45&apos;, u&apos;w46&apos;, u&apos;w47&apos;, u&apos;w48&apos;, u&apos;w49&apos;, u&apos;w5&apos;, u&apos;w50&apos;, u&apos;w55&apos;, u&apos;w56&apos;, u&apos;w57&apos;, u&apos;w58&apos;, u&apos;w59&apos;, u&apos;w60&apos;, u&apos;w62&apos;, u&apos;w63&apos;, u&apos;w66&apos;, u&apos;w8&apos;, u&apos;wo&apos;, u&apos;i6&apos;, u&apos;i7&apos;, u&apos;i8&apos;, u&apos;i9&apos;, u&apos;ilx&apos;, u&apos;p29&apos;, u&apos;w29&apos;, u&apos;w33&apos;, u&apos;w36&apos;, u&apos;w39&apos;, u&apos;w4&apos;, u&apos;w40&apos;, u&apos;w51&apos;, u&apos;w52&apos;, u&apos;w53&apos;, u&apos;w54&apos;, u&apos;w6&apos;, u&apos;w61&apos;, u&apos;w64&apos;, u&apos;w65&apos;, u&apos;w67&apos;, u&apos;w7&apos;, u&apos;w9&apos;, u&apos;pax&apos;, u&apos;pd&apos;, u&apos;pe&apos;, u&apos;phx&apos;, u&apos;plx&apos;, u&apos;pmx&apos;, u&apos;pnl&apos;, u&apos;prx&apos;, u&apos;pwx&apos;, u&apos;w11&apos;, u&apos;w14&apos;, u&apos;w15&apos;, u&apos;w17&apos;, u&apos;w19&apos;, u&apos;w2&apos;, u&apos;w23&apos;, u&apos;w25&apos;, u&apos;w26&apos;, u&apos;w27&apos;, u&apos;pl0&apos;, u&apos;pl4&apos;, u&apos;pl3&apos;, u&apos;pm2.5&apos;, u&apos;ph4.4&apos;, u&apos;pn40&apos;, u&apos;ph3.3&apos;, u&apos;ph2.6&apos;] 转换txt1234567891011121314151617cnt=0resultlistfile=open('test.txt','w')idsfile=open('ids.txt','w')for imgid in ids: if int(imgid)&lt;40000: idsfile.write(imgid+'\\n') img=annos[\"imgs\"][imgid] cnt+=1 for obj in img['objects']: box = obj['bbox'] ss = obj['category'] resstr=imgid+' '+ss+' '+str(box['xmin'])+' '+str(box['ymin'])+' '+str(box['xmax'])+' '+str(box['ymax'])+' 0 '+str(cnt) resultlistfile.write(resstr+'\\n') print (resstr) idsfile.close()resultlistfile.close() 1234567891011121314151617181910056 pne 414 877 431 909 0 110056 i5 452 886 468 916 0 110056 pne 1215 928 1237 950 0 110056 i5 1274 927 1294 949 0 110056 pne 2016 910 2032 934 0 110063 pr20 1637 949 1678 1002 0 210063 p27 1371 701 1426 759 0 210063 po 1482 692 1543 753 0 210063 pl40 1370 774 1422 834 0 210063 ph4.5 1480 765 1543 828 0 210128 pl40 1349 539 1450 643 0 310128 p11 1476 545 1570 650 0 310128 pn 1584 562 1684 662 0 31012 pl30 645 516 735 603 0 41012 pm20 742 512 837 600 0 41012 p26 843 487 938 572 0 41012 ph4.5 531 752 618 840 0 41012 p9 529 847 621 941 0 4 转换json1234567891011121314151617181920212223242526272829resultcont=open('test.txt','r')#print('namelist',resultcont)perid=''imgid=''# types=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]# trainotest='train'objs=[]results = &#123;&#125;for resultline in resultcont.read().split('\\n'): if resultline: ressplit=resultline.split(' ') if (not perid==ressplit[0]): perid=ressplit[0] if (not imgid == ''): #print(objs) results[imgid] = &#123;\"objects\":objs,\"id\":imgid,\"path\":\"\"+trainotest+\"/\"+imgid+\".jpg\"&#125; objs=[] mobj = &#123;\"bbox\":dict(zip([\"xmin\",\"ymin\",\"xmax\",\"ymax\"], [float(ressplit[2]),float(ressplit[3]),float(ressplit[4]),float(ressplit[5])])), \"category\":str(ressplit[1])&#125; objs.append(mobj) #print(ressplit[2:6]) imgid=ressplit[0]results[imgid] = &#123;\"objects\":objs,\"id\":imgid,\"path\":\"\"+trainotest+\"/\"+imgid+\".jpg\"&#125;results_annos = &#123;\"imgs\":results,\"types\":types&#125; print (results_annos)open(\"../../Src1/annotations.json\", \"w\").write(json.dumps(results_annos)) json转voc1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import jsonimport pylab as plimport randomimport numpy as npimport cv2import anno_func%matplotlib inlinedatadir = \"../../Src1/\"trainotest='train'filedir = datadir + \"/annotations.json\"ids = open(datadir + \"/\"+trainotest+\"/ids.txt\").read().splitlines()annos = json.loads(open(filedir).read())cnt=0resultlistfile=open('test.txt','w')for imgid in ids: if int(imgid)&lt;40000: img=annos[\"imgs\"][imgid] cnt+=1 node_root = Element('annotation') node_folder = SubElement(node_root, 'folder') node_folder.text = 'train' node_filename = SubElement(node_root, 'filename') node_filename.text = str(imgid)+'.jpg' node_filename = SubElement(node_root, 'path') node_filename.text = datadir+trainotest+\"/\"+str(imgid)+'.jpg' node_size = SubElement(node_root, 'size') node_width = SubElement(node_size, 'width') node_width.text = '2048' node_height = SubElement(node_size, 'height') node_height.text = '2048' node_depth = SubElement(node_size, 'depth') node_depth.text = '3' for obj in img['objects']: box = obj['bbox'] ss = obj['category'] str(box['xmin'])+' '+str(box['ymin'])+' '+str(box['xmax'])+' '+str(box['ymax'])+' 0 '+str(cnt) node_object = SubElement(node_root, 'object') node_name = SubElement(node_object, 'name') node_name.text = ss node_difficult = SubElement(node_object, 'difficult') node_difficult.text = '0' node_bndbox = SubElement(node_object, 'bndbox') node_xmin = SubElement(node_bndbox, 'xmin') node_xmin.text = str(int(box['xmin'])) node_ymin = SubElement(node_bndbox, 'ymin') node_ymin.text = str(int(box['ymin'])) node_xmax = SubElement(node_bndbox, 'xmax') node_xmax.text = str(int(box['xmax'])) node_ymax = SubElement(node_bndbox, 'ymax') node_ymax.text = str(int(box['ymax'])) xml = tostring(node_root, pretty_print=True) #格式化显示，该换行的换行 dom = parseString(xml) #print xml xmlfile=open(datadir+\"xml/\"+imgid+'.xml','w') xmlfile.write(xml)","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://www.huarenlab.com/categories/深度学习/"}],"tags":[{"name":"标签转换","slug":"标签转换","permalink":"http://www.huarenlab.com/tags/标签转换/"}]},{"title":"迁移说明","slug":"change","date":"2018-05-06T06:47:51.000Z","updated":"2019-04-13T01:52:14.044Z","comments":true,"path":"2018/05/06/change/","link":"","permalink":"http://www.huarenlab.com/2018/05/06/change/","excerpt":"","text":"原导航站迁移为博客访问 http://www.huarenlab.com/navi 获取原站内容，感谢您多年来的支持！！！","categories":[{"name":"皮一下","slug":"皮一下","permalink":"http://www.huarenlab.com/categories/皮一下/"}],"tags":[{"name":"原网站","slug":"原网站","permalink":"http://www.huarenlab.com/tags/原网站/"}]}]}