{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/favicon.ico","path":"favicon.ico","modified":1,"renderable":0},{"_id":"source/imgs/2018-10-30-nvidia-smi.jpg","path":"imgs/2018-10-30-nvidia-smi.jpg","modified":1,"renderable":0},{"_id":"source/imgs/2018-10-30-caffe-train.jpg","path":"imgs/2018-10-30-caffe-train.jpg","modified":1,"renderable":0},{"_id":"themes/material/source/css/style.less","path":"css/style.less","modified":1,"renderable":1},{"_id":"themes/material/source/img/alipay.jpg","path":"img/alipay.jpg","modified":1,"renderable":1},{"_id":"themes/material/source/img/avatar.jpg","path":"img/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/material/source/img/brand.jpg","path":"img/brand.jpg","modified":1,"renderable":1},{"_id":"themes/material/source/img/cc.png","path":"img/cc.png","modified":1,"renderable":1},{"_id":"themes/material/source/img/img-err.png","path":"img/img-err.png","modified":1,"renderable":1},{"_id":"themes/material/source/img/img-loading.png","path":"img/img-loading.png","modified":1,"renderable":1},{"_id":"themes/material/source/js/main.min.js","path":"js/main.min.js","modified":1,"renderable":1},{"_id":"themes/material/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/material/source/img/wechat.jpg","path":"img/wechat.jpg","modified":1,"renderable":1},{"_id":"themes/material/source/js/search.min.js","path":"js/search.min.js","modified":1,"renderable":1},{"_id":"themes/material/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/material/source/js/waves.min.js","path":"js/waves.min.js","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Bold.eot","path":"css/fonts/roboto/Roboto-Bold.eot","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Bold.woff","path":"css/fonts/roboto/Roboto-Bold.woff","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Bold.woff2","path":"css/fonts/roboto/Roboto-Bold.woff2","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Light.eot","path":"css/fonts/roboto/Roboto-Light.eot","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Light.woff","path":"css/fonts/roboto/Roboto-Light.woff","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Light.woff2","path":"css/fonts/roboto/Roboto-Light.woff2","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Medium.eot","path":"css/fonts/roboto/Roboto-Medium.eot","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Medium.woff","path":"css/fonts/roboto/Roboto-Medium.woff","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Medium.woff2","path":"css/fonts/roboto/Roboto-Medium.woff2","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Regular.eot","path":"css/fonts/roboto/Roboto-Regular.eot","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Regular.woff2","path":"css/fonts/roboto/Roboto-Regular.woff2","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Thin.eot","path":"css/fonts/roboto/Roboto-Thin.eot","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Regular.woff","path":"css/fonts/roboto/Roboto-Regular.woff","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Thin.woff","path":"css/fonts/roboto/Roboto-Thin.woff","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Thin.woff2","path":"css/fonts/roboto/Roboto-Thin.woff2","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.woff2","path":"css/fonts/fontawesome/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.woff","path":"css/fonts/fontawesome/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Bold.ttf","path":"css/fonts/roboto/Roboto-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Light.ttf","path":"css/fonts/roboto/Roboto-Light.ttf","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Medium.ttf","path":"css/fonts/roboto/Roboto-Medium.ttf","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Regular.ttf","path":"css/fonts/roboto/Roboto-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Thin.ttf","path":"css/fonts/roboto/Roboto-Thin.ttf","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/fontawesome/FontAwesome.otf","path":"css/fonts/fontawesome/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.eot","path":"css/fonts/fontawesome/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.ttf","path":"css/fonts/fontawesome/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"source/imgs/2019-11-07-vott-test.png","path":"imgs/2019-11-07-vott-test.png","modified":1,"renderable":0},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.svg","path":"css/fonts/fontawesome/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"c1bde3042b6732fa1489f531eb3ae9b75f45045f","modified":1555120334044},{"_id":"source/favicon.ico","hash":"ebe2caf7666237efa2cef95be7dc0bffb83bfbe5","modified":1555120334044},{"_id":"themes/material/.editorconfig","hash":"9b0445427777519defe360ea38c61729d847b3d3","modified":1555120334060},{"_id":"themes/material/package.json","hash":"1e68f8a243aa789452f6b1bafb7bad1295cb74a7","modified":1555120334060},{"_id":"themes/material/LICENSE","hash":"24944bf7920108f5a4790e6071c32e9102760c37","modified":1555120334060},{"_id":"themes/material/README.md","hash":"b188fb95a9c16eb188eeffa6caa0895a14676338","modified":1555120334060},{"_id":"themes/material/_config.yml","hash":"1b7bd470a01b6e5520feea8ff9488dbd823b1c8b","modified":1574905788515},{"_id":"source/_posts/caffe-cuda9-ubuntu1804.md","hash":"e3068fce8f20b349989443f8e35cc68fcec5a257","modified":1555120334044},{"_id":"source/_posts/label-transfer.md","hash":"de125633dc35db5242ac4fabe9ac7f6161f0e1de","modified":1555120334044},{"_id":"source/_posts/change.md","hash":"ea8ffc3eb9cb8d0c4db405143c0eb85b49366a77","modified":1555120334044},{"_id":"source/_posts/neo-ai-lab.md","hash":"afe314b57d922a56917a6c64c622b6cf57265c19","modified":1574906447111},{"_id":"source/_posts/singularity-base.md","hash":"3d62a321981ba56524d6dd1c08a74d4001526cc3","modified":1574905651383},{"_id":"source/_posts/vott-neon.md","hash":"616adba6905f660b8cc3b10ef8754be9671a39be","modified":1573113567801},{"_id":"source/_posts/yolo-train.md","hash":"9886af80c860fcb09994985e53e8dedb1ba94ab1","modified":1555120334044},{"_id":"source/categories/index.md","hash":"d9e1c9ceae8ef50082e267b6ba5044cb4714cdca","modified":1555120334040},{"_id":"source/imgs/2018-10-30-nvidia-smi.jpg","hash":"7f55d02cd87fe3a308df7dc3c23da999263936d4","modified":1555120334044},{"_id":"source/tags/index.md","hash":"ea267f39caf87836acc99fc0d11ca6b0889a036c","modified":1555120334044},{"_id":"source/navi/index.md","hash":"141a845cb6828ed14244aef6074e197253edde7f","modified":1573114311577},{"_id":"themes/material/languages/en.yml","hash":"f1879b4a03292d06e6cfc634c35772be1143c86e","modified":1555120334060},{"_id":"themes/material/languages/zh-CN.yml","hash":"3b8a9d95e2cb406c6c951e2cf16e7065fa75ba3f","modified":1555120334060},{"_id":"themes/material/languages/zh-TW.yml","hash":"21776a3c705f931f7f3f1d92ee8e9acf4ca26d5b","modified":1555120334060},{"_id":"themes/material/layout/archive.ejs","hash":"d039719e21f6a6fa2925b00aaa623a180a78c818","modified":1555120334060},{"_id":"themes/material/layout/categories.ejs","hash":"d5ae86ba13e7051ff6c52a7f14083b55929b139d","modified":1555120334060},{"_id":"themes/material/layout/layout.ejs","hash":"f2c2bf58794c697f61f141719546c15597c2ad71","modified":1555120334060},{"_id":"themes/material/layout/index.ejs","hash":"39477807b98b2d2df78f3b82498a11e90be8222c","modified":1555120334060},{"_id":"themes/material/layout/category.ejs","hash":"7ea26a8a935886963eda82f41c7bd5270cf780d9","modified":1555120334060},{"_id":"themes/material/layout/navis.ejs","hash":"f1cc608f0e9da5c108077ce5259ca076555b230d","modified":1555120334060},{"_id":"themes/material/layout/page.ejs","hash":"afb98face24d39a21ebbbde6592a9afc98572aa4","modified":1555120334060},{"_id":"themes/material/layout/navi.ejs","hash":"3e164a723af885a1189a4934a715869589e12a35","modified":1555120334060},{"_id":"themes/material/scripts/plugins.js","hash":"e439d717513616bedeed37ba9b05117470809b21","modified":1555120334060},{"_id":"themes/material/layout/tag.ejs","hash":"36786a3de7f6cad58209603f7d84ba23addea174","modified":1555120334060},{"_id":"source/imgs/2018-10-30-caffe-train.jpg","hash":"68c430a8f59356cae51652a8dba027ba0158679f","modified":1555120334040},{"_id":"themes/material/layout/post.ejs","hash":"afbf8532dc8d148ca4dff2ca127a3382907cf2f5","modified":1555120334060},{"_id":"themes/material/layout/tags.ejs","hash":"9cf937f7b4b3d06f72a20f5edde396088c67c645","modified":1555120334060},{"_id":"themes/material/layout/_partial/after-footer.ejs","hash":"9ac30b9439fab69973cf4722dbf2945a18fd3804","modified":1555120334060},{"_id":"themes/material/layout/_partial/archive.ejs","hash":"55cd81ef9183426d6d99fd91550fce0a9cc92aa0","modified":1555120334060},{"_id":"themes/material/layout/_partial/footer.ejs","hash":"4132b25682e6b83bf21c2e86edc9a8df8955a62b","modified":1555120334060},{"_id":"themes/material/layout/_partial/header.ejs","hash":"6156bf20791e46fc1c5872113276c1c1f5c13773","modified":1555120334060},{"_id":"themes/material/layout/_partial/index-item.ejs","hash":"ec7b3ec79bbbead9c7e43e2e6c6b5c8bef509410","modified":1555120334060},{"_id":"themes/material/layout/_partial/loading.ejs","hash":"bc4cb19b20de55a0332647f4dca9684184383685","modified":1555120334060},{"_id":"themes/material/layout/_partial/menu.ejs","hash":"d3cf676befa6ea8eb635c2e38f88913ef591395f","modified":1555120334060},{"_id":"themes/material/layout/_partial/paginator.ejs","hash":"dc27242927890f130a64400596b9b7ad5fca8972","modified":1555120334060},{"_id":"themes/material/layout/_partial/script.ejs","hash":"99cf7dfc1f2de366025d470600fa59ff4240ab2c","modified":1555120334060},{"_id":"themes/material/layout/_partial/post.ejs","hash":"d89be00c9b3a086c2e0c3c7d9f8e2f6de5861a5f","modified":1555120334060},{"_id":"themes/material/layout/_partial/search.ejs","hash":"c2091c621b5480ef1e69d72027028cec8e929892","modified":1555120334060},{"_id":"themes/material/layout/_partial/tags-bar.ejs","hash":"19eff4876d31080a427644f7a43fe172d0c008c6","modified":1555120334060},{"_id":"themes/material/layout/_partial/head.ejs","hash":"b197b87b120b09b68aa3d79954ed039816a88664","modified":1555120334060},{"_id":"themes/material/source/css/style.less","hash":"3e151cd162e8af87d7ca90e3067f7bd99a25f823","modified":1555120334056},{"_id":"themes/material/source/img/alipay.jpg","hash":"6054d9ed2ca7cd1f645b729e05632134467d4daa","modified":1555120334060},{"_id":"themes/material/source/img/avatar.jpg","hash":"f3a7ae0571bc7615e7e03a4409f489de0d1fade9","modified":1555120334060},{"_id":"themes/material/source/img/brand.jpg","hash":"d85c0f8f86d73465f82f74060296febcb3847f8a","modified":1555120334060},{"_id":"themes/material/source/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1555120334060},{"_id":"themes/material/source/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1555120334060},{"_id":"themes/material/source/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1555120334060},{"_id":"themes/material/source/js/main.min.js","hash":"70652f94832de4801ffe80bf59d09265ac84599f","modified":1555120334060},{"_id":"themes/material/source/js/main.js","hash":"411836a39a01be178e7bba14f8959b6949488de9","modified":1555120334060},{"_id":"themes/material/source/img/wechat.jpg","hash":"ef069cc9e80c7553fd60589b0727bbbf8c6de372","modified":1555120334060},{"_id":"themes/material/source/js/search.min.js","hash":"a8a450bb8b1ca9ad577052addcbd3393f1af6c6a","modified":1555120334060},{"_id":"themes/material/source/js/search.js","hash":"a1de7e7a2ef8330ebcd9f3a7a4622b3bac44e4f3","modified":1555120334060},{"_id":"themes/material/source/js/waves.min.js","hash":"3e8f25de9729d8941b97ec5081e0b9ad89385b2e","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/baidu.ejs","hash":"e44d526029f122e9c2c74f3a647c35002c818cbe","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/disqus.ejs","hash":"4a0c01e4195f685f9825fcd016d01249dbdd52ca","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/dynamic-title.ejs","hash":"23c101d45911eb0846533aaa2d409c43aa5e899a","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/gitment.ejs","hash":"5723d507eca4390e8e5d18c0770e7953b8c22f5a","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/google-analytics.ejs","hash":"a947f4076b54b48d4df5baf2d5b3c39b632c7576","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/mathjax.ejs","hash":"ea603a057196de53bd6afab1fddb93d11f27eb81","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/page-visit.ejs","hash":"2decb77bf3c1a064ea6ce1d4e78892c434d9c884","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/site-visit.ejs","hash":"8fbd0910828f1ab6eba728bdecc9811d623baae2","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/tajs.ejs","hash":"97b48fe10be1c71d4ff25ccec3bd92d97466c9c5","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/uyan.ejs","hash":"e370bd04ea5cf1c83e0c20516aff7ba3ca8b2d0b","modified":1555120334060},{"_id":"themes/material/layout/_partial/plugins/valine.ejs","hash":"a976ca36bd09aeb2902bf94fcc7a59975ea25148","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/comment.ejs","hash":"f2c6a55a88ce694b44c46c8322293172afc00255","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/category.ejs","hash":"c7476165721a3a5e34d00d8c5c07e1e5474cd800","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/copyright.ejs","hash":"968b27ca952d01b066cfe49fb670faf177d6b67e","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/date.ejs","hash":"ea85b46e12d3b9c3612eef7aa76289a663fbc096","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/head-meta.ejs","hash":"b0c680ce5b8aaf461a6731b1ff1287bd140c168a","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/nav.ejs","hash":"11e7d504f7c7a3c4c052da13cfa8ea4862c9383e","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/reward-btn.ejs","hash":"41c242fe3159dc68cec8dd00ab6d2663f5a51179","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/reward.ejs","hash":"23719e09689b3afbb19214c6603eb02f896cb9ba","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/share-fab.ejs","hash":"93482ad7d1e01b966f5ee1c5d12b88564e02b349","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/share.ejs","hash":"8df0d7bf6f8e106cdbdac2dd10a97367aa0695f8","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/tag.ejs","hash":"b3dc38652c4a018a37418136478dcd522fc49f79","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/title.ejs","hash":"062d56cb88ae2be3a6616b911d4ebeffcbfe3cff","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/toc.ejs","hash":"b6123e895c16ace651f1832281ff655776d4068c","modified":1555120334060},{"_id":"themes/material/layout/_partial/post/updated.ejs","hash":"5caa71745aa340ce57938a930f3b898ee7518d74","modified":1555120334060},{"_id":"themes/material/source/css/_partial/article.less","hash":"4ea7ef6dc47a3df8d31bac4bdf83c17d4161f593","modified":1555120334056},{"_id":"themes/material/source/css/_partial/archives.less","hash":"7d2a6886265386c640e94ffca3f042675f701a35","modified":1555120334056},{"_id":"themes/material/source/css/_partial/highlight.less","hash":"58492b7cdb45fe09b026b2f34e8ae69c2ddb8228","modified":1555120334056},{"_id":"themes/material/source/css/_partial/gotop.less","hash":"b7db31b9bc563c10b9e3cf3e6d9cfddfeb3e805a","modified":1555120334056},{"_id":"themes/material/source/css/_partial/layout.less","hash":"f22c732f15c13bf31838ca039fb182a1b0f59b7a","modified":1555120334056},{"_id":"themes/material/source/css/_partial/lightbox.less","hash":"a9b72e45fcf7c4070cc9caa708cf747a896e9cae","modified":1555120334056},{"_id":"themes/material/source/css/_partial/header.less","hash":"90f0948a9182c14b1dac1e9dbed3c883543266f9","modified":1555120334056},{"_id":"themes/material/source/css/_partial/loading.less","hash":"f9d06a1e24fb4857fd18d7a0bfbb3a0ab2d1c742","modified":1555120334056},{"_id":"themes/material/source/css/_partial/postlist.less","hash":"10e922b23dbe98f27a85ce04ea89ca7091ff2866","modified":1555120334056},{"_id":"themes/material/source/css/_partial/roboto.less","hash":"2e0469ed8161d5672d903ca1a8027cd65fe007f1","modified":1555120334056},{"_id":"themes/material/source/css/_partial/page.less","hash":"e92ccb53e6ac73a51498c6a9672db9d0d2bc7f1a","modified":1555120334056},{"_id":"themes/material/source/css/_partial/share.less","hash":"27d80bcc96a53dd1e7eaa9a7d746e4b212357302","modified":1555120334056},{"_id":"themes/material/source/css/_partial/search.less","hash":"1d6641ae7568a0153d24beba9fd9704d2b155f6c","modified":1555120334056},{"_id":"themes/material/source/css/_partial/reward.less","hash":"4857f90bb57fc22ca3f942d8934d86d5e9e82c1e","modified":1555120334056},{"_id":"themes/material/source/css/_partial/variable.less","hash":"3246c37e90be1215a7ca4c7d08d490ce3012d0e3","modified":1555120334056},{"_id":"themes/material/source/css/_partial/waves.less","hash":"77bfd0b373b0469eb0176167fb076ccda4edf2a7","modified":1555120334056},{"_id":"themes/material/source/css/_partial/tags.less","hash":"959f4373fda6e45f6a4041a995ed3ea8a05a5170","modified":1555120334056},{"_id":"themes/material/source/css/_partial/fontawesome.less","hash":"ca30b732d2efbb0cd55a272ecdabc97f895aee78","modified":1555120334056},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1555120334056},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1555120334056},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1555120334056},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1555120334056},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1555120334060},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1555120334056},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1555120334056},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1555120334056},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1555120334056},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1555120334060},{"_id":"themes/material/source/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1555120334060},{"_id":"themes/material/source/css/fonts/fontawesome/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1555120334056},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1555120334056},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1555120334056},{"_id":"source/imgs/2019-11-07-vott-test.png","hash":"c8a7d6314e83b50b064ee51e8ee2b47606880ceb","modified":1573113424177},{"_id":"themes/material/source/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1555120334056},{"_id":"public/content.json","hash":"d2315364ed4815b599d39d7a50c8dc48f4a4bee6","modified":1574906481162},{"_id":"public/2018/05/06/change/index.html","hash":"967589c1665c85177529e0516f68bae9f4f5ee5a","modified":1574906481776},{"_id":"public/archives/index.html","hash":"19b31f19a8bd97e6c26c6ef1bad447850fb7bb09","modified":1574906481776},{"_id":"public/archives/2018/index.html","hash":"a8614db35fe522e5887ead0cff14902fd1881557","modified":1574906481777},{"_id":"public/archives/2018/05/index.html","hash":"469c3d1ded75d056afe42b925e1d257c12f2d2a2","modified":1574906481777},{"_id":"public/archives/2018/06/index.html","hash":"c838f8e5c5e3c26b1c57a9df7618b99c283029e9","modified":1574906481777},{"_id":"public/archives/2018/09/index.html","hash":"8de0c4258213be7c7e1f6d2629621843c2f5ce03","modified":1574906481777},{"_id":"public/archives/2018/10/index.html","hash":"ab40a0c5c6653b053f30311adb61f9ac8c117e60","modified":1574906481777},{"_id":"public/archives/2019/index.html","hash":"19e504cc399bd2c43da375f6a9e97616081e3c1b","modified":1574906481777},{"_id":"public/archives/2019/11/index.html","hash":"5d8f87c58d8d821e45af76977fe426acfe26365e","modified":1574906481777},{"_id":"public/categories/深度学习/index.html","hash":"b05f4eca5b0bdfb14b9893626f03231ea2f73089","modified":1574906481777},{"_id":"public/categories/皮一下/index.html","hash":"c2ca55746d0fc345865326fd954f9c2ddd3cec9b","modified":1574906481777},{"_id":"public/tags/caffe配置/index.html","hash":"68727f2920f0bc388b29d9eb4e61a3f7b2e2473e","modified":1574906481777},{"_id":"public/tags/标签转换/index.html","hash":"5da563a3fd6ebd612b3f77fbaaf558f1c80d4687","modified":1574906481777},{"_id":"public/tags/原网站/index.html","hash":"f96b92fdf7ee0a50fdc912af8a58c066f380950f","modified":1574906481777},{"_id":"public/tags/镜像/index.html","hash":"905cc04c55f9c7cc9ad3fe08b577bb1af0cbbb85","modified":1574906481777},{"_id":"public/tags/docker/index.html","hash":"c140d855efe94052e5c1fc3454c7fb6fe0228b0c","modified":1574906481777},{"_id":"public/tags/容器/index.html","hash":"ba3d39ef6bbfb5f974bc3a09934837172c69163e","modified":1574906481778},{"_id":"public/tags/singularity/index.html","hash":"bb1a7707262bad6c2fd8a2f32626ecdeea3d9a40","modified":1574906481778},{"_id":"public/tags/标注/index.html","hash":"0de97e55b12259abf5679f02bcb913dfdcfe1337","modified":1574906481778},{"_id":"public/tags/yolo/index.html","hash":"bee5d31e0c40043c401dbc40afa5cc6763cdf832","modified":1574906481778},{"_id":"public/categories/index.html","hash":"5aea31f392e08b13e09bc703cd81d90d57bdd113","modified":1574906481783},{"_id":"public/tags/index.html","hash":"d7001b28ec6000876cf16f749c249c204e8a864c","modified":1574906481783},{"_id":"public/navi/index.html","hash":"d6b60dc3f7306a21e4ca2ae059c718450015fa34","modified":1574906481783},{"_id":"public/2019/11/27/neo-ai-lab/index.html","hash":"55815cf0c4010ddce9055d2017458a92987bc799","modified":1574906481783},{"_id":"public/2019/11/23/singularity-base/index.html","hash":"dc7f3be109089e99028086b7bd79fdd77f2debd4","modified":1574906481783},{"_id":"public/2019/11/06/vott-neon/index.html","hash":"c028de038aa8a23d2b4087011927ba153b9c1525","modified":1574906481783},{"_id":"public/2018/10/30/caffe-cuda9-ubuntu1804/index.html","hash":"c9d37674db4d4f74fbb398628b422cdf30dc9369","modified":1574906481783},{"_id":"public/2018/09/17/yolo-train/index.html","hash":"b0865f5d52bd0e400403e5ac84961cf5f0836887","modified":1574906481783},{"_id":"public/2018/06/06/label-transfer/index.html","hash":"be718032bd947d6fd78964fb3221bac9eefd9cb1","modified":1574906481783},{"_id":"public/index.html","hash":"4a05fc1a4792737ab1759cc11c0ca5e4f9772d1f","modified":1574906481783},{"_id":"public/CNAME","hash":"c1bde3042b6732fa1489f531eb3ae9b75f45045f","modified":1574906481789},{"_id":"public/favicon.ico","hash":"ebe2caf7666237efa2cef95be7dc0bffb83bfbe5","modified":1574906481790},{"_id":"public/imgs/2018-10-30-nvidia-smi.jpg","hash":"7f55d02cd87fe3a308df7dc3c23da999263936d4","modified":1574906481790},{"_id":"public/img/alipay.jpg","hash":"6054d9ed2ca7cd1f645b729e05632134467d4daa","modified":1574906481790},{"_id":"public/img/avatar.jpg","hash":"f3a7ae0571bc7615e7e03a4409f489de0d1fade9","modified":1574906481790},{"_id":"public/img/brand.jpg","hash":"d85c0f8f86d73465f82f74060296febcb3847f8a","modified":1574906481790},{"_id":"public/img/cc.png","hash":"ebce75a62b40976a72d43f0bd937d859ac24d87c","modified":1574906481790},{"_id":"public/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1574906481790},{"_id":"public/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1574906481790},{"_id":"public/img/wechat.jpg","hash":"ef069cc9e80c7553fd60589b0727bbbf8c6de372","modified":1574906481790},{"_id":"public/css/fonts/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1574906481790},{"_id":"public/css/fonts/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1574906481790},{"_id":"public/css/fonts/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1574906481791},{"_id":"public/css/fonts/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1574906481792},{"_id":"public/css/fonts/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1574906481792},{"_id":"public/css/fonts/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1574906481792},{"_id":"public/css/fonts/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1574906481794},{"_id":"public/css/fonts/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1574906481794},{"_id":"public/css/fonts/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1574906481794},{"_id":"public/css/fonts/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1574906481794},{"_id":"public/css/fonts/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1574906481794},{"_id":"public/css/fonts/roboto/Roboto-Thin.eot","hash":"0790a51a848dbe7292c98f9d0459218bf1a8ffdd","modified":1574906481794},{"_id":"public/css/fonts/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1574906481794},{"_id":"public/css/fonts/roboto/Roboto-Thin.woff","hash":"fbc3e71d456c96667d8082ab910e3946ef89240b","modified":1574906481794},{"_id":"public/css/fonts/roboto/Roboto-Thin.woff2","hash":"2449e3dac5ddb7c3da8bb07450493b62d052758c","modified":1574906481794},{"_id":"public/imgs/2018-10-30-caffe-train.jpg","hash":"68c430a8f59356cae51652a8dba027ba0158679f","modified":1574906481815},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1574906481815},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1574906481815},{"_id":"public/css/fonts/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1574906481815},{"_id":"public/css/fonts/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1574906481815},{"_id":"public/css/fonts/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1574906481815},{"_id":"public/css/fonts/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1574906481815},{"_id":"public/css/fonts/roboto/Roboto-Thin.ttf","hash":"173ed64528b4d010a76d8d38deb1d7e7eed58eda","modified":1574906481816},{"_id":"public/js/main.min.js","hash":"70652f94832de4801ffe80bf59d09265ac84599f","modified":1574906481822},{"_id":"public/js/search.min.js","hash":"a8a450bb8b1ca9ad577052addcbd3393f1af6c6a","modified":1574906481822},{"_id":"public/js/search.js","hash":"a1de7e7a2ef8330ebcd9f3a7a4622b3bac44e4f3","modified":1574906481822},{"_id":"public/js/waves.min.js","hash":"3e8f25de9729d8941b97ec5081e0b9ad89385b2e","modified":1574906481826},{"_id":"public/js/main.js","hash":"411836a39a01be178e7bba14f8959b6949488de9","modified":1574906481826},{"_id":"public/css/fonts/fontawesome/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1574906481826},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1574906481826},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1574906481826},{"_id":"public/css/fonts/fontawesome/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1574906481855},{"_id":"public/css/style.css","hash":"94aa0bdd26536728dcdfeacf65d1d09b3bb8a888","modified":1574906482222},{"_id":"public/imgs/2019-11-07-vott-test.png","hash":"c8a7d6314e83b50b064ee51e8ee2b47606880ceb","modified":1574906482248}],"Category":[{"name":"深度学习","_id":"ck3i2nlgx0004axsiu4x9k9bw"},{"name":"皮一下","_id":"ck3i2nlhl000gaxsib6vcl3my"}],"Data":[],"Page":[{"title":"分类","date":"2018-05-05T05:21:17.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2018-05-05 13:21:17\ntype: categories\nlayout: categories\n---","updated":"2019-04-13T01:52:14.040Z","path":"categories/index.html","comments":1,"_id":"ck3i2nlgt0001axsig40i4l10","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"标签","date":"2018-05-05T09:27:09.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2018-05-05 17:27:09\ntype: tags\nlayout: tags\n---","updated":"2019-04-13T01:52:14.044Z","path":"tags/index.html","comments":1,"_id":"ck3i2nlgw0003axsirj4i3p4u","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"导航","date":"2018-09-14T11:21:17.000Z","type":"navi","layout":"navi","_content":"\n### 学术\n\n%%%\n\n[学术论文搜索](http://nav.hiqq.com.cn/txs/?q=deep%20learning)\nhiqq:集合百度、谷歌、CNKI、SCI\n\n[专著下载](http://gen.lib.rus.ec/search.php?req=risc+v&open=0&res=25&view=simple&phrase=1&column=def)\nLibrary Genesis:英文版，收录全\n\n[全能论文下载](http://sci-hub.tw/)\nSCI-HUB:且用且珍惜\n\n[百度学术](http://xueshu.baidu.com/)\n保持学习态度\n\n[专利检索](http://pss-system.cnipa.gov.cn/sipopublicsearch/portal/uiIndex.shtml)\n需要登录，可下载全文\n\n[算法竞赛](https://www.kaggle.com/competitions)\nkaggle:最大的竞赛平台，奖金丰厚\n\n\n[生理数据数据库](http://www.physionet.org/physiobank/database/#ecg)\nphysionet:ECG信号下载\n\n[公开课教学](https://www.coursera.org/)\ncoursera:快来学习，充实自己\n\n[优达学城](http://cn.udacity.com/course/intro-to-self-driving-cars--nd113-cn)\nudacity:硅谷前沿技术学习平台\n\n[b站视频资源](https://space.bilibili.com/8431135/#/)\nneophack:过气up主\n\n[b站视频资源](https://space.bilibili.com/209599371/#/)\n李沐:MXNET视频教程\n\n[b站视频资源](https://space.bilibili.com/12430528/#/)\n宫帅USTC:很多最新深度学习分享\n\n[b站视频资源](https://space.bilibili.com/19062251/#/)\n秋兰作佩:视频图像处理教学\n\n[莫凡python](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/1-1-why/)\n偏向于实践手把手教学\n\n[华东师范公开课](http://wims.math.ecnu.edu.cn/ChunLi/)\n陆吾生最优化和稀疏感知课程\n\n\n[小木虫](http://muchong.com/guide.php)\n学术交流\n\n/%%%\n\n## 技术\n\n%%%\n\n[慕课网](https://www.imooc.com/course/list?c=deep)\n程序员充电，包含深度学习\n\n[W3C学院](https://www.w3cschool.cn/)\nw3cschool:例子丰富\n\n[Gayhub](https://github.com/)\ngithub:最大的开源社区\n\n[联合开发网](http://www.pudn.com/)\n上传一份代码有30次下载机会\n\n[CSDN博客](https://blog.csdn.net/u011014502)\nCSDN:博客,咕咕咕\n\n/%%%\n\n## 资源\n\n%%%\n\n[网盘搜索](http://www.panduoduo.net/)\n盘多多:不是盘夕夕\n\n[网盘搜索](http://www.tebaidu.com/file-56956d74a355d2e8776bedffaa197d1112967444.html)\n特百度:和多多一起辅助找资料\n\n[手写latex](https://webdemo.myscript.com/views/main/math.html)\nmyscript:手写公式转latex\n\n[预训练模型](https://pan.baidu.com/s/1a4WOZLCSFNzGVX082iKe0w)\n百度云:keras模型（密码：3gs8）\n\n[吴恩达机器学习](https://pan.baidu.com/s/19RXTyHqWMftsehs7Th5qcA)\n百度云:视频+讲义（密码：q46u）\n\n[IDA7.0](https://pan.baidu.com/s/1S6Uksg0te4tKHzxQw0z7kw)\n百度云:静态分析神器（密码：i5qf）\n\n[图书代码下载](http://www.tup.tsinghua.edu.cn/booksCenter/book_07482601.html)\n清华大学出版社:很多书有资源下载\n\n[cpu参数](https://ark.intel.com/zh-cn/products/series/122593/-i7-)\nINTEL:详细参数和选型\n\n[微软订阅](https://msdn.itellyou.cn/)\nITellYou:office、windows、vs2019\n\n[Linux软件包](https://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html)\npkgs:安装低版本软件，下载方便\n\n[pipy软件包](https://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy)\nlfd.uci:numpy-mkl等python软件包\n\n[传图识色](https://www.sojson.com/web/img.html)\n能识别图片的主要颜色值\n\n[坐标拾取](http://www.gpsspg.com/maps.htm)\n支持谷歌、百度、腾讯/高德、图吧\n\n[wolfram](https://reference.wolfram.com/language/ref/InverseDistanceTransform.html)\n统一符号语言读取的大量内置算法和知识\n\n/%%%\n\n## 我是购物狂\n\n%%%\n\n[百面机器学习](https://item.jd.com/12401859.html)\n京东:百面机器学习\n\n[教你设计CPU](https://item.jd.com/12360850.html)\n京东:RISC-V是当前比较火的架构\n\n[荔枝糖](https://item.taobao.com/item.htm?id=573670462932)\n能跑RISC-V的FPGA的开发板\n\n[荔枝丹](https://item.taobao.com/item.htm?id=578484113485)\n能跑yolo的risc-v的开发板，堪智K210\n\n/%%%\n\n","source":"navi/index.md","raw":"---\ntitle: 导航\ndate: 2018-09-14 19:21:17\ntype: navi\nlayout: navi\n---\n\n### 学术\n\n%%%\n\n[学术论文搜索](http://nav.hiqq.com.cn/txs/?q=deep%20learning)\nhiqq:集合百度、谷歌、CNKI、SCI\n\n[专著下载](http://gen.lib.rus.ec/search.php?req=risc+v&open=0&res=25&view=simple&phrase=1&column=def)\nLibrary Genesis:英文版，收录全\n\n[全能论文下载](http://sci-hub.tw/)\nSCI-HUB:且用且珍惜\n\n[百度学术](http://xueshu.baidu.com/)\n保持学习态度\n\n[专利检索](http://pss-system.cnipa.gov.cn/sipopublicsearch/portal/uiIndex.shtml)\n需要登录，可下载全文\n\n[算法竞赛](https://www.kaggle.com/competitions)\nkaggle:最大的竞赛平台，奖金丰厚\n\n\n[生理数据数据库](http://www.physionet.org/physiobank/database/#ecg)\nphysionet:ECG信号下载\n\n[公开课教学](https://www.coursera.org/)\ncoursera:快来学习，充实自己\n\n[优达学城](http://cn.udacity.com/course/intro-to-self-driving-cars--nd113-cn)\nudacity:硅谷前沿技术学习平台\n\n[b站视频资源](https://space.bilibili.com/8431135/#/)\nneophack:过气up主\n\n[b站视频资源](https://space.bilibili.com/209599371/#/)\n李沐:MXNET视频教程\n\n[b站视频资源](https://space.bilibili.com/12430528/#/)\n宫帅USTC:很多最新深度学习分享\n\n[b站视频资源](https://space.bilibili.com/19062251/#/)\n秋兰作佩:视频图像处理教学\n\n[莫凡python](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/1-1-why/)\n偏向于实践手把手教学\n\n[华东师范公开课](http://wims.math.ecnu.edu.cn/ChunLi/)\n陆吾生最优化和稀疏感知课程\n\n\n[小木虫](http://muchong.com/guide.php)\n学术交流\n\n/%%%\n\n## 技术\n\n%%%\n\n[慕课网](https://www.imooc.com/course/list?c=deep)\n程序员充电，包含深度学习\n\n[W3C学院](https://www.w3cschool.cn/)\nw3cschool:例子丰富\n\n[Gayhub](https://github.com/)\ngithub:最大的开源社区\n\n[联合开发网](http://www.pudn.com/)\n上传一份代码有30次下载机会\n\n[CSDN博客](https://blog.csdn.net/u011014502)\nCSDN:博客,咕咕咕\n\n/%%%\n\n## 资源\n\n%%%\n\n[网盘搜索](http://www.panduoduo.net/)\n盘多多:不是盘夕夕\n\n[网盘搜索](http://www.tebaidu.com/file-56956d74a355d2e8776bedffaa197d1112967444.html)\n特百度:和多多一起辅助找资料\n\n[手写latex](https://webdemo.myscript.com/views/main/math.html)\nmyscript:手写公式转latex\n\n[预训练模型](https://pan.baidu.com/s/1a4WOZLCSFNzGVX082iKe0w)\n百度云:keras模型（密码：3gs8）\n\n[吴恩达机器学习](https://pan.baidu.com/s/19RXTyHqWMftsehs7Th5qcA)\n百度云:视频+讲义（密码：q46u）\n\n[IDA7.0](https://pan.baidu.com/s/1S6Uksg0te4tKHzxQw0z7kw)\n百度云:静态分析神器（密码：i5qf）\n\n[图书代码下载](http://www.tup.tsinghua.edu.cn/booksCenter/book_07482601.html)\n清华大学出版社:很多书有资源下载\n\n[cpu参数](https://ark.intel.com/zh-cn/products/series/122593/-i7-)\nINTEL:详细参数和选型\n\n[微软订阅](https://msdn.itellyou.cn/)\nITellYou:office、windows、vs2019\n\n[Linux软件包](https://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html)\npkgs:安装低版本软件，下载方便\n\n[pipy软件包](https://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy)\nlfd.uci:numpy-mkl等python软件包\n\n[传图识色](https://www.sojson.com/web/img.html)\n能识别图片的主要颜色值\n\n[坐标拾取](http://www.gpsspg.com/maps.htm)\n支持谷歌、百度、腾讯/高德、图吧\n\n[wolfram](https://reference.wolfram.com/language/ref/InverseDistanceTransform.html)\n统一符号语言读取的大量内置算法和知识\n\n/%%%\n\n## 我是购物狂\n\n%%%\n\n[百面机器学习](https://item.jd.com/12401859.html)\n京东:百面机器学习\n\n[教你设计CPU](https://item.jd.com/12360850.html)\n京东:RISC-V是当前比较火的架构\n\n[荔枝糖](https://item.taobao.com/item.htm?id=573670462932)\n能跑RISC-V的FPGA的开发板\n\n[荔枝丹](https://item.taobao.com/item.htm?id=578484113485)\n能跑yolo的risc-v的开发板，堪智K210\n\n/%%%\n\n","updated":"2019-11-07T08:11:51.577Z","path":"navi/index.html","comments":1,"_id":"ck3i2nlh10007axsi8bsg5u6t","content":"<h3 id=\"学术\"><a href=\"#学术\" class=\"headerlink\" title=\"学术\"></a>学术</h3><p>%%%</p>\n<p><a href=\"http://nav.hiqq.com.cn/txs/?q=deep%20learning\" target=\"_blank\" rel=\"noopener\">学术论文搜索</a><br>hiqq:集合百度、谷歌、CNKI、SCI</p>\n<p><a href=\"http://gen.lib.rus.ec/search.php?req=risc+v&amp;open=0&amp;res=25&amp;view=simple&amp;phrase=1&amp;column=def\" target=\"_blank\" rel=\"noopener\">专著下载</a><br>Library Genesis:英文版，收录全</p>\n<p><a href=\"http://sci-hub.tw/\" target=\"_blank\" rel=\"noopener\">全能论文下载</a><br>SCI-HUB:且用且珍惜</p>\n<p><a href=\"http://xueshu.baidu.com/\" target=\"_blank\" rel=\"noopener\">百度学术</a><br>保持学习态度</p>\n<p><a href=\"http://pss-system.cnipa.gov.cn/sipopublicsearch/portal/uiIndex.shtml\" target=\"_blank\" rel=\"noopener\">专利检索</a><br>需要登录，可下载全文</p>\n<p><a href=\"https://www.kaggle.com/competitions\" target=\"_blank\" rel=\"noopener\">算法竞赛</a><br>kaggle:最大的竞赛平台，奖金丰厚</p>\n<p><a href=\"http://www.physionet.org/physiobank/database/#ecg\" target=\"_blank\" rel=\"noopener\">生理数据数据库</a><br>physionet:ECG信号下载</p>\n<p><a href=\"https://www.coursera.org/\" target=\"_blank\" rel=\"noopener\">公开课教学</a><br>coursera:快来学习，充实自己</p>\n<p><a href=\"http://cn.udacity.com/course/intro-to-self-driving-cars--nd113-cn\" target=\"_blank\" rel=\"noopener\">优达学城</a><br>udacity:硅谷前沿技术学习平台</p>\n<p><a href=\"https://space.bilibili.com/8431135/#/\" target=\"_blank\" rel=\"noopener\">b站视频资源</a><br>neophack:过气up主</p>\n<p><a href=\"https://space.bilibili.com/209599371/#/\" target=\"_blank\" rel=\"noopener\">b站视频资源</a><br>李沐:MXNET视频教程</p>\n<p><a href=\"https://space.bilibili.com/12430528/#/\" target=\"_blank\" rel=\"noopener\">b站视频资源</a><br>宫帅USTC:很多最新深度学习分享</p>\n<p><a href=\"https://space.bilibili.com/19062251/#/\" target=\"_blank\" rel=\"noopener\">b站视频资源</a><br>秋兰作佩:视频图像处理教学</p>\n<p><a href=\"https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/1-1-why/\" target=\"_blank\" rel=\"noopener\">莫凡python</a><br>偏向于实践手把手教学</p>\n<p><a href=\"http://wims.math.ecnu.edu.cn/ChunLi/\" target=\"_blank\" rel=\"noopener\">华东师范公开课</a><br>陆吾生最优化和稀疏感知课程</p>\n<p><a href=\"http://muchong.com/guide.php\" target=\"_blank\" rel=\"noopener\">小木虫</a><br>学术交流</p>\n<p>/%%%</p>\n<h2 id=\"技术\"><a href=\"#技术\" class=\"headerlink\" title=\"技术\"></a>技术</h2><p>%%%</p>\n<p><a href=\"https://www.imooc.com/course/list?c=deep\" target=\"_blank\" rel=\"noopener\">慕课网</a><br>程序员充电，包含深度学习</p>\n<p><a href=\"https://www.w3cschool.cn/\" target=\"_blank\" rel=\"noopener\">W3C学院</a><br>w3cschool:例子丰富</p>\n<p><a href=\"https://github.com/\" target=\"_blank\" rel=\"noopener\">Gayhub</a><br>github:最大的开源社区</p>\n<p><a href=\"http://www.pudn.com/\" target=\"_blank\" rel=\"noopener\">联合开发网</a><br>上传一份代码有30次下载机会</p>\n<p><a href=\"https://blog.csdn.net/u011014502\" target=\"_blank\" rel=\"noopener\">CSDN博客</a><br>CSDN:博客,咕咕咕</p>\n<p>/%%%</p>\n<h2 id=\"资源\"><a href=\"#资源\" class=\"headerlink\" title=\"资源\"></a>资源</h2><p>%%%</p>\n<p><a href=\"http://www.panduoduo.net/\" target=\"_blank\" rel=\"noopener\">网盘搜索</a><br>盘多多:不是盘夕夕</p>\n<p><a href=\"http://www.tebaidu.com/file-56956d74a355d2e8776bedffaa197d1112967444.html\" target=\"_blank\" rel=\"noopener\">网盘搜索</a><br>特百度:和多多一起辅助找资料</p>\n<p><a href=\"https://webdemo.myscript.com/views/main/math.html\" target=\"_blank\" rel=\"noopener\">手写latex</a><br>myscript:手写公式转latex</p>\n<p><a href=\"https://pan.baidu.com/s/1a4WOZLCSFNzGVX082iKe0w\" target=\"_blank\" rel=\"noopener\">预训练模型</a><br>百度云:keras模型（密码：3gs8）</p>\n<p><a href=\"https://pan.baidu.com/s/19RXTyHqWMftsehs7Th5qcA\" target=\"_blank\" rel=\"noopener\">吴恩达机器学习</a><br>百度云:视频+讲义（密码：q46u）</p>\n<p><a href=\"https://pan.baidu.com/s/1S6Uksg0te4tKHzxQw0z7kw\" target=\"_blank\" rel=\"noopener\">IDA7.0</a><br>百度云:静态分析神器（密码：i5qf）</p>\n<p><a href=\"http://www.tup.tsinghua.edu.cn/booksCenter/book_07482601.html\" target=\"_blank\" rel=\"noopener\">图书代码下载</a><br>清华大学出版社:很多书有资源下载</p>\n<p><a href=\"https://ark.intel.com/zh-cn/products/series/122593/-i7-\" target=\"_blank\" rel=\"noopener\">cpu参数</a><br>INTEL:详细参数和选型</p>\n<p><a href=\"https://msdn.itellyou.cn/\" target=\"_blank\" rel=\"noopener\">微软订阅</a><br>ITellYou:office、windows、vs2019</p>\n<p><a href=\"https://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html\" target=\"_blank\" rel=\"noopener\">Linux软件包</a><br>pkgs:安装低版本软件，下载方便</p>\n<p><a href=\"https://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy\" target=\"_blank\" rel=\"noopener\">pipy软件包</a><br>lfd.uci:numpy-mkl等python软件包</p>\n<p><a href=\"https://www.sojson.com/web/img.html\" target=\"_blank\" rel=\"noopener\">传图识色</a><br>能识别图片的主要颜色值</p>\n<p><a href=\"http://www.gpsspg.com/maps.htm\" target=\"_blank\" rel=\"noopener\">坐标拾取</a><br>支持谷歌、百度、腾讯/高德、图吧</p>\n<p><a href=\"https://reference.wolfram.com/language/ref/InverseDistanceTransform.html\" target=\"_blank\" rel=\"noopener\">wolfram</a><br>统一符号语言读取的大量内置算法和知识</p>\n<p>/%%%</p>\n<h2 id=\"我是购物狂\"><a href=\"#我是购物狂\" class=\"headerlink\" title=\"我是购物狂\"></a>我是购物狂</h2><p>%%%</p>\n<p><a href=\"https://item.jd.com/12401859.html\" target=\"_blank\" rel=\"noopener\">百面机器学习</a><br>京东:百面机器学习</p>\n<p><a href=\"https://item.jd.com/12360850.html\" target=\"_blank\" rel=\"noopener\">教你设计CPU</a><br>京东:RISC-V是当前比较火的架构</p>\n<p><a href=\"https://item.taobao.com/item.htm?id=573670462932\" target=\"_blank\" rel=\"noopener\">荔枝糖</a><br>能跑RISC-V的FPGA的开发板</p>\n<p><a href=\"https://item.taobao.com/item.htm?id=578484113485\" target=\"_blank\" rel=\"noopener\">荔枝丹</a><br>能跑yolo的risc-v的开发板，堪智K210</p>\n<p>/%%%</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"学术\"><a href=\"#学术\" class=\"headerlink\" title=\"学术\"></a>学术</h3><p>%%%</p>\n<p><a href=\"http://nav.hiqq.com.cn/txs/?q=deep%20learning\" target=\"_blank\" rel=\"noopener\">学术论文搜索</a><br>hiqq:集合百度、谷歌、CNKI、SCI</p>\n<p><a href=\"http://gen.lib.rus.ec/search.php?req=risc+v&amp;open=0&amp;res=25&amp;view=simple&amp;phrase=1&amp;column=def\" target=\"_blank\" rel=\"noopener\">专著下载</a><br>Library Genesis:英文版，收录全</p>\n<p><a href=\"http://sci-hub.tw/\" target=\"_blank\" rel=\"noopener\">全能论文下载</a><br>SCI-HUB:且用且珍惜</p>\n<p><a href=\"http://xueshu.baidu.com/\" target=\"_blank\" rel=\"noopener\">百度学术</a><br>保持学习态度</p>\n<p><a href=\"http://pss-system.cnipa.gov.cn/sipopublicsearch/portal/uiIndex.shtml\" target=\"_blank\" rel=\"noopener\">专利检索</a><br>需要登录，可下载全文</p>\n<p><a href=\"https://www.kaggle.com/competitions\" target=\"_blank\" rel=\"noopener\">算法竞赛</a><br>kaggle:最大的竞赛平台，奖金丰厚</p>\n<p><a href=\"http://www.physionet.org/physiobank/database/#ecg\" target=\"_blank\" rel=\"noopener\">生理数据数据库</a><br>physionet:ECG信号下载</p>\n<p><a href=\"https://www.coursera.org/\" target=\"_blank\" rel=\"noopener\">公开课教学</a><br>coursera:快来学习，充实自己</p>\n<p><a href=\"http://cn.udacity.com/course/intro-to-self-driving-cars--nd113-cn\" target=\"_blank\" rel=\"noopener\">优达学城</a><br>udacity:硅谷前沿技术学习平台</p>\n<p><a href=\"https://space.bilibili.com/8431135/#/\" target=\"_blank\" rel=\"noopener\">b站视频资源</a><br>neophack:过气up主</p>\n<p><a href=\"https://space.bilibili.com/209599371/#/\" target=\"_blank\" rel=\"noopener\">b站视频资源</a><br>李沐:MXNET视频教程</p>\n<p><a href=\"https://space.bilibili.com/12430528/#/\" target=\"_blank\" rel=\"noopener\">b站视频资源</a><br>宫帅USTC:很多最新深度学习分享</p>\n<p><a href=\"https://space.bilibili.com/19062251/#/\" target=\"_blank\" rel=\"noopener\">b站视频资源</a><br>秋兰作佩:视频图像处理教学</p>\n<p><a href=\"https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/1-1-why/\" target=\"_blank\" rel=\"noopener\">莫凡python</a><br>偏向于实践手把手教学</p>\n<p><a href=\"http://wims.math.ecnu.edu.cn/ChunLi/\" target=\"_blank\" rel=\"noopener\">华东师范公开课</a><br>陆吾生最优化和稀疏感知课程</p>\n<p><a href=\"http://muchong.com/guide.php\" target=\"_blank\" rel=\"noopener\">小木虫</a><br>学术交流</p>\n<p>/%%%</p>\n<h2 id=\"技术\"><a href=\"#技术\" class=\"headerlink\" title=\"技术\"></a>技术</h2><p>%%%</p>\n<p><a href=\"https://www.imooc.com/course/list?c=deep\" target=\"_blank\" rel=\"noopener\">慕课网</a><br>程序员充电，包含深度学习</p>\n<p><a href=\"https://www.w3cschool.cn/\" target=\"_blank\" rel=\"noopener\">W3C学院</a><br>w3cschool:例子丰富</p>\n<p><a href=\"https://github.com/\" target=\"_blank\" rel=\"noopener\">Gayhub</a><br>github:最大的开源社区</p>\n<p><a href=\"http://www.pudn.com/\" target=\"_blank\" rel=\"noopener\">联合开发网</a><br>上传一份代码有30次下载机会</p>\n<p><a href=\"https://blog.csdn.net/u011014502\" target=\"_blank\" rel=\"noopener\">CSDN博客</a><br>CSDN:博客,咕咕咕</p>\n<p>/%%%</p>\n<h2 id=\"资源\"><a href=\"#资源\" class=\"headerlink\" title=\"资源\"></a>资源</h2><p>%%%</p>\n<p><a href=\"http://www.panduoduo.net/\" target=\"_blank\" rel=\"noopener\">网盘搜索</a><br>盘多多:不是盘夕夕</p>\n<p><a href=\"http://www.tebaidu.com/file-56956d74a355d2e8776bedffaa197d1112967444.html\" target=\"_blank\" rel=\"noopener\">网盘搜索</a><br>特百度:和多多一起辅助找资料</p>\n<p><a href=\"https://webdemo.myscript.com/views/main/math.html\" target=\"_blank\" rel=\"noopener\">手写latex</a><br>myscript:手写公式转latex</p>\n<p><a href=\"https://pan.baidu.com/s/1a4WOZLCSFNzGVX082iKe0w\" target=\"_blank\" rel=\"noopener\">预训练模型</a><br>百度云:keras模型（密码：3gs8）</p>\n<p><a href=\"https://pan.baidu.com/s/19RXTyHqWMftsehs7Th5qcA\" target=\"_blank\" rel=\"noopener\">吴恩达机器学习</a><br>百度云:视频+讲义（密码：q46u）</p>\n<p><a href=\"https://pan.baidu.com/s/1S6Uksg0te4tKHzxQw0z7kw\" target=\"_blank\" rel=\"noopener\">IDA7.0</a><br>百度云:静态分析神器（密码：i5qf）</p>\n<p><a href=\"http://www.tup.tsinghua.edu.cn/booksCenter/book_07482601.html\" target=\"_blank\" rel=\"noopener\">图书代码下载</a><br>清华大学出版社:很多书有资源下载</p>\n<p><a href=\"https://ark.intel.com/zh-cn/products/series/122593/-i7-\" target=\"_blank\" rel=\"noopener\">cpu参数</a><br>INTEL:详细参数和选型</p>\n<p><a href=\"https://msdn.itellyou.cn/\" target=\"_blank\" rel=\"noopener\">微软订阅</a><br>ITellYou:office、windows、vs2019</p>\n<p><a href=\"https://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html\" target=\"_blank\" rel=\"noopener\">Linux软件包</a><br>pkgs:安装低版本软件，下载方便</p>\n<p><a href=\"https://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy\" target=\"_blank\" rel=\"noopener\">pipy软件包</a><br>lfd.uci:numpy-mkl等python软件包</p>\n<p><a href=\"https://www.sojson.com/web/img.html\" target=\"_blank\" rel=\"noopener\">传图识色</a><br>能识别图片的主要颜色值</p>\n<p><a href=\"http://www.gpsspg.com/maps.htm\" target=\"_blank\" rel=\"noopener\">坐标拾取</a><br>支持谷歌、百度、腾讯/高德、图吧</p>\n<p><a href=\"https://reference.wolfram.com/language/ref/InverseDistanceTransform.html\" target=\"_blank\" rel=\"noopener\">wolfram</a><br>统一符号语言读取的大量内置算法和知识</p>\n<p>/%%%</p>\n<h2 id=\"我是购物狂\"><a href=\"#我是购物狂\" class=\"headerlink\" title=\"我是购物狂\"></a>我是购物狂</h2><p>%%%</p>\n<p><a href=\"https://item.jd.com/12401859.html\" target=\"_blank\" rel=\"noopener\">百面机器学习</a><br>京东:百面机器学习</p>\n<p><a href=\"https://item.jd.com/12360850.html\" target=\"_blank\" rel=\"noopener\">教你设计CPU</a><br>京东:RISC-V是当前比较火的架构</p>\n<p><a href=\"https://item.taobao.com/item.htm?id=573670462932\" target=\"_blank\" rel=\"noopener\">荔枝糖</a><br>能跑RISC-V的FPGA的开发板</p>\n<p><a href=\"https://item.taobao.com/item.htm?id=578484113485\" target=\"_blank\" rel=\"noopener\">荔枝丹</a><br>能跑yolo的risc-v的开发板，堪智K210</p>\n<p>/%%%</p>\n"}],"Post":[{"title":"Ubuntu18.04LTS+cuda9.0+caffe(old repo老版本)安装踩坑","date":"2018-10-30T12:15:51.000Z","_content":"在Ubuntu上安装cuda9.0，并配置caffe环境，caffe为2016年的版本，由于改动太多，移植到新版麻烦，这里就安装教程和遇到问题做一些记录\n\n<!-- more -->\n\n\n### 1.常用编译需要的软件\n首先安装必要软件\n```bash\nsudo apt install make cmake\n```\n\n编译GPU版需要安装驱动\n```bash\nchmod 777 NVIDIA-Linux-x86_64-410.73.run\nsudo ./NVIDIA-Linux-x86_64-410.73.run --no-opengl-files\n# --no-opengl-files适合笔记本用户安装，可以防止桌面分辨率异常，台式机可以不加\nchmod 777 cuda_9.0.176_384.81_linux.run\nsudo ./cuda_9.0.176_384.81_linux.run\n# cuda安装时候提示安装驱动，选n\n```\n\n### 2.安装caffe需要的库\n```bash\nsudo apt install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\nsudo apt install --no-install-recommends libboost-all-dev\nsudo apt install libatlas-base-dev\nsudo apt install libgflags-dev libgoogle-glog-dev liblmdb-dev\n```\n### 3.根据自己配置修改Makefile.config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA_ARCH 中的20和21两行\n\n### 4.编译\n\n```bash\nmake all\n```\n\n# 注意\n\n### 1 如果报错如下，protobuf版本不一致\n\n    .build_release/src/caffe/proto/caffe.pb.h:17:2: error: #error This file was generated by an older version of protoc which is\n\n默认protobuf为3.0版本，旧版2.5版本安装如下 \n```bash\nwget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf8_2.5.0-9ubuntu1_amd64.deb\nwget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb\nwget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-dev_2.5.0-9ubuntu1_amd64.deb\nsudo dpkg -i libprotobuf8_2.5.0-9ubuntu1_amd64.deb libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb libprotobuf-dev_2.5.0-9ubuntu1_amd64.deb\n```\n\n更多库下载\n\nhttps://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html\n\n\n### 2 如果报错如下，为g++版本不兼容\n\n    src/caffe/layers/contrastive_loss_layer.cpp:56:30: error: no matching function for call to ‘max(float, double)’\n\n     Dtype dist = std::max(margin - sqrt(dist_sq_.cpu_data()[i]), 0.0);\n\n通过安装低版本gcc g++解决\n```bash\nsudo apt install gcc-4.8 g++-4.8\ncd /usr/bin\nsudo ln -s gcc-4.8 gcc\nsudo ln -s g++-4.8 g++\n```\n\n### 3 如果报错如下，anaconda库冲突\n\n    CXX/LD -o .build_release/tools/upgrade_net_proto_text.bin\n    .build_release/tools/upgrade_net_proto_text.o: In function `main':\n    /usr/include/c++/5/bits/basic_string.tcc:219: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_create(unsigned long&, unsigned long)'\n    /usr/lib/gcc/x86_64-linux-gnu/5/../../../x86_64-linux-gnu/libglog.so: undefined reference to `vtable for std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'\n\n 在makefile.config修改include路径lib路径等，编译pycaffe时再添加Python的include路径lib路径\n```bash\n# Whatever else you find you need goes here.\n#INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include $(CUDNN_PATH)\n#LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib $(CUDNN_PATH)\nINCLUDE_DIRS := /usr/local/include /usr/include/hdf5/serial /usr/include/python2.7 $(CUDNN_PATH)\nLIBRARY_DIRS := /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial $(CUDNN_PATH)\n```\n\n### 4 cublas报错\n\n    F1030 16:15:43.990840  1937 math_functions.cu:28] Check failed: status == CUBLAS_STATUS_SUCCESS (13 vs. 0)  CUBLAS_STATUS_EXECUTION_FAILED\n\n安装CUDA9.0会出现以上错误\n\n通过安装补丁[Patch 2 (Released Mar 5, 2018)](https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1704&target_type=runfilelocal)解决\n\n# 训练模型\n![caffe-train](/imgs/2018-10-30-caffe-train.jpg)\n![GPU](/imgs/2018-10-30-nvidia-smi.jpg)\n \n\n声明：如有错误或者侵权请邮箱联系我","source":"_posts/caffe-cuda9-ubuntu1804.md","raw":"---\ntitle: Ubuntu18.04LTS+cuda9.0+caffe(old repo老版本)安装踩坑\ndate: 2018-10-30 20:15:51\ntags: caffe配置\ncategories: 深度学习\n---\n在Ubuntu上安装cuda9.0，并配置caffe环境，caffe为2016年的版本，由于改动太多，移植到新版麻烦，这里就安装教程和遇到问题做一些记录\n\n<!-- more -->\n\n\n### 1.常用编译需要的软件\n首先安装必要软件\n```bash\nsudo apt install make cmake\n```\n\n编译GPU版需要安装驱动\n```bash\nchmod 777 NVIDIA-Linux-x86_64-410.73.run\nsudo ./NVIDIA-Linux-x86_64-410.73.run --no-opengl-files\n# --no-opengl-files适合笔记本用户安装，可以防止桌面分辨率异常，台式机可以不加\nchmod 777 cuda_9.0.176_384.81_linux.run\nsudo ./cuda_9.0.176_384.81_linux.run\n# cuda安装时候提示安装驱动，选n\n```\n\n### 2.安装caffe需要的库\n```bash\nsudo apt install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\nsudo apt install --no-install-recommends libboost-all-dev\nsudo apt install libatlas-base-dev\nsudo apt install libgflags-dev libgoogle-glog-dev liblmdb-dev\n```\n### 3.根据自己配置修改Makefile.config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA_ARCH 中的20和21两行\n\n### 4.编译\n\n```bash\nmake all\n```\n\n# 注意\n\n### 1 如果报错如下，protobuf版本不一致\n\n    .build_release/src/caffe/proto/caffe.pb.h:17:2: error: #error This file was generated by an older version of protoc which is\n\n默认protobuf为3.0版本，旧版2.5版本安装如下 \n```bash\nwget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf8_2.5.0-9ubuntu1_amd64.deb\nwget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb\nwget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-dev_2.5.0-9ubuntu1_amd64.deb\nsudo dpkg -i libprotobuf8_2.5.0-9ubuntu1_amd64.deb libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb libprotobuf-dev_2.5.0-9ubuntu1_amd64.deb\n```\n\n更多库下载\n\nhttps://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html\n\n\n### 2 如果报错如下，为g++版本不兼容\n\n    src/caffe/layers/contrastive_loss_layer.cpp:56:30: error: no matching function for call to ‘max(float, double)’\n\n     Dtype dist = std::max(margin - sqrt(dist_sq_.cpu_data()[i]), 0.0);\n\n通过安装低版本gcc g++解决\n```bash\nsudo apt install gcc-4.8 g++-4.8\ncd /usr/bin\nsudo ln -s gcc-4.8 gcc\nsudo ln -s g++-4.8 g++\n```\n\n### 3 如果报错如下，anaconda库冲突\n\n    CXX/LD -o .build_release/tools/upgrade_net_proto_text.bin\n    .build_release/tools/upgrade_net_proto_text.o: In function `main':\n    /usr/include/c++/5/bits/basic_string.tcc:219: undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_create(unsigned long&, unsigned long)'\n    /usr/lib/gcc/x86_64-linux-gnu/5/../../../x86_64-linux-gnu/libglog.so: undefined reference to `vtable for std::__cxx11::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4.21'\n\n 在makefile.config修改include路径lib路径等，编译pycaffe时再添加Python的include路径lib路径\n```bash\n# Whatever else you find you need goes here.\n#INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include $(CUDNN_PATH)\n#LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib $(CUDNN_PATH)\nINCLUDE_DIRS := /usr/local/include /usr/include/hdf5/serial /usr/include/python2.7 $(CUDNN_PATH)\nLIBRARY_DIRS := /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial $(CUDNN_PATH)\n```\n\n### 4 cublas报错\n\n    F1030 16:15:43.990840  1937 math_functions.cu:28] Check failed: status == CUBLAS_STATUS_SUCCESS (13 vs. 0)  CUBLAS_STATUS_EXECUTION_FAILED\n\n安装CUDA9.0会出现以上错误\n\n通过安装补丁[Patch 2 (Released Mar 5, 2018)](https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1704&target_type=runfilelocal)解决\n\n# 训练模型\n![caffe-train](/imgs/2018-10-30-caffe-train.jpg)\n![GPU](/imgs/2018-10-30-nvidia-smi.jpg)\n \n\n声明：如有错误或者侵权请邮箱联系我","slug":"caffe-cuda9-ubuntu1804","published":1,"updated":"2019-04-13T01:52:14.044Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3i2nlgo0000axsitfcc39n6","content":"<p>在Ubuntu上安装cuda9.0，并配置caffe环境，caffe为2016年的版本，由于改动太多，移植到新版麻烦，这里就安装教程和遇到问题做一些记录</p>\n<a id=\"more\"></a>\n<h3 id=\"1-常用编译需要的软件\"><a href=\"#1-常用编译需要的软件\" class=\"headerlink\" title=\"1.常用编译需要的软件\"></a>1.常用编译需要的软件</h3><p>首先安装必要软件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install make cmake</span><br></pre></td></tr></table></figure></p>\n<p>编译GPU版需要安装驱动<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod 777 NVIDIA-Linux-x86_64-410.73.run</span><br><span class=\"line\">sudo ./NVIDIA-Linux-x86_64-410.73.run --no-opengl-files</span><br><span class=\"line\"><span class=\"comment\"># --no-opengl-files适合笔记本用户安装，可以防止桌面分辨率异常，台式机可以不加</span></span><br><span class=\"line\">chmod 777 cuda_9.0.176_384.81_linux.run</span><br><span class=\"line\">sudo ./cuda_9.0.176_384.81_linux.run</span><br><span class=\"line\"><span class=\"comment\"># cuda安装时候提示安装驱动，选n</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-安装caffe需要的库\"><a href=\"#2-安装caffe需要的库\" class=\"headerlink\" title=\"2.安装caffe需要的库\"></a>2.安装caffe需要的库</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler</span><br><span class=\"line\">sudo apt install --no-install-recommends libboost-all-dev</span><br><span class=\"line\">sudo apt install libatlas-base-dev</span><br><span class=\"line\">sudo apt install libgflags-dev libgoogle-glog-dev liblmdb-dev</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-根据自己配置修改Makefile-config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA-ARCH-中的20和21两行\"><a href=\"#3-根据自己配置修改Makefile-config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA-ARCH-中的20和21两行\" class=\"headerlink\" title=\"3.根据自己配置修改Makefile.config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA_ARCH 中的20和21两行\"></a>3.根据自己配置修改Makefile.config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA_ARCH 中的20和21两行</h3><h3 id=\"4-编译\"><a href=\"#4-编译\" class=\"headerlink\" title=\"4.编译\"></a>4.编译</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make all</span><br></pre></td></tr></table></figure>\n<h1 id=\"注意\"><a href=\"#注意\" class=\"headerlink\" title=\"注意\"></a>注意</h1><h3 id=\"1-如果报错如下，protobuf版本不一致\"><a href=\"#1-如果报错如下，protobuf版本不一致\" class=\"headerlink\" title=\"1 如果报错如下，protobuf版本不一致\"></a>1 如果报错如下，protobuf版本不一致</h3><pre><code>.build_release/src/caffe/proto/caffe.pb.h:17:2: error: #error This file was generated by an older version of protoc which is\n</code></pre><p>默认protobuf为3.0版本，旧版2.5版本安装如下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf8_2.5.0-9ubuntu1_amd64.deb</span><br><span class=\"line\">wget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb</span><br><span class=\"line\">wget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-dev_2.5.0-9ubuntu1_amd64.deb</span><br><span class=\"line\">sudo dpkg -i libprotobuf8_2.5.0-9ubuntu1_amd64.deb libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb libprotobuf-dev_2.5.0-9ubuntu1_amd64.deb</span><br></pre></td></tr></table></figure></p>\n<p>更多库下载</p>\n<p><a href=\"https://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html\" target=\"_blank\" rel=\"noopener\">https://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html</a></p>\n<h3 id=\"2-如果报错如下，为g-版本不兼容\"><a href=\"#2-如果报错如下，为g-版本不兼容\" class=\"headerlink\" title=\"2 如果报错如下，为g++版本不兼容\"></a>2 如果报错如下，为g++版本不兼容</h3><pre><code>src/caffe/layers/contrastive_loss_layer.cpp:56:30: error: no matching function for call to ‘max(float, double)’\n\n Dtype dist = std::max(margin - sqrt(dist_sq_.cpu_data()[i]), 0.0);\n</code></pre><p>通过安装低版本gcc g++解决<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install gcc-4.8 g++-4.8</span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/bin</span><br><span class=\"line\">sudo ln -s gcc-4.8 gcc</span><br><span class=\"line\">sudo ln -s g++-4.8 g++</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"3-如果报错如下，anaconda库冲突\"><a href=\"#3-如果报错如下，anaconda库冲突\" class=\"headerlink\" title=\"3 如果报错如下，anaconda库冲突\"></a>3 如果报错如下，anaconda库冲突</h3><pre><code>CXX/LD -o .build_release/tools/upgrade_net_proto_text.bin\n.build_release/tools/upgrade_net_proto_text.o: In function `main&apos;:\n/usr/include/c++/5/bits/basic_string.tcc:219: undefined reference to `std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_create(unsigned long&amp;, unsigned long)&apos;\n/usr/lib/gcc/x86_64-linux-gnu/5/../../../x86_64-linux-gnu/libglog.so: undefined reference to `vtable for std::__cxx11::basic_stringbuf&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;@GLIBCXX_3.4.21&apos;\n</code></pre><p> 在makefile.config修改include路径lib路径等，编译pycaffe时再添加Python的include路径lib路径<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Whatever else you find you need goes here.</span></span><br><span class=\"line\"><span class=\"comment\">#INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include $(CUDNN_PATH)</span></span><br><span class=\"line\"><span class=\"comment\">#LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib $(CUDNN_PATH)</span></span><br><span class=\"line\">INCLUDE_DIRS := /usr/<span class=\"built_in\">local</span>/include /usr/include/hdf5/serial /usr/include/python2.7 $(CUDNN_PATH)</span><br><span class=\"line\">LIBRARY_DIRS := /usr/<span class=\"built_in\">local</span>/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial $(CUDNN_PATH)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"4-cublas报错\"><a href=\"#4-cublas报错\" class=\"headerlink\" title=\"4 cublas报错\"></a>4 cublas报错</h3><pre><code>F1030 16:15:43.990840  1937 math_functions.cu:28] Check failed: status == CUBLAS_STATUS_SUCCESS (13 vs. 0)  CUBLAS_STATUS_EXECUTION_FAILED\n</code></pre><p>安装CUDA9.0会出现以上错误</p>\n<p>通过安装补丁<a href=\"https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1704&amp;target_type=runfilelocal\" target=\"_blank\" rel=\"noopener\">Patch 2 (Released Mar 5, 2018)</a>解决</p>\n<h1 id=\"训练模型\"><a href=\"#训练模型\" class=\"headerlink\" title=\"训练模型\"></a>训练模型</h1><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"/imgs/2018-10-30-caffe-train.jpg\" alt=\"caffe-train\" title>\n                </div>\n                <div class=\"image-caption\">caffe-train</div>\n            </figure>\n<figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"/imgs/2018-10-30-nvidia-smi.jpg\" alt=\"GPU\" title>\n                </div>\n                <div class=\"image-caption\">GPU</div>\n            </figure>\n<p>声明：如有错误或者侵权请邮箱联系我</p>\n","site":{"data":{}},"excerpt":"<p>在Ubuntu上安装cuda9.0，并配置caffe环境，caffe为2016年的版本，由于改动太多，移植到新版麻烦，这里就安装教程和遇到问题做一些记录</p>","more":"<h3 id=\"1-常用编译需要的软件\"><a href=\"#1-常用编译需要的软件\" class=\"headerlink\" title=\"1.常用编译需要的软件\"></a>1.常用编译需要的软件</h3><p>首先安装必要软件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install make cmake</span><br></pre></td></tr></table></figure></p>\n<p>编译GPU版需要安装驱动<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod 777 NVIDIA-Linux-x86_64-410.73.run</span><br><span class=\"line\">sudo ./NVIDIA-Linux-x86_64-410.73.run --no-opengl-files</span><br><span class=\"line\"><span class=\"comment\"># --no-opengl-files适合笔记本用户安装，可以防止桌面分辨率异常，台式机可以不加</span></span><br><span class=\"line\">chmod 777 cuda_9.0.176_384.81_linux.run</span><br><span class=\"line\">sudo ./cuda_9.0.176_384.81_linux.run</span><br><span class=\"line\"><span class=\"comment\"># cuda安装时候提示安装驱动，选n</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-安装caffe需要的库\"><a href=\"#2-安装caffe需要的库\" class=\"headerlink\" title=\"2.安装caffe需要的库\"></a>2.安装caffe需要的库</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler</span><br><span class=\"line\">sudo apt install --no-install-recommends libboost-all-dev</span><br><span class=\"line\">sudo apt install libatlas-base-dev</span><br><span class=\"line\">sudo apt install libgflags-dev libgoogle-glog-dev liblmdb-dev</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-根据自己配置修改Makefile-config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA-ARCH-中的20和21两行\"><a href=\"#3-根据自己配置修改Makefile-config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA-ARCH-中的20和21两行\" class=\"headerlink\" title=\"3.根据自己配置修改Makefile.config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA_ARCH 中的20和21两行\"></a>3.根据自己配置修改Makefile.config，主要是是否使用cudnn、仅使用CPU、cuda9注意删除CUDA_ARCH 中的20和21两行</h3><h3 id=\"4-编译\"><a href=\"#4-编译\" class=\"headerlink\" title=\"4.编译\"></a>4.编译</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make all</span><br></pre></td></tr></table></figure>\n<h1 id=\"注意\"><a href=\"#注意\" class=\"headerlink\" title=\"注意\"></a>注意</h1><h3 id=\"1-如果报错如下，protobuf版本不一致\"><a href=\"#1-如果报错如下，protobuf版本不一致\" class=\"headerlink\" title=\"1 如果报错如下，protobuf版本不一致\"></a>1 如果报错如下，protobuf版本不一致</h3><pre><code>.build_release/src/caffe/proto/caffe.pb.h:17:2: error: #error This file was generated by an older version of protoc which is\n</code></pre><p>默认protobuf为3.0版本，旧版2.5版本安装如下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf8_2.5.0-9ubuntu1_amd64.deb</span><br><span class=\"line\">wget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb</span><br><span class=\"line\">wget http://archive.ubuntu.com/ubuntu/pool/main/p/protobuf/libprotobuf-dev_2.5.0-9ubuntu1_amd64.deb</span><br><span class=\"line\">sudo dpkg -i libprotobuf8_2.5.0-9ubuntu1_amd64.deb libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb libprotobuf-dev_2.5.0-9ubuntu1_amd64.deb</span><br></pre></td></tr></table></figure></p>\n<p>更多库下载</p>\n<p><a href=\"https://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html\" target=\"_blank\" rel=\"noopener\">https://ubuntu.pkgs.org/14.04/ubuntu-main-amd64/libprotobuf-lite8_2.5.0-9ubuntu1_amd64.deb.html</a></p>\n<h3 id=\"2-如果报错如下，为g-版本不兼容\"><a href=\"#2-如果报错如下，为g-版本不兼容\" class=\"headerlink\" title=\"2 如果报错如下，为g++版本不兼容\"></a>2 如果报错如下，为g++版本不兼容</h3><pre><code>src/caffe/layers/contrastive_loss_layer.cpp:56:30: error: no matching function for call to ‘max(float, double)’\n\n Dtype dist = std::max(margin - sqrt(dist_sq_.cpu_data()[i]), 0.0);\n</code></pre><p>通过安装低版本gcc g++解决<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install gcc-4.8 g++-4.8</span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/bin</span><br><span class=\"line\">sudo ln -s gcc-4.8 gcc</span><br><span class=\"line\">sudo ln -s g++-4.8 g++</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"3-如果报错如下，anaconda库冲突\"><a href=\"#3-如果报错如下，anaconda库冲突\" class=\"headerlink\" title=\"3 如果报错如下，anaconda库冲突\"></a>3 如果报错如下，anaconda库冲突</h3><pre><code>CXX/LD -o .build_release/tools/upgrade_net_proto_text.bin\n.build_release/tools/upgrade_net_proto_text.o: In function `main&apos;:\n/usr/include/c++/5/bits/basic_string.tcc:219: undefined reference to `std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_create(unsigned long&amp;, unsigned long)&apos;\n/usr/lib/gcc/x86_64-linux-gnu/5/../../../x86_64-linux-gnu/libglog.so: undefined reference to `vtable for std::__cxx11::basic_stringbuf&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;@GLIBCXX_3.4.21&apos;\n</code></pre><p> 在makefile.config修改include路径lib路径等，编译pycaffe时再添加Python的include路径lib路径<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Whatever else you find you need goes here.</span></span><br><span class=\"line\"><span class=\"comment\">#INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include $(CUDNN_PATH)</span></span><br><span class=\"line\"><span class=\"comment\">#LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib $(CUDNN_PATH)</span></span><br><span class=\"line\">INCLUDE_DIRS := /usr/<span class=\"built_in\">local</span>/include /usr/include/hdf5/serial /usr/include/python2.7 $(CUDNN_PATH)</span><br><span class=\"line\">LIBRARY_DIRS := /usr/<span class=\"built_in\">local</span>/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial $(CUDNN_PATH)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"4-cublas报错\"><a href=\"#4-cublas报错\" class=\"headerlink\" title=\"4 cublas报错\"></a>4 cublas报错</h3><pre><code>F1030 16:15:43.990840  1937 math_functions.cu:28] Check failed: status == CUBLAS_STATUS_SUCCESS (13 vs. 0)  CUBLAS_STATUS_EXECUTION_FAILED\n</code></pre><p>安装CUDA9.0会出现以上错误</p>\n<p>通过安装补丁<a href=\"https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1704&amp;target_type=runfilelocal\" target=\"_blank\" rel=\"noopener\">Patch 2 (Released Mar 5, 2018)</a>解决</p>\n<h1 id=\"训练模型\"><a href=\"#训练模型\" class=\"headerlink\" title=\"训练模型\"></a>训练模型</h1><figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"/imgs/2018-10-30-caffe-train.jpg\" alt=\"caffe-train\" title>\n                </div>\n                <div class=\"image-caption\">caffe-train</div>\n            </figure>\n<figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"/imgs/2018-10-30-nvidia-smi.jpg\" alt=\"GPU\" title>\n                </div>\n                <div class=\"image-caption\">GPU</div>\n            </figure>\n<p>声明：如有错误或者侵权请邮箱联系我</p>"},{"title":"深度学习常用标签转换","date":"2018-06-06T13:25:51.000Z","_content":"在处理coco数据、imageNet、VOC数据时，需要对数据标签进行转换，本文即提供转换代码\n\n<!-- more -->\n本文主要是对tencent 100k交通标志标记数据转换\n\n临时写的，代码很乱，需要根据实际路径修改\n\n数据下载： http://cg.cs.tsinghua.edu.cn/traffic-sign/tutorial.html\n\n\n\n### 加载标签\n```python\nimport json\nimport pylab as pl\nimport random\nimport numpy as np\nimport cv2\nimport anno_func\n%matplotlib inline\n\ndatadir = \"../../data/\"\n\nfiledir = datadir + \"/annotations.json\"\nids = open(datadir + \"/test/ids.txt\").read().splitlines()\n\nannos = json.loads(open(filedir).read())\n```\n### 分析结构\n```python\nimgid = random.sample(ids, 1)[0]\nimg=annos[\"imgs\"][imgid]\nprint (img)\nimg=annos[\"types\"]\nprint (img)\n```\n```\n{u'path': u'test/2468.jpg', u'objects': [{u'category': u'pn', u'bbox': {u'xmin': 1343.2, u'ymin': 911.2, u'ymax': 964.0, u'xmax': 1396.0}, u'ellipse_org': [[1367.87, 911.552], [1395.46, 937.913], [1368.33, 963.195], [1343.97, 936.988], [1353.99, 958.571], [1387.91, 957.183]], u'ellipse': [[1369.0028076171875, 937.2377319335938], [51.76936721801758, 52.934967041015625], 139.54888916015625]}, {u'category': u'pn', u'bbox': {u'xmin': 1197.6, u'ymin': 940.0, u'ymax': 963.2, u'xmax': 1220.8}, u'ellipse_org': [[1209.01, 940.921], [1219.11, 951.016], [1209.21, 961.043], [1199.25, 951.626], [1201.96, 944.986], [1201.22, 956.775], [1217.55, 945.799]], u'ellipse': [[1209.0211181640625, 950.5414428710938], [19.53607940673828, 21.289642333984375], 153.71450805664062]}, {u'category': u'p11', u'bbox': {u'xmin': 229.6, u'ymin': 963.2, u'ymax': 1008.8000000000001, u'xmax': 270.4}, u'ellipse_org': [[248.171, 963.658], [269.073, 986.158], [249.236, 1008.39], [231.395, 984.827], [262.816, 1002.0], [236.987, 1001.87], [263.881, 971.513]], u'ellipse': [[249.62039184570312, 985.5843505859375], [37.6942024230957, 44.657630920410156], 177.4745330810547]}, {u'category': u'pl10', u'bbox': {u'xmin': 235.2, u'ymin': 1009.6, u'ymax': 1056.8, u'xmax': 279.2}, u'ellipse_org': [[254.683, 1009.92], [277.41, 1032.51], [255.785, 1055.1], [235.813, 1031.96], [240.496, 1047.8], [239.945, 1018.6], [270.386, 1047.11], [271.488, 1017.49]], u'ellipse': [[255.57847595214844, 1031.8031005859375], [41.567535400390625, 45.633445739746094], 3.8224732875823975]}], u'id': 2468}\n[u'i1', u'i10', u'i11', u'i12', u'i13', u'i14', u'i15', u'i2', u'i3', u'i4', u'i5', u'il100', u'il110', u'il50', u'il60', u'il70', u'il80', u'il90', u'io', u'ip', u'p1', u'p10', u'p11', u'p12', u'p13', u'p14', u'p15', u'p16', u'p17', u'p18', u'p19', u'p2', u'p20', u'p21', u'p22', u'p23', u'p24', u'p25', u'p26', u'p27', u'p28', u'p3', u'p4', u'p5', u'p6', u'p7', u'p8', u'p9', u'pa10', u'pa12', u'pa13', u'pa14', u'pa8', u'pb', u'pc', u'pg', u'ph1.5', u'ph2', u'ph2.1', u'ph2.2', u'ph2.4', u'ph2.5', u'ph2.8', u'ph2.9', u'ph3', u'ph3.2', u'ph3.5', u'ph3.8', u'ph4', u'ph4.2', u'ph4.3', u'ph4.5', u'ph4.8', u'ph5', u'ph5.3', u'ph5.5', u'pl10', u'pl100', u'pl110', u'pl120', u'pl15', u'pl20', u'pl25', u'pl30', u'pl35', u'pl40', u'pl5', u'pl50', u'pl60', u'pl65', u'pl70', u'pl80', u'pl90', u'pm10', u'pm13', u'pm15', u'pm1.5', u'pm2', u'pm20', u'pm25', u'pm30', u'pm35', u'pm40', u'pm46', u'pm5', u'pm50', u'pm55', u'pm8', u'pn', u'pne', u'po', u'pr10', u'pr100', u'pr20', u'pr30', u'pr40', u'pr45', u'pr50', u'pr60', u'pr70', u'pr80', u'ps', u'pw2', u'pw2.5', u'pw3', u'pw3.2', u'pw3.5', u'pw4', u'pw4.2', u'pw4.5', u'w1', u'w10', u'w12', u'w13', u'w16', u'w18', u'w20', u'w21', u'w22', u'w24', u'w28', u'w3', u'w30', u'w31', u'w32', u'w34', u'w35', u'w37', u'w38', u'w41', u'w42', u'w43', u'w44', u'w45', u'w46', u'w47', u'w48', u'w49', u'w5', u'w50', u'w55', u'w56', u'w57', u'w58', u'w59', u'w60', u'w62', u'w63', u'w66', u'w8', u'wo', u'i6', u'i7', u'i8', u'i9', u'ilx', u'p29', u'w29', u'w33', u'w36', u'w39', u'w4', u'w40', u'w51', u'w52', u'w53', u'w54', u'w6', u'w61', u'w64', u'w65', u'w67', u'w7', u'w9', u'pax', u'pd', u'pe', u'phx', u'plx', u'pmx', u'pnl', u'prx', u'pwx', u'w11', u'w14', u'w15', u'w17', u'w19', u'w2', u'w23', u'w25', u'w26', u'w27', u'pl0', u'pl4', u'pl3', u'pm2.5', u'ph4.4', u'pn40', u'ph3.3', u'ph2.6']\n```\n\n### 转换txt\n```python\ncnt=0\nresultlistfile=open('test.txt','w')\nidsfile=open('ids.txt','w')\nfor imgid in ids:\n    if int(imgid)<40000:\n        idsfile.write(imgid+'\\n')\n        img=annos[\"imgs\"][imgid]\n        cnt+=1\n        for obj in img['objects']:\n            box = obj['bbox']\n            ss = obj['category']\n            resstr=imgid+' '+ss+' '+str(box['xmin'])+' '+str(box['ymin'])+' '+str(box['xmax'])+' '+str(box['ymax'])+' 0 '+str(cnt)\n            resultlistfile.write(resstr+'\\n')\n            print (resstr)\n        \nidsfile.close()\nresultlistfile.close()\n```\n```\n\n10056 pne 414 877 431 909 0 1\n10056 i5 452 886 468 916 0 1\n10056 pne 1215 928 1237 950 0 1\n10056 i5 1274 927 1294 949 0 1\n10056 pne 2016 910 2032 934 0 1\n10063 pr20 1637 949 1678 1002 0 2\n10063 p27 1371 701 1426 759 0 2\n10063 po 1482 692 1543 753 0 2\n10063 pl40 1370 774 1422 834 0 2\n10063 ph4.5 1480 765 1543 828 0 2\n10128 pl40 1349 539 1450 643 0 3\n10128 p11 1476 545 1570 650 0 3\n10128 pn 1584 562 1684 662 0 3\n1012 pl30 645 516 735 603 0 4\n1012 pm20 742 512 837 600 0 4\n1012 p26 843 487 938 572 0 4\n1012 ph4.5 531 752 618 840 0 4\n1012 p9 529 847 621 941 0 4\n```\n### 转换json\n```python\nresultcont=open('test.txt','r')\n#print('namelist',resultcont)\nperid=''\nimgid=''\n# types=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]\n# trainotest='train'\nobjs=[]\nresults = {}\nfor resultline in resultcont.read().split('\\n'):\n    if resultline:\n        ressplit=resultline.split(' ')\n        if (not perid==ressplit[0]):\n            perid=ressplit[0]\n            \n            if (not imgid == ''):\n                #print(objs)\n                results[imgid] = {\"objects\":objs,\"id\":imgid,\"path\":\"\"+trainotest+\"/\"+imgid+\".jpg\"}\n            objs=[]\n        mobj = {\"bbox\":dict(zip([\"xmin\",\"ymin\",\"xmax\",\"ymax\"],\n                                [float(ressplit[2]),float(ressplit[3]),float(ressplit[4]),float(ressplit[5])])), \n                    \"category\":str(ressplit[1])}\n        objs.append(mobj)\n        #print(ressplit[2:6])\n        imgid=ressplit[0]\nresults[imgid] = {\"objects\":objs,\"id\":imgid,\"path\":\"\"+trainotest+\"/\"+imgid+\".jpg\"}\n\nresults_annos = {\"imgs\":results,\"types\":types}   \nprint (results_annos)\nopen(\"../../Src1/annotations.json\", \"w\").write(json.dumps(results_annos))\n```\n### json转voc\n```python\nimport json\nimport pylab as pl\nimport random\nimport numpy as np\nimport cv2\nimport anno_func\n%matplotlib inline\n\ndatadir = \"../../Src1/\"\ntrainotest='train'\nfiledir = datadir + \"/annotations.json\"\nids = open(datadir + \"/\"+trainotest+\"/ids.txt\").read().splitlines()\n\nannos = json.loads(open(filedir).read())\n\ncnt=0\nresultlistfile=open('test.txt','w')\nfor imgid in ids:\n    if int(imgid)<40000:\n        img=annos[\"imgs\"][imgid]\n        cnt+=1\n        node_root = Element('annotation')\n\n        node_folder = SubElement(node_root, 'folder')\n        node_folder.text = 'train'\n\n        node_filename = SubElement(node_root, 'filename')\n        node_filename.text = str(imgid)+'.jpg'\n        \n        node_filename = SubElement(node_root, 'path')\n        node_filename.text = datadir+trainotest+\"/\"+str(imgid)+'.jpg'\n\n        node_size = SubElement(node_root, 'size')\n        node_width = SubElement(node_size, 'width')\n        node_width.text = '2048'\n\n        node_height = SubElement(node_size, 'height')\n        node_height.text = '2048'\n\n        node_depth = SubElement(node_size, 'depth')\n        node_depth.text = '3'\n        \n        for obj in img['objects']:\n            box = obj['bbox']\n            ss = obj['category']\n            str(box['xmin'])+' '+str(box['ymin'])+' '+str(box['xmax'])+' '+str(box['ymax'])+' 0 '+str(cnt)\n            \n\n            node_object = SubElement(node_root, 'object')\n            node_name = SubElement(node_object, 'name')\n            node_name.text = ss\n            node_difficult = SubElement(node_object, 'difficult')\n            node_difficult.text = '0'\n            node_bndbox = SubElement(node_object, 'bndbox')\n            node_xmin = SubElement(node_bndbox, 'xmin')\n            node_xmin.text = str(int(box['xmin']))\n            node_ymin = SubElement(node_bndbox, 'ymin')\n            node_ymin.text = str(int(box['ymin']))\n            node_xmax = SubElement(node_bndbox, 'xmax')\n            node_xmax.text = str(int(box['xmax']))\n            node_ymax = SubElement(node_bndbox, 'ymax')\n            node_ymax.text = str(int(box['ymax']))\n\n        xml = tostring(node_root, pretty_print=True)  #格式化显示，该换行的换行\n        dom = parseString(xml)\n            #print xml\n        xmlfile=open(datadir+\"xml/\"+imgid+'.xml','w')\n        xmlfile.write(xml)\n\n```\n","source":"_posts/label-transfer.md","raw":"---\ntitle: 深度学习常用标签转换\ndate: 2018-06-06 21:25:51\ntags: 标签转换\ncategories: 深度学习\n---\n在处理coco数据、imageNet、VOC数据时，需要对数据标签进行转换，本文即提供转换代码\n\n<!-- more -->\n本文主要是对tencent 100k交通标志标记数据转换\n\n临时写的，代码很乱，需要根据实际路径修改\n\n数据下载： http://cg.cs.tsinghua.edu.cn/traffic-sign/tutorial.html\n\n\n\n### 加载标签\n```python\nimport json\nimport pylab as pl\nimport random\nimport numpy as np\nimport cv2\nimport anno_func\n%matplotlib inline\n\ndatadir = \"../../data/\"\n\nfiledir = datadir + \"/annotations.json\"\nids = open(datadir + \"/test/ids.txt\").read().splitlines()\n\nannos = json.loads(open(filedir).read())\n```\n### 分析结构\n```python\nimgid = random.sample(ids, 1)[0]\nimg=annos[\"imgs\"][imgid]\nprint (img)\nimg=annos[\"types\"]\nprint (img)\n```\n```\n{u'path': u'test/2468.jpg', u'objects': [{u'category': u'pn', u'bbox': {u'xmin': 1343.2, u'ymin': 911.2, u'ymax': 964.0, u'xmax': 1396.0}, u'ellipse_org': [[1367.87, 911.552], [1395.46, 937.913], [1368.33, 963.195], [1343.97, 936.988], [1353.99, 958.571], [1387.91, 957.183]], u'ellipse': [[1369.0028076171875, 937.2377319335938], [51.76936721801758, 52.934967041015625], 139.54888916015625]}, {u'category': u'pn', u'bbox': {u'xmin': 1197.6, u'ymin': 940.0, u'ymax': 963.2, u'xmax': 1220.8}, u'ellipse_org': [[1209.01, 940.921], [1219.11, 951.016], [1209.21, 961.043], [1199.25, 951.626], [1201.96, 944.986], [1201.22, 956.775], [1217.55, 945.799]], u'ellipse': [[1209.0211181640625, 950.5414428710938], [19.53607940673828, 21.289642333984375], 153.71450805664062]}, {u'category': u'p11', u'bbox': {u'xmin': 229.6, u'ymin': 963.2, u'ymax': 1008.8000000000001, u'xmax': 270.4}, u'ellipse_org': [[248.171, 963.658], [269.073, 986.158], [249.236, 1008.39], [231.395, 984.827], [262.816, 1002.0], [236.987, 1001.87], [263.881, 971.513]], u'ellipse': [[249.62039184570312, 985.5843505859375], [37.6942024230957, 44.657630920410156], 177.4745330810547]}, {u'category': u'pl10', u'bbox': {u'xmin': 235.2, u'ymin': 1009.6, u'ymax': 1056.8, u'xmax': 279.2}, u'ellipse_org': [[254.683, 1009.92], [277.41, 1032.51], [255.785, 1055.1], [235.813, 1031.96], [240.496, 1047.8], [239.945, 1018.6], [270.386, 1047.11], [271.488, 1017.49]], u'ellipse': [[255.57847595214844, 1031.8031005859375], [41.567535400390625, 45.633445739746094], 3.8224732875823975]}], u'id': 2468}\n[u'i1', u'i10', u'i11', u'i12', u'i13', u'i14', u'i15', u'i2', u'i3', u'i4', u'i5', u'il100', u'il110', u'il50', u'il60', u'il70', u'il80', u'il90', u'io', u'ip', u'p1', u'p10', u'p11', u'p12', u'p13', u'p14', u'p15', u'p16', u'p17', u'p18', u'p19', u'p2', u'p20', u'p21', u'p22', u'p23', u'p24', u'p25', u'p26', u'p27', u'p28', u'p3', u'p4', u'p5', u'p6', u'p7', u'p8', u'p9', u'pa10', u'pa12', u'pa13', u'pa14', u'pa8', u'pb', u'pc', u'pg', u'ph1.5', u'ph2', u'ph2.1', u'ph2.2', u'ph2.4', u'ph2.5', u'ph2.8', u'ph2.9', u'ph3', u'ph3.2', u'ph3.5', u'ph3.8', u'ph4', u'ph4.2', u'ph4.3', u'ph4.5', u'ph4.8', u'ph5', u'ph5.3', u'ph5.5', u'pl10', u'pl100', u'pl110', u'pl120', u'pl15', u'pl20', u'pl25', u'pl30', u'pl35', u'pl40', u'pl5', u'pl50', u'pl60', u'pl65', u'pl70', u'pl80', u'pl90', u'pm10', u'pm13', u'pm15', u'pm1.5', u'pm2', u'pm20', u'pm25', u'pm30', u'pm35', u'pm40', u'pm46', u'pm5', u'pm50', u'pm55', u'pm8', u'pn', u'pne', u'po', u'pr10', u'pr100', u'pr20', u'pr30', u'pr40', u'pr45', u'pr50', u'pr60', u'pr70', u'pr80', u'ps', u'pw2', u'pw2.5', u'pw3', u'pw3.2', u'pw3.5', u'pw4', u'pw4.2', u'pw4.5', u'w1', u'w10', u'w12', u'w13', u'w16', u'w18', u'w20', u'w21', u'w22', u'w24', u'w28', u'w3', u'w30', u'w31', u'w32', u'w34', u'w35', u'w37', u'w38', u'w41', u'w42', u'w43', u'w44', u'w45', u'w46', u'w47', u'w48', u'w49', u'w5', u'w50', u'w55', u'w56', u'w57', u'w58', u'w59', u'w60', u'w62', u'w63', u'w66', u'w8', u'wo', u'i6', u'i7', u'i8', u'i9', u'ilx', u'p29', u'w29', u'w33', u'w36', u'w39', u'w4', u'w40', u'w51', u'w52', u'w53', u'w54', u'w6', u'w61', u'w64', u'w65', u'w67', u'w7', u'w9', u'pax', u'pd', u'pe', u'phx', u'plx', u'pmx', u'pnl', u'prx', u'pwx', u'w11', u'w14', u'w15', u'w17', u'w19', u'w2', u'w23', u'w25', u'w26', u'w27', u'pl0', u'pl4', u'pl3', u'pm2.5', u'ph4.4', u'pn40', u'ph3.3', u'ph2.6']\n```\n\n### 转换txt\n```python\ncnt=0\nresultlistfile=open('test.txt','w')\nidsfile=open('ids.txt','w')\nfor imgid in ids:\n    if int(imgid)<40000:\n        idsfile.write(imgid+'\\n')\n        img=annos[\"imgs\"][imgid]\n        cnt+=1\n        for obj in img['objects']:\n            box = obj['bbox']\n            ss = obj['category']\n            resstr=imgid+' '+ss+' '+str(box['xmin'])+' '+str(box['ymin'])+' '+str(box['xmax'])+' '+str(box['ymax'])+' 0 '+str(cnt)\n            resultlistfile.write(resstr+'\\n')\n            print (resstr)\n        \nidsfile.close()\nresultlistfile.close()\n```\n```\n\n10056 pne 414 877 431 909 0 1\n10056 i5 452 886 468 916 0 1\n10056 pne 1215 928 1237 950 0 1\n10056 i5 1274 927 1294 949 0 1\n10056 pne 2016 910 2032 934 0 1\n10063 pr20 1637 949 1678 1002 0 2\n10063 p27 1371 701 1426 759 0 2\n10063 po 1482 692 1543 753 0 2\n10063 pl40 1370 774 1422 834 0 2\n10063 ph4.5 1480 765 1543 828 0 2\n10128 pl40 1349 539 1450 643 0 3\n10128 p11 1476 545 1570 650 0 3\n10128 pn 1584 562 1684 662 0 3\n1012 pl30 645 516 735 603 0 4\n1012 pm20 742 512 837 600 0 4\n1012 p26 843 487 938 572 0 4\n1012 ph4.5 531 752 618 840 0 4\n1012 p9 529 847 621 941 0 4\n```\n### 转换json\n```python\nresultcont=open('test.txt','r')\n#print('namelist',resultcont)\nperid=''\nimgid=''\n# types=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]\n# trainotest='train'\nobjs=[]\nresults = {}\nfor resultline in resultcont.read().split('\\n'):\n    if resultline:\n        ressplit=resultline.split(' ')\n        if (not perid==ressplit[0]):\n            perid=ressplit[0]\n            \n            if (not imgid == ''):\n                #print(objs)\n                results[imgid] = {\"objects\":objs,\"id\":imgid,\"path\":\"\"+trainotest+\"/\"+imgid+\".jpg\"}\n            objs=[]\n        mobj = {\"bbox\":dict(zip([\"xmin\",\"ymin\",\"xmax\",\"ymax\"],\n                                [float(ressplit[2]),float(ressplit[3]),float(ressplit[4]),float(ressplit[5])])), \n                    \"category\":str(ressplit[1])}\n        objs.append(mobj)\n        #print(ressplit[2:6])\n        imgid=ressplit[0]\nresults[imgid] = {\"objects\":objs,\"id\":imgid,\"path\":\"\"+trainotest+\"/\"+imgid+\".jpg\"}\n\nresults_annos = {\"imgs\":results,\"types\":types}   \nprint (results_annos)\nopen(\"../../Src1/annotations.json\", \"w\").write(json.dumps(results_annos))\n```\n### json转voc\n```python\nimport json\nimport pylab as pl\nimport random\nimport numpy as np\nimport cv2\nimport anno_func\n%matplotlib inline\n\ndatadir = \"../../Src1/\"\ntrainotest='train'\nfiledir = datadir + \"/annotations.json\"\nids = open(datadir + \"/\"+trainotest+\"/ids.txt\").read().splitlines()\n\nannos = json.loads(open(filedir).read())\n\ncnt=0\nresultlistfile=open('test.txt','w')\nfor imgid in ids:\n    if int(imgid)<40000:\n        img=annos[\"imgs\"][imgid]\n        cnt+=1\n        node_root = Element('annotation')\n\n        node_folder = SubElement(node_root, 'folder')\n        node_folder.text = 'train'\n\n        node_filename = SubElement(node_root, 'filename')\n        node_filename.text = str(imgid)+'.jpg'\n        \n        node_filename = SubElement(node_root, 'path')\n        node_filename.text = datadir+trainotest+\"/\"+str(imgid)+'.jpg'\n\n        node_size = SubElement(node_root, 'size')\n        node_width = SubElement(node_size, 'width')\n        node_width.text = '2048'\n\n        node_height = SubElement(node_size, 'height')\n        node_height.text = '2048'\n\n        node_depth = SubElement(node_size, 'depth')\n        node_depth.text = '3'\n        \n        for obj in img['objects']:\n            box = obj['bbox']\n            ss = obj['category']\n            str(box['xmin'])+' '+str(box['ymin'])+' '+str(box['xmax'])+' '+str(box['ymax'])+' 0 '+str(cnt)\n            \n\n            node_object = SubElement(node_root, 'object')\n            node_name = SubElement(node_object, 'name')\n            node_name.text = ss\n            node_difficult = SubElement(node_object, 'difficult')\n            node_difficult.text = '0'\n            node_bndbox = SubElement(node_object, 'bndbox')\n            node_xmin = SubElement(node_bndbox, 'xmin')\n            node_xmin.text = str(int(box['xmin']))\n            node_ymin = SubElement(node_bndbox, 'ymin')\n            node_ymin.text = str(int(box['ymin']))\n            node_xmax = SubElement(node_bndbox, 'xmax')\n            node_xmax.text = str(int(box['xmax']))\n            node_ymax = SubElement(node_bndbox, 'ymax')\n            node_ymax.text = str(int(box['ymax']))\n\n        xml = tostring(node_root, pretty_print=True)  #格式化显示，该换行的换行\n        dom = parseString(xml)\n            #print xml\n        xmlfile=open(datadir+\"xml/\"+imgid+'.xml','w')\n        xmlfile.write(xml)\n\n```\n","slug":"label-transfer","published":1,"updated":"2019-04-13T01:52:14.044Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3i2nlgu0002axsiy8ydk8t7","content":"<p>在处理coco数据、imageNet、VOC数据时，需要对数据标签进行转换，本文即提供转换代码</p>\n<a id=\"more\"></a>\n<p>本文主要是对tencent 100k交通标志标记数据转换</p>\n<p>临时写的，代码很乱，需要根据实际路径修改</p>\n<p>数据下载： <a href=\"http://cg.cs.tsinghua.edu.cn/traffic-sign/tutorial.html\" target=\"_blank\" rel=\"noopener\">http://cg.cs.tsinghua.edu.cn/traffic-sign/tutorial.html</a></p>\n<h3 id=\"加载标签\"><a href=\"#加载标签\" class=\"headerlink\" title=\"加载标签\"></a>加载标签</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> pylab <span class=\"keyword\">as</span> pl</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> anno_func</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">datadir = <span class=\"string\">\"../../data/\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">filedir = datadir + <span class=\"string\">\"/annotations.json\"</span></span><br><span class=\"line\">ids = open(datadir + <span class=\"string\">\"/test/ids.txt\"</span>).read().splitlines()</span><br><span class=\"line\"></span><br><span class=\"line\">annos = json.loads(open(filedir).read())</span><br></pre></td></tr></table></figure>\n<h3 id=\"分析结构\"><a href=\"#分析结构\" class=\"headerlink\" title=\"分析结构\"></a>分析结构</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">imgid = random.sample(ids, <span class=\"number\">1</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">img=annos[<span class=\"string\">\"imgs\"</span>][imgid]</span><br><span class=\"line\"><span class=\"keyword\">print</span> (img)</span><br><span class=\"line\">img=annos[<span class=\"string\">\"types\"</span>]</span><br><span class=\"line\"><span class=\"keyword\">print</span> (img)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;u&apos;path&apos;: u&apos;test/2468.jpg&apos;, u&apos;objects&apos;: [&#123;u&apos;category&apos;: u&apos;pn&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 1343.2, u&apos;ymin&apos;: 911.2, u&apos;ymax&apos;: 964.0, u&apos;xmax&apos;: 1396.0&#125;, u&apos;ellipse_org&apos;: [[1367.87, 911.552], [1395.46, 937.913], [1368.33, 963.195], [1343.97, 936.988], [1353.99, 958.571], [1387.91, 957.183]], u&apos;ellipse&apos;: [[1369.0028076171875, 937.2377319335938], [51.76936721801758, 52.934967041015625], 139.54888916015625]&#125;, &#123;u&apos;category&apos;: u&apos;pn&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 1197.6, u&apos;ymin&apos;: 940.0, u&apos;ymax&apos;: 963.2, u&apos;xmax&apos;: 1220.8&#125;, u&apos;ellipse_org&apos;: [[1209.01, 940.921], [1219.11, 951.016], [1209.21, 961.043], [1199.25, 951.626], [1201.96, 944.986], [1201.22, 956.775], [1217.55, 945.799]], u&apos;ellipse&apos;: [[1209.0211181640625, 950.5414428710938], [19.53607940673828, 21.289642333984375], 153.71450805664062]&#125;, &#123;u&apos;category&apos;: u&apos;p11&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 229.6, u&apos;ymin&apos;: 963.2, u&apos;ymax&apos;: 1008.8000000000001, u&apos;xmax&apos;: 270.4&#125;, u&apos;ellipse_org&apos;: [[248.171, 963.658], [269.073, 986.158], [249.236, 1008.39], [231.395, 984.827], [262.816, 1002.0], [236.987, 1001.87], [263.881, 971.513]], u&apos;ellipse&apos;: [[249.62039184570312, 985.5843505859375], [37.6942024230957, 44.657630920410156], 177.4745330810547]&#125;, &#123;u&apos;category&apos;: u&apos;pl10&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 235.2, u&apos;ymin&apos;: 1009.6, u&apos;ymax&apos;: 1056.8, u&apos;xmax&apos;: 279.2&#125;, u&apos;ellipse_org&apos;: [[254.683, 1009.92], [277.41, 1032.51], [255.785, 1055.1], [235.813, 1031.96], [240.496, 1047.8], [239.945, 1018.6], [270.386, 1047.11], [271.488, 1017.49]], u&apos;ellipse&apos;: [[255.57847595214844, 1031.8031005859375], [41.567535400390625, 45.633445739746094], 3.8224732875823975]&#125;], u&apos;id&apos;: 2468&#125;</span><br><span class=\"line\">[u&apos;i1&apos;, u&apos;i10&apos;, u&apos;i11&apos;, u&apos;i12&apos;, u&apos;i13&apos;, u&apos;i14&apos;, u&apos;i15&apos;, u&apos;i2&apos;, u&apos;i3&apos;, u&apos;i4&apos;, u&apos;i5&apos;, u&apos;il100&apos;, u&apos;il110&apos;, u&apos;il50&apos;, u&apos;il60&apos;, u&apos;il70&apos;, u&apos;il80&apos;, u&apos;il90&apos;, u&apos;io&apos;, u&apos;ip&apos;, u&apos;p1&apos;, u&apos;p10&apos;, u&apos;p11&apos;, u&apos;p12&apos;, u&apos;p13&apos;, u&apos;p14&apos;, u&apos;p15&apos;, u&apos;p16&apos;, u&apos;p17&apos;, u&apos;p18&apos;, u&apos;p19&apos;, u&apos;p2&apos;, u&apos;p20&apos;, u&apos;p21&apos;, u&apos;p22&apos;, u&apos;p23&apos;, u&apos;p24&apos;, u&apos;p25&apos;, u&apos;p26&apos;, u&apos;p27&apos;, u&apos;p28&apos;, u&apos;p3&apos;, u&apos;p4&apos;, u&apos;p5&apos;, u&apos;p6&apos;, u&apos;p7&apos;, u&apos;p8&apos;, u&apos;p9&apos;, u&apos;pa10&apos;, u&apos;pa12&apos;, u&apos;pa13&apos;, u&apos;pa14&apos;, u&apos;pa8&apos;, u&apos;pb&apos;, u&apos;pc&apos;, u&apos;pg&apos;, u&apos;ph1.5&apos;, u&apos;ph2&apos;, u&apos;ph2.1&apos;, u&apos;ph2.2&apos;, u&apos;ph2.4&apos;, u&apos;ph2.5&apos;, u&apos;ph2.8&apos;, u&apos;ph2.9&apos;, u&apos;ph3&apos;, u&apos;ph3.2&apos;, u&apos;ph3.5&apos;, u&apos;ph3.8&apos;, u&apos;ph4&apos;, u&apos;ph4.2&apos;, u&apos;ph4.3&apos;, u&apos;ph4.5&apos;, u&apos;ph4.8&apos;, u&apos;ph5&apos;, u&apos;ph5.3&apos;, u&apos;ph5.5&apos;, u&apos;pl10&apos;, u&apos;pl100&apos;, u&apos;pl110&apos;, u&apos;pl120&apos;, u&apos;pl15&apos;, u&apos;pl20&apos;, u&apos;pl25&apos;, u&apos;pl30&apos;, u&apos;pl35&apos;, u&apos;pl40&apos;, u&apos;pl5&apos;, u&apos;pl50&apos;, u&apos;pl60&apos;, u&apos;pl65&apos;, u&apos;pl70&apos;, u&apos;pl80&apos;, u&apos;pl90&apos;, u&apos;pm10&apos;, u&apos;pm13&apos;, u&apos;pm15&apos;, u&apos;pm1.5&apos;, u&apos;pm2&apos;, u&apos;pm20&apos;, u&apos;pm25&apos;, u&apos;pm30&apos;, u&apos;pm35&apos;, u&apos;pm40&apos;, u&apos;pm46&apos;, u&apos;pm5&apos;, u&apos;pm50&apos;, u&apos;pm55&apos;, u&apos;pm8&apos;, u&apos;pn&apos;, u&apos;pne&apos;, u&apos;po&apos;, u&apos;pr10&apos;, u&apos;pr100&apos;, u&apos;pr20&apos;, u&apos;pr30&apos;, u&apos;pr40&apos;, u&apos;pr45&apos;, u&apos;pr50&apos;, u&apos;pr60&apos;, u&apos;pr70&apos;, u&apos;pr80&apos;, u&apos;ps&apos;, u&apos;pw2&apos;, u&apos;pw2.5&apos;, u&apos;pw3&apos;, u&apos;pw3.2&apos;, u&apos;pw3.5&apos;, u&apos;pw4&apos;, u&apos;pw4.2&apos;, u&apos;pw4.5&apos;, u&apos;w1&apos;, u&apos;w10&apos;, u&apos;w12&apos;, u&apos;w13&apos;, u&apos;w16&apos;, u&apos;w18&apos;, u&apos;w20&apos;, u&apos;w21&apos;, u&apos;w22&apos;, u&apos;w24&apos;, u&apos;w28&apos;, u&apos;w3&apos;, u&apos;w30&apos;, u&apos;w31&apos;, u&apos;w32&apos;, u&apos;w34&apos;, u&apos;w35&apos;, u&apos;w37&apos;, u&apos;w38&apos;, u&apos;w41&apos;, u&apos;w42&apos;, u&apos;w43&apos;, u&apos;w44&apos;, u&apos;w45&apos;, u&apos;w46&apos;, u&apos;w47&apos;, u&apos;w48&apos;, u&apos;w49&apos;, u&apos;w5&apos;, u&apos;w50&apos;, u&apos;w55&apos;, u&apos;w56&apos;, u&apos;w57&apos;, u&apos;w58&apos;, u&apos;w59&apos;, u&apos;w60&apos;, u&apos;w62&apos;, u&apos;w63&apos;, u&apos;w66&apos;, u&apos;w8&apos;, u&apos;wo&apos;, u&apos;i6&apos;, u&apos;i7&apos;, u&apos;i8&apos;, u&apos;i9&apos;, u&apos;ilx&apos;, u&apos;p29&apos;, u&apos;w29&apos;, u&apos;w33&apos;, u&apos;w36&apos;, u&apos;w39&apos;, u&apos;w4&apos;, u&apos;w40&apos;, u&apos;w51&apos;, u&apos;w52&apos;, u&apos;w53&apos;, u&apos;w54&apos;, u&apos;w6&apos;, u&apos;w61&apos;, u&apos;w64&apos;, u&apos;w65&apos;, u&apos;w67&apos;, u&apos;w7&apos;, u&apos;w9&apos;, u&apos;pax&apos;, u&apos;pd&apos;, u&apos;pe&apos;, u&apos;phx&apos;, u&apos;plx&apos;, u&apos;pmx&apos;, u&apos;pnl&apos;, u&apos;prx&apos;, u&apos;pwx&apos;, u&apos;w11&apos;, u&apos;w14&apos;, u&apos;w15&apos;, u&apos;w17&apos;, u&apos;w19&apos;, u&apos;w2&apos;, u&apos;w23&apos;, u&apos;w25&apos;, u&apos;w26&apos;, u&apos;w27&apos;, u&apos;pl0&apos;, u&apos;pl4&apos;, u&apos;pl3&apos;, u&apos;pm2.5&apos;, u&apos;ph4.4&apos;, u&apos;pn40&apos;, u&apos;ph3.3&apos;, u&apos;ph2.6&apos;]</span><br></pre></td></tr></table></figure>\n<h3 id=\"转换txt\"><a href=\"#转换txt\" class=\"headerlink\" title=\"转换txt\"></a>转换txt</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cnt=<span class=\"number\">0</span></span><br><span class=\"line\">resultlistfile=open(<span class=\"string\">'test.txt'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\">idsfile=open(<span class=\"string\">'ids.txt'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> imgid <span class=\"keyword\">in</span> ids:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> int(imgid)&lt;<span class=\"number\">40000</span>:</span><br><span class=\"line\">        idsfile.write(imgid+<span class=\"string\">'\\n'</span>)</span><br><span class=\"line\">        img=annos[<span class=\"string\">\"imgs\"</span>][imgid]</span><br><span class=\"line\">        cnt+=<span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> obj <span class=\"keyword\">in</span> img[<span class=\"string\">'objects'</span>]:</span><br><span class=\"line\">            box = obj[<span class=\"string\">'bbox'</span>]</span><br><span class=\"line\">            ss = obj[<span class=\"string\">'category'</span>]</span><br><span class=\"line\">            resstr=imgid+<span class=\"string\">' '</span>+ss+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'xmin'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'ymin'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'xmax'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'ymax'</span>])+<span class=\"string\">' 0 '</span>+str(cnt)</span><br><span class=\"line\">            resultlistfile.write(resstr+<span class=\"string\">'\\n'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">print</span> (resstr)</span><br><span class=\"line\">        </span><br><span class=\"line\">idsfile.close()</span><br><span class=\"line\">resultlistfile.close()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">10056 pne 414 877 431 909 0 1</span><br><span class=\"line\">10056 i5 452 886 468 916 0 1</span><br><span class=\"line\">10056 pne 1215 928 1237 950 0 1</span><br><span class=\"line\">10056 i5 1274 927 1294 949 0 1</span><br><span class=\"line\">10056 pne 2016 910 2032 934 0 1</span><br><span class=\"line\">10063 pr20 1637 949 1678 1002 0 2</span><br><span class=\"line\">10063 p27 1371 701 1426 759 0 2</span><br><span class=\"line\">10063 po 1482 692 1543 753 0 2</span><br><span class=\"line\">10063 pl40 1370 774 1422 834 0 2</span><br><span class=\"line\">10063 ph4.5 1480 765 1543 828 0 2</span><br><span class=\"line\">10128 pl40 1349 539 1450 643 0 3</span><br><span class=\"line\">10128 p11 1476 545 1570 650 0 3</span><br><span class=\"line\">10128 pn 1584 562 1684 662 0 3</span><br><span class=\"line\">1012 pl30 645 516 735 603 0 4</span><br><span class=\"line\">1012 pm20 742 512 837 600 0 4</span><br><span class=\"line\">1012 p26 843 487 938 572 0 4</span><br><span class=\"line\">1012 ph4.5 531 752 618 840 0 4</span><br><span class=\"line\">1012 p9 529 847 621 941 0 4</span><br></pre></td></tr></table></figure>\n<h3 id=\"转换json\"><a href=\"#转换json\" class=\"headerlink\" title=\"转换json\"></a>转换json</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">resultcont=open(<span class=\"string\">'test.txt'</span>,<span class=\"string\">'r'</span>)</span><br><span class=\"line\"><span class=\"comment\">#print('namelist',resultcont)</span></span><br><span class=\"line\">perid=<span class=\"string\">''</span></span><br><span class=\"line\">imgid=<span class=\"string\">''</span></span><br><span class=\"line\"><span class=\"comment\"># types=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]</span></span><br><span class=\"line\"><span class=\"comment\"># trainotest='train'</span></span><br><span class=\"line\">objs=[]</span><br><span class=\"line\">results = &#123;&#125;</span><br><span class=\"line\"><span class=\"keyword\">for</span> resultline <span class=\"keyword\">in</span> resultcont.read().split(<span class=\"string\">'\\n'</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> resultline:</span><br><span class=\"line\">        ressplit=resultline.split(<span class=\"string\">' '</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"keyword\">not</span> perid==ressplit[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            perid=ressplit[<span class=\"number\">0</span>]</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"keyword\">if</span> (<span class=\"keyword\">not</span> imgid == <span class=\"string\">''</span>):</span><br><span class=\"line\">                <span class=\"comment\">#print(objs)</span></span><br><span class=\"line\">                results[imgid] = &#123;<span class=\"string\">\"objects\"</span>:objs,<span class=\"string\">\"id\"</span>:imgid,<span class=\"string\">\"path\"</span>:<span class=\"string\">\"\"</span>+trainotest+<span class=\"string\">\"/\"</span>+imgid+<span class=\"string\">\".jpg\"</span>&#125;</span><br><span class=\"line\">            objs=[]</span><br><span class=\"line\">        mobj = &#123;<span class=\"string\">\"bbox\"</span>:dict(zip([<span class=\"string\">\"xmin\"</span>,<span class=\"string\">\"ymin\"</span>,<span class=\"string\">\"xmax\"</span>,<span class=\"string\">\"ymax\"</span>],</span><br><span class=\"line\">                                [float(ressplit[<span class=\"number\">2</span>]),float(ressplit[<span class=\"number\">3</span>]),float(ressplit[<span class=\"number\">4</span>]),float(ressplit[<span class=\"number\">5</span>])])), </span><br><span class=\"line\">                    <span class=\"string\">\"category\"</span>:str(ressplit[<span class=\"number\">1</span>])&#125;</span><br><span class=\"line\">        objs.append(mobj)</span><br><span class=\"line\">        <span class=\"comment\">#print(ressplit[2:6])</span></span><br><span class=\"line\">        imgid=ressplit[<span class=\"number\">0</span>]</span><br><span class=\"line\">results[imgid] = &#123;<span class=\"string\">\"objects\"</span>:objs,<span class=\"string\">\"id\"</span>:imgid,<span class=\"string\">\"path\"</span>:<span class=\"string\">\"\"</span>+trainotest+<span class=\"string\">\"/\"</span>+imgid+<span class=\"string\">\".jpg\"</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">results_annos = &#123;<span class=\"string\">\"imgs\"</span>:results,<span class=\"string\">\"types\"</span>:types&#125;   </span><br><span class=\"line\"><span class=\"keyword\">print</span> (results_annos)</span><br><span class=\"line\">open(<span class=\"string\">\"../../Src1/annotations.json\"</span>, <span class=\"string\">\"w\"</span>).write(json.dumps(results_annos))</span><br></pre></td></tr></table></figure>\n<h3 id=\"json转voc\"><a href=\"#json转voc\" class=\"headerlink\" title=\"json转voc\"></a>json转voc</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> pylab <span class=\"keyword\">as</span> pl</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> anno_func</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">datadir = <span class=\"string\">\"../../Src1/\"</span></span><br><span class=\"line\">trainotest=<span class=\"string\">'train'</span></span><br><span class=\"line\">filedir = datadir + <span class=\"string\">\"/annotations.json\"</span></span><br><span class=\"line\">ids = open(datadir + <span class=\"string\">\"/\"</span>+trainotest+<span class=\"string\">\"/ids.txt\"</span>).read().splitlines()</span><br><span class=\"line\"></span><br><span class=\"line\">annos = json.loads(open(filedir).read())</span><br><span class=\"line\"></span><br><span class=\"line\">cnt=<span class=\"number\">0</span></span><br><span class=\"line\">resultlistfile=open(<span class=\"string\">'test.txt'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> imgid <span class=\"keyword\">in</span> ids:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> int(imgid)&lt;<span class=\"number\">40000</span>:</span><br><span class=\"line\">        img=annos[<span class=\"string\">\"imgs\"</span>][imgid]</span><br><span class=\"line\">        cnt+=<span class=\"number\">1</span></span><br><span class=\"line\">        node_root = Element(<span class=\"string\">'annotation'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        node_folder = SubElement(node_root, <span class=\"string\">'folder'</span>)</span><br><span class=\"line\">        node_folder.text = <span class=\"string\">'train'</span></span><br><span class=\"line\"></span><br><span class=\"line\">        node_filename = SubElement(node_root, <span class=\"string\">'filename'</span>)</span><br><span class=\"line\">        node_filename.text = str(imgid)+<span class=\"string\">'.jpg'</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        node_filename = SubElement(node_root, <span class=\"string\">'path'</span>)</span><br><span class=\"line\">        node_filename.text = datadir+trainotest+<span class=\"string\">\"/\"</span>+str(imgid)+<span class=\"string\">'.jpg'</span></span><br><span class=\"line\"></span><br><span class=\"line\">        node_size = SubElement(node_root, <span class=\"string\">'size'</span>)</span><br><span class=\"line\">        node_width = SubElement(node_size, <span class=\"string\">'width'</span>)</span><br><span class=\"line\">        node_width.text = <span class=\"string\">'2048'</span></span><br><span class=\"line\"></span><br><span class=\"line\">        node_height = SubElement(node_size, <span class=\"string\">'height'</span>)</span><br><span class=\"line\">        node_height.text = <span class=\"string\">'2048'</span></span><br><span class=\"line\"></span><br><span class=\"line\">        node_depth = SubElement(node_size, <span class=\"string\">'depth'</span>)</span><br><span class=\"line\">        node_depth.text = <span class=\"string\">'3'</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">for</span> obj <span class=\"keyword\">in</span> img[<span class=\"string\">'objects'</span>]:</span><br><span class=\"line\">            box = obj[<span class=\"string\">'bbox'</span>]</span><br><span class=\"line\">            ss = obj[<span class=\"string\">'category'</span>]</span><br><span class=\"line\">            str(box[<span class=\"string\">'xmin'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'ymin'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'xmax'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'ymax'</span>])+<span class=\"string\">' 0 '</span>+str(cnt)</span><br><span class=\"line\">            </span><br><span class=\"line\"></span><br><span class=\"line\">            node_object = SubElement(node_root, <span class=\"string\">'object'</span>)</span><br><span class=\"line\">            node_name = SubElement(node_object, <span class=\"string\">'name'</span>)</span><br><span class=\"line\">            node_name.text = ss</span><br><span class=\"line\">            node_difficult = SubElement(node_object, <span class=\"string\">'difficult'</span>)</span><br><span class=\"line\">            node_difficult.text = <span class=\"string\">'0'</span></span><br><span class=\"line\">            node_bndbox = SubElement(node_object, <span class=\"string\">'bndbox'</span>)</span><br><span class=\"line\">            node_xmin = SubElement(node_bndbox, <span class=\"string\">'xmin'</span>)</span><br><span class=\"line\">            node_xmin.text = str(int(box[<span class=\"string\">'xmin'</span>]))</span><br><span class=\"line\">            node_ymin = SubElement(node_bndbox, <span class=\"string\">'ymin'</span>)</span><br><span class=\"line\">            node_ymin.text = str(int(box[<span class=\"string\">'ymin'</span>]))</span><br><span class=\"line\">            node_xmax = SubElement(node_bndbox, <span class=\"string\">'xmax'</span>)</span><br><span class=\"line\">            node_xmax.text = str(int(box[<span class=\"string\">'xmax'</span>]))</span><br><span class=\"line\">            node_ymax = SubElement(node_bndbox, <span class=\"string\">'ymax'</span>)</span><br><span class=\"line\">            node_ymax.text = str(int(box[<span class=\"string\">'ymax'</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">        xml = tostring(node_root, pretty_print=<span class=\"keyword\">True</span>)  <span class=\"comment\">#格式化显示，该换行的换行</span></span><br><span class=\"line\">        dom = parseString(xml)</span><br><span class=\"line\">            <span class=\"comment\">#print xml</span></span><br><span class=\"line\">        xmlfile=open(datadir+<span class=\"string\">\"xml/\"</span>+imgid+<span class=\"string\">'.xml'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\">        xmlfile.write(xml)</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>在处理coco数据、imageNet、VOC数据时，需要对数据标签进行转换，本文即提供转换代码</p>","more":"<p>本文主要是对tencent 100k交通标志标记数据转换</p>\n<p>临时写的，代码很乱，需要根据实际路径修改</p>\n<p>数据下载： <a href=\"http://cg.cs.tsinghua.edu.cn/traffic-sign/tutorial.html\" target=\"_blank\" rel=\"noopener\">http://cg.cs.tsinghua.edu.cn/traffic-sign/tutorial.html</a></p>\n<h3 id=\"加载标签\"><a href=\"#加载标签\" class=\"headerlink\" title=\"加载标签\"></a>加载标签</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> pylab <span class=\"keyword\">as</span> pl</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> anno_func</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">datadir = <span class=\"string\">\"../../data/\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">filedir = datadir + <span class=\"string\">\"/annotations.json\"</span></span><br><span class=\"line\">ids = open(datadir + <span class=\"string\">\"/test/ids.txt\"</span>).read().splitlines()</span><br><span class=\"line\"></span><br><span class=\"line\">annos = json.loads(open(filedir).read())</span><br></pre></td></tr></table></figure>\n<h3 id=\"分析结构\"><a href=\"#分析结构\" class=\"headerlink\" title=\"分析结构\"></a>分析结构</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">imgid = random.sample(ids, <span class=\"number\">1</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">img=annos[<span class=\"string\">\"imgs\"</span>][imgid]</span><br><span class=\"line\"><span class=\"keyword\">print</span> (img)</span><br><span class=\"line\">img=annos[<span class=\"string\">\"types\"</span>]</span><br><span class=\"line\"><span class=\"keyword\">print</span> (img)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;u&apos;path&apos;: u&apos;test/2468.jpg&apos;, u&apos;objects&apos;: [&#123;u&apos;category&apos;: u&apos;pn&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 1343.2, u&apos;ymin&apos;: 911.2, u&apos;ymax&apos;: 964.0, u&apos;xmax&apos;: 1396.0&#125;, u&apos;ellipse_org&apos;: [[1367.87, 911.552], [1395.46, 937.913], [1368.33, 963.195], [1343.97, 936.988], [1353.99, 958.571], [1387.91, 957.183]], u&apos;ellipse&apos;: [[1369.0028076171875, 937.2377319335938], [51.76936721801758, 52.934967041015625], 139.54888916015625]&#125;, &#123;u&apos;category&apos;: u&apos;pn&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 1197.6, u&apos;ymin&apos;: 940.0, u&apos;ymax&apos;: 963.2, u&apos;xmax&apos;: 1220.8&#125;, u&apos;ellipse_org&apos;: [[1209.01, 940.921], [1219.11, 951.016], [1209.21, 961.043], [1199.25, 951.626], [1201.96, 944.986], [1201.22, 956.775], [1217.55, 945.799]], u&apos;ellipse&apos;: [[1209.0211181640625, 950.5414428710938], [19.53607940673828, 21.289642333984375], 153.71450805664062]&#125;, &#123;u&apos;category&apos;: u&apos;p11&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 229.6, u&apos;ymin&apos;: 963.2, u&apos;ymax&apos;: 1008.8000000000001, u&apos;xmax&apos;: 270.4&#125;, u&apos;ellipse_org&apos;: [[248.171, 963.658], [269.073, 986.158], [249.236, 1008.39], [231.395, 984.827], [262.816, 1002.0], [236.987, 1001.87], [263.881, 971.513]], u&apos;ellipse&apos;: [[249.62039184570312, 985.5843505859375], [37.6942024230957, 44.657630920410156], 177.4745330810547]&#125;, &#123;u&apos;category&apos;: u&apos;pl10&apos;, u&apos;bbox&apos;: &#123;u&apos;xmin&apos;: 235.2, u&apos;ymin&apos;: 1009.6, u&apos;ymax&apos;: 1056.8, u&apos;xmax&apos;: 279.2&#125;, u&apos;ellipse_org&apos;: [[254.683, 1009.92], [277.41, 1032.51], [255.785, 1055.1], [235.813, 1031.96], [240.496, 1047.8], [239.945, 1018.6], [270.386, 1047.11], [271.488, 1017.49]], u&apos;ellipse&apos;: [[255.57847595214844, 1031.8031005859375], [41.567535400390625, 45.633445739746094], 3.8224732875823975]&#125;], u&apos;id&apos;: 2468&#125;</span><br><span class=\"line\">[u&apos;i1&apos;, u&apos;i10&apos;, u&apos;i11&apos;, u&apos;i12&apos;, u&apos;i13&apos;, u&apos;i14&apos;, u&apos;i15&apos;, u&apos;i2&apos;, u&apos;i3&apos;, u&apos;i4&apos;, u&apos;i5&apos;, u&apos;il100&apos;, u&apos;il110&apos;, u&apos;il50&apos;, u&apos;il60&apos;, u&apos;il70&apos;, u&apos;il80&apos;, u&apos;il90&apos;, u&apos;io&apos;, u&apos;ip&apos;, u&apos;p1&apos;, u&apos;p10&apos;, u&apos;p11&apos;, u&apos;p12&apos;, u&apos;p13&apos;, u&apos;p14&apos;, u&apos;p15&apos;, u&apos;p16&apos;, u&apos;p17&apos;, u&apos;p18&apos;, u&apos;p19&apos;, u&apos;p2&apos;, u&apos;p20&apos;, u&apos;p21&apos;, u&apos;p22&apos;, u&apos;p23&apos;, u&apos;p24&apos;, u&apos;p25&apos;, u&apos;p26&apos;, u&apos;p27&apos;, u&apos;p28&apos;, u&apos;p3&apos;, u&apos;p4&apos;, u&apos;p5&apos;, u&apos;p6&apos;, u&apos;p7&apos;, u&apos;p8&apos;, u&apos;p9&apos;, u&apos;pa10&apos;, u&apos;pa12&apos;, u&apos;pa13&apos;, u&apos;pa14&apos;, u&apos;pa8&apos;, u&apos;pb&apos;, u&apos;pc&apos;, u&apos;pg&apos;, u&apos;ph1.5&apos;, u&apos;ph2&apos;, u&apos;ph2.1&apos;, u&apos;ph2.2&apos;, u&apos;ph2.4&apos;, u&apos;ph2.5&apos;, u&apos;ph2.8&apos;, u&apos;ph2.9&apos;, u&apos;ph3&apos;, u&apos;ph3.2&apos;, u&apos;ph3.5&apos;, u&apos;ph3.8&apos;, u&apos;ph4&apos;, u&apos;ph4.2&apos;, u&apos;ph4.3&apos;, u&apos;ph4.5&apos;, u&apos;ph4.8&apos;, u&apos;ph5&apos;, u&apos;ph5.3&apos;, u&apos;ph5.5&apos;, u&apos;pl10&apos;, u&apos;pl100&apos;, u&apos;pl110&apos;, u&apos;pl120&apos;, u&apos;pl15&apos;, u&apos;pl20&apos;, u&apos;pl25&apos;, u&apos;pl30&apos;, u&apos;pl35&apos;, u&apos;pl40&apos;, u&apos;pl5&apos;, u&apos;pl50&apos;, u&apos;pl60&apos;, u&apos;pl65&apos;, u&apos;pl70&apos;, u&apos;pl80&apos;, u&apos;pl90&apos;, u&apos;pm10&apos;, u&apos;pm13&apos;, u&apos;pm15&apos;, u&apos;pm1.5&apos;, u&apos;pm2&apos;, u&apos;pm20&apos;, u&apos;pm25&apos;, u&apos;pm30&apos;, u&apos;pm35&apos;, u&apos;pm40&apos;, u&apos;pm46&apos;, u&apos;pm5&apos;, u&apos;pm50&apos;, u&apos;pm55&apos;, u&apos;pm8&apos;, u&apos;pn&apos;, u&apos;pne&apos;, u&apos;po&apos;, u&apos;pr10&apos;, u&apos;pr100&apos;, u&apos;pr20&apos;, u&apos;pr30&apos;, u&apos;pr40&apos;, u&apos;pr45&apos;, u&apos;pr50&apos;, u&apos;pr60&apos;, u&apos;pr70&apos;, u&apos;pr80&apos;, u&apos;ps&apos;, u&apos;pw2&apos;, u&apos;pw2.5&apos;, u&apos;pw3&apos;, u&apos;pw3.2&apos;, u&apos;pw3.5&apos;, u&apos;pw4&apos;, u&apos;pw4.2&apos;, u&apos;pw4.5&apos;, u&apos;w1&apos;, u&apos;w10&apos;, u&apos;w12&apos;, u&apos;w13&apos;, u&apos;w16&apos;, u&apos;w18&apos;, u&apos;w20&apos;, u&apos;w21&apos;, u&apos;w22&apos;, u&apos;w24&apos;, u&apos;w28&apos;, u&apos;w3&apos;, u&apos;w30&apos;, u&apos;w31&apos;, u&apos;w32&apos;, u&apos;w34&apos;, u&apos;w35&apos;, u&apos;w37&apos;, u&apos;w38&apos;, u&apos;w41&apos;, u&apos;w42&apos;, u&apos;w43&apos;, u&apos;w44&apos;, u&apos;w45&apos;, u&apos;w46&apos;, u&apos;w47&apos;, u&apos;w48&apos;, u&apos;w49&apos;, u&apos;w5&apos;, u&apos;w50&apos;, u&apos;w55&apos;, u&apos;w56&apos;, u&apos;w57&apos;, u&apos;w58&apos;, u&apos;w59&apos;, u&apos;w60&apos;, u&apos;w62&apos;, u&apos;w63&apos;, u&apos;w66&apos;, u&apos;w8&apos;, u&apos;wo&apos;, u&apos;i6&apos;, u&apos;i7&apos;, u&apos;i8&apos;, u&apos;i9&apos;, u&apos;ilx&apos;, u&apos;p29&apos;, u&apos;w29&apos;, u&apos;w33&apos;, u&apos;w36&apos;, u&apos;w39&apos;, u&apos;w4&apos;, u&apos;w40&apos;, u&apos;w51&apos;, u&apos;w52&apos;, u&apos;w53&apos;, u&apos;w54&apos;, u&apos;w6&apos;, u&apos;w61&apos;, u&apos;w64&apos;, u&apos;w65&apos;, u&apos;w67&apos;, u&apos;w7&apos;, u&apos;w9&apos;, u&apos;pax&apos;, u&apos;pd&apos;, u&apos;pe&apos;, u&apos;phx&apos;, u&apos;plx&apos;, u&apos;pmx&apos;, u&apos;pnl&apos;, u&apos;prx&apos;, u&apos;pwx&apos;, u&apos;w11&apos;, u&apos;w14&apos;, u&apos;w15&apos;, u&apos;w17&apos;, u&apos;w19&apos;, u&apos;w2&apos;, u&apos;w23&apos;, u&apos;w25&apos;, u&apos;w26&apos;, u&apos;w27&apos;, u&apos;pl0&apos;, u&apos;pl4&apos;, u&apos;pl3&apos;, u&apos;pm2.5&apos;, u&apos;ph4.4&apos;, u&apos;pn40&apos;, u&apos;ph3.3&apos;, u&apos;ph2.6&apos;]</span><br></pre></td></tr></table></figure>\n<h3 id=\"转换txt\"><a href=\"#转换txt\" class=\"headerlink\" title=\"转换txt\"></a>转换txt</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cnt=<span class=\"number\">0</span></span><br><span class=\"line\">resultlistfile=open(<span class=\"string\">'test.txt'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\">idsfile=open(<span class=\"string\">'ids.txt'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> imgid <span class=\"keyword\">in</span> ids:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> int(imgid)&lt;<span class=\"number\">40000</span>:</span><br><span class=\"line\">        idsfile.write(imgid+<span class=\"string\">'\\n'</span>)</span><br><span class=\"line\">        img=annos[<span class=\"string\">\"imgs\"</span>][imgid]</span><br><span class=\"line\">        cnt+=<span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> obj <span class=\"keyword\">in</span> img[<span class=\"string\">'objects'</span>]:</span><br><span class=\"line\">            box = obj[<span class=\"string\">'bbox'</span>]</span><br><span class=\"line\">            ss = obj[<span class=\"string\">'category'</span>]</span><br><span class=\"line\">            resstr=imgid+<span class=\"string\">' '</span>+ss+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'xmin'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'ymin'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'xmax'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'ymax'</span>])+<span class=\"string\">' 0 '</span>+str(cnt)</span><br><span class=\"line\">            resultlistfile.write(resstr+<span class=\"string\">'\\n'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">print</span> (resstr)</span><br><span class=\"line\">        </span><br><span class=\"line\">idsfile.close()</span><br><span class=\"line\">resultlistfile.close()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">10056 pne 414 877 431 909 0 1</span><br><span class=\"line\">10056 i5 452 886 468 916 0 1</span><br><span class=\"line\">10056 pne 1215 928 1237 950 0 1</span><br><span class=\"line\">10056 i5 1274 927 1294 949 0 1</span><br><span class=\"line\">10056 pne 2016 910 2032 934 0 1</span><br><span class=\"line\">10063 pr20 1637 949 1678 1002 0 2</span><br><span class=\"line\">10063 p27 1371 701 1426 759 0 2</span><br><span class=\"line\">10063 po 1482 692 1543 753 0 2</span><br><span class=\"line\">10063 pl40 1370 774 1422 834 0 2</span><br><span class=\"line\">10063 ph4.5 1480 765 1543 828 0 2</span><br><span class=\"line\">10128 pl40 1349 539 1450 643 0 3</span><br><span class=\"line\">10128 p11 1476 545 1570 650 0 3</span><br><span class=\"line\">10128 pn 1584 562 1684 662 0 3</span><br><span class=\"line\">1012 pl30 645 516 735 603 0 4</span><br><span class=\"line\">1012 pm20 742 512 837 600 0 4</span><br><span class=\"line\">1012 p26 843 487 938 572 0 4</span><br><span class=\"line\">1012 ph4.5 531 752 618 840 0 4</span><br><span class=\"line\">1012 p9 529 847 621 941 0 4</span><br></pre></td></tr></table></figure>\n<h3 id=\"转换json\"><a href=\"#转换json\" class=\"headerlink\" title=\"转换json\"></a>转换json</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">resultcont=open(<span class=\"string\">'test.txt'</span>,<span class=\"string\">'r'</span>)</span><br><span class=\"line\"><span class=\"comment\">#print('namelist',resultcont)</span></span><br><span class=\"line\">perid=<span class=\"string\">''</span></span><br><span class=\"line\">imgid=<span class=\"string\">''</span></span><br><span class=\"line\"><span class=\"comment\"># types=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]</span></span><br><span class=\"line\"><span class=\"comment\"># trainotest='train'</span></span><br><span class=\"line\">objs=[]</span><br><span class=\"line\">results = &#123;&#125;</span><br><span class=\"line\"><span class=\"keyword\">for</span> resultline <span class=\"keyword\">in</span> resultcont.read().split(<span class=\"string\">'\\n'</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> resultline:</span><br><span class=\"line\">        ressplit=resultline.split(<span class=\"string\">' '</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"keyword\">not</span> perid==ressplit[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            perid=ressplit[<span class=\"number\">0</span>]</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"keyword\">if</span> (<span class=\"keyword\">not</span> imgid == <span class=\"string\">''</span>):</span><br><span class=\"line\">                <span class=\"comment\">#print(objs)</span></span><br><span class=\"line\">                results[imgid] = &#123;<span class=\"string\">\"objects\"</span>:objs,<span class=\"string\">\"id\"</span>:imgid,<span class=\"string\">\"path\"</span>:<span class=\"string\">\"\"</span>+trainotest+<span class=\"string\">\"/\"</span>+imgid+<span class=\"string\">\".jpg\"</span>&#125;</span><br><span class=\"line\">            objs=[]</span><br><span class=\"line\">        mobj = &#123;<span class=\"string\">\"bbox\"</span>:dict(zip([<span class=\"string\">\"xmin\"</span>,<span class=\"string\">\"ymin\"</span>,<span class=\"string\">\"xmax\"</span>,<span class=\"string\">\"ymax\"</span>],</span><br><span class=\"line\">                                [float(ressplit[<span class=\"number\">2</span>]),float(ressplit[<span class=\"number\">3</span>]),float(ressplit[<span class=\"number\">4</span>]),float(ressplit[<span class=\"number\">5</span>])])), </span><br><span class=\"line\">                    <span class=\"string\">\"category\"</span>:str(ressplit[<span class=\"number\">1</span>])&#125;</span><br><span class=\"line\">        objs.append(mobj)</span><br><span class=\"line\">        <span class=\"comment\">#print(ressplit[2:6])</span></span><br><span class=\"line\">        imgid=ressplit[<span class=\"number\">0</span>]</span><br><span class=\"line\">results[imgid] = &#123;<span class=\"string\">\"objects\"</span>:objs,<span class=\"string\">\"id\"</span>:imgid,<span class=\"string\">\"path\"</span>:<span class=\"string\">\"\"</span>+trainotest+<span class=\"string\">\"/\"</span>+imgid+<span class=\"string\">\".jpg\"</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">results_annos = &#123;<span class=\"string\">\"imgs\"</span>:results,<span class=\"string\">\"types\"</span>:types&#125;   </span><br><span class=\"line\"><span class=\"keyword\">print</span> (results_annos)</span><br><span class=\"line\">open(<span class=\"string\">\"../../Src1/annotations.json\"</span>, <span class=\"string\">\"w\"</span>).write(json.dumps(results_annos))</span><br></pre></td></tr></table></figure>\n<h3 id=\"json转voc\"><a href=\"#json转voc\" class=\"headerlink\" title=\"json转voc\"></a>json转voc</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> pylab <span class=\"keyword\">as</span> pl</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> anno_func</span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">datadir = <span class=\"string\">\"../../Src1/\"</span></span><br><span class=\"line\">trainotest=<span class=\"string\">'train'</span></span><br><span class=\"line\">filedir = datadir + <span class=\"string\">\"/annotations.json\"</span></span><br><span class=\"line\">ids = open(datadir + <span class=\"string\">\"/\"</span>+trainotest+<span class=\"string\">\"/ids.txt\"</span>).read().splitlines()</span><br><span class=\"line\"></span><br><span class=\"line\">annos = json.loads(open(filedir).read())</span><br><span class=\"line\"></span><br><span class=\"line\">cnt=<span class=\"number\">0</span></span><br><span class=\"line\">resultlistfile=open(<span class=\"string\">'test.txt'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> imgid <span class=\"keyword\">in</span> ids:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> int(imgid)&lt;<span class=\"number\">40000</span>:</span><br><span class=\"line\">        img=annos[<span class=\"string\">\"imgs\"</span>][imgid]</span><br><span class=\"line\">        cnt+=<span class=\"number\">1</span></span><br><span class=\"line\">        node_root = Element(<span class=\"string\">'annotation'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        node_folder = SubElement(node_root, <span class=\"string\">'folder'</span>)</span><br><span class=\"line\">        node_folder.text = <span class=\"string\">'train'</span></span><br><span class=\"line\"></span><br><span class=\"line\">        node_filename = SubElement(node_root, <span class=\"string\">'filename'</span>)</span><br><span class=\"line\">        node_filename.text = str(imgid)+<span class=\"string\">'.jpg'</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        node_filename = SubElement(node_root, <span class=\"string\">'path'</span>)</span><br><span class=\"line\">        node_filename.text = datadir+trainotest+<span class=\"string\">\"/\"</span>+str(imgid)+<span class=\"string\">'.jpg'</span></span><br><span class=\"line\"></span><br><span class=\"line\">        node_size = SubElement(node_root, <span class=\"string\">'size'</span>)</span><br><span class=\"line\">        node_width = SubElement(node_size, <span class=\"string\">'width'</span>)</span><br><span class=\"line\">        node_width.text = <span class=\"string\">'2048'</span></span><br><span class=\"line\"></span><br><span class=\"line\">        node_height = SubElement(node_size, <span class=\"string\">'height'</span>)</span><br><span class=\"line\">        node_height.text = <span class=\"string\">'2048'</span></span><br><span class=\"line\"></span><br><span class=\"line\">        node_depth = SubElement(node_size, <span class=\"string\">'depth'</span>)</span><br><span class=\"line\">        node_depth.text = <span class=\"string\">'3'</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">for</span> obj <span class=\"keyword\">in</span> img[<span class=\"string\">'objects'</span>]:</span><br><span class=\"line\">            box = obj[<span class=\"string\">'bbox'</span>]</span><br><span class=\"line\">            ss = obj[<span class=\"string\">'category'</span>]</span><br><span class=\"line\">            str(box[<span class=\"string\">'xmin'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'ymin'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'xmax'</span>])+<span class=\"string\">' '</span>+str(box[<span class=\"string\">'ymax'</span>])+<span class=\"string\">' 0 '</span>+str(cnt)</span><br><span class=\"line\">            </span><br><span class=\"line\"></span><br><span class=\"line\">            node_object = SubElement(node_root, <span class=\"string\">'object'</span>)</span><br><span class=\"line\">            node_name = SubElement(node_object, <span class=\"string\">'name'</span>)</span><br><span class=\"line\">            node_name.text = ss</span><br><span class=\"line\">            node_difficult = SubElement(node_object, <span class=\"string\">'difficult'</span>)</span><br><span class=\"line\">            node_difficult.text = <span class=\"string\">'0'</span></span><br><span class=\"line\">            node_bndbox = SubElement(node_object, <span class=\"string\">'bndbox'</span>)</span><br><span class=\"line\">            node_xmin = SubElement(node_bndbox, <span class=\"string\">'xmin'</span>)</span><br><span class=\"line\">            node_xmin.text = str(int(box[<span class=\"string\">'xmin'</span>]))</span><br><span class=\"line\">            node_ymin = SubElement(node_bndbox, <span class=\"string\">'ymin'</span>)</span><br><span class=\"line\">            node_ymin.text = str(int(box[<span class=\"string\">'ymin'</span>]))</span><br><span class=\"line\">            node_xmax = SubElement(node_bndbox, <span class=\"string\">'xmax'</span>)</span><br><span class=\"line\">            node_xmax.text = str(int(box[<span class=\"string\">'xmax'</span>]))</span><br><span class=\"line\">            node_ymax = SubElement(node_bndbox, <span class=\"string\">'ymax'</span>)</span><br><span class=\"line\">            node_ymax.text = str(int(box[<span class=\"string\">'ymax'</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\">        xml = tostring(node_root, pretty_print=<span class=\"keyword\">True</span>)  <span class=\"comment\">#格式化显示，该换行的换行</span></span><br><span class=\"line\">        dom = parseString(xml)</span><br><span class=\"line\">            <span class=\"comment\">#print xml</span></span><br><span class=\"line\">        xmlfile=open(datadir+<span class=\"string\">\"xml/\"</span>+imgid+<span class=\"string\">'.xml'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\">        xmlfile.write(xml)</span><br></pre></td></tr></table></figure>"},{"title":"迁移说明","date":"2018-05-06T06:47:51.000Z","_content":"## 原导航站迁移为博客\n\n访问 `http://www.huarenlab.com/navi` 获取原站内容，感谢您多年来的支持！！！","source":"_posts/change.md","raw":"---\ntitle: 迁移说明\ndate: 2018-05-06 14:47:51\ntags: 原网站\ncategories: 皮一下\n---\n## 原导航站迁移为博客\n\n访问 `http://www.huarenlab.com/navi` 获取原站内容，感谢您多年来的支持！！！","slug":"change","published":1,"updated":"2019-04-13T01:52:14.044Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3i2nlgz0006axsittiz6awh","content":"<h2 id=\"原导航站迁移为博客\"><a href=\"#原导航站迁移为博客\" class=\"headerlink\" title=\"原导航站迁移为博客\"></a>原导航站迁移为博客</h2><p>访问 <code>http://www.huarenlab.com/navi</code> 获取原站内容，感谢您多年来的支持！！！</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"原导航站迁移为博客\"><a href=\"#原导航站迁移为博客\" class=\"headerlink\" title=\"原导航站迁移为博客\"></a>原导航站迁移为博客</h2><p>访问 <code>http://www.huarenlab.com/navi</code> 获取原站内容，感谢您多年来的支持！！！</p>\n"},{"title":"深度学习环境镜像","date":"2019-11-27T14:13:11.000Z","_content":"随着深度学习新技术的出现，cuda版本越来越高，升级导致之前编译过的程序不可用。本文介绍个人修改的docker，基于nvidia的tensorrt镜像cuda10.1版本，添加opencv+contrib3.4.8，添加常用机器学习框架，添加simpledet版的mxnet等。\n\n<!-- more -->\n# 介绍\n\n理想的深度学习开发和导出工具，这个项目是为了创建一个新的开发环境，使用docker开发数据科学中的人工智能模型，特别是计算机视觉。\n\n# pull镜像\n\n镜像地址\n[https://hub.docker.com/r/neoneone/neo-ai](https://hub.docker.com/r/neoneone/neo-ai)\n\n## 使用docker\n```\ndocker pull neoneone/neo-ai\n# mirror\ndocker pull registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai\n```\n\n## 使用singularity\n```\nsingularity pull docker://neoneone/neo-ai\n# mirror\nsingularity pull docker://registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai\n```\n\n# 运行docker\n\ndocker运行\n\n```\n# 运行镜像\ndocker run -it --rm --runtime=nvidia -v $(pwd):/workspace -w /workspace -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$DISPLAY -p 8888:8888 -p 6006:6006 registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai:latest\n# 查看运行的容器\ndocker ps -a\n# shell访问容器\ndocker exec -it a1d1dd53a7ba /bin/bash\n```\nsingularity运行\n```\nsingularity shell --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg \n```\n\n# 测试程序yolo\n\n代码地址[https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/restructure/yolo](https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/restructure/yolo)\n\n在`yolo/apps/trt-yolo`目录下的CMakeLists.txt的36行修改cuda版本\n```cmake\nfind_package(CUDA 10.1 EXACT REQUIRED cudart cublas curand)\n```\n\n在`data/test_images.txt`修改测试图片路径\n\n执行`prebuild.sh`安装依赖和下载模型\n\nyolo目录下执行\n```shell\n$ cd apps/trt-yolo\n$ mkdir build && cd build\n$ cmake -D CMAKE_BUILD_TYPE=Release .. \n$ make && cp trt-yolo-app ../../..\n$ cd ../../../\n$ trt-yolo-app --flagfile=config/yolov3-tiny.txt\n\n```\n\n测试输出\n```\nBuilding complete!\nSerializing the TensorRT Engine...\nSerialized plan file cached at location : data/yolov3-kFLOAT-kGPU-batch4.engine\nLoading TRT Engine...\nUNKNOWN: Deserialize required 1818080 microseconds.\nLoading Complete!\nTotal number of images used for inference : 6\n[======================================================================] 100 %\nNetwork Type : yolov3 Precision : kFLOAT Batch Size : 4 Inference time per image : 75.239 ms\n```\n\n# 备份恢复docker镜像\n\n查看本地镜像\n```\ndocker images\n```\n\n备份\n\n```\ndocker save -o ~/container-backup.tar container-backup\n```\n\n恢复\n```\ndocker load -i ~/container-backup.tar\n```\n","source":"_posts/neo-ai-lab.md","raw":"---\ntitle: 深度学习环境镜像\ndate: 2019-11-27 22:13:11\ntags: [镜像,docker]\ncategories: 深度学习\n---\n随着深度学习新技术的出现，cuda版本越来越高，升级导致之前编译过的程序不可用。本文介绍个人修改的docker，基于nvidia的tensorrt镜像cuda10.1版本，添加opencv+contrib3.4.8，添加常用机器学习框架，添加simpledet版的mxnet等。\n\n<!-- more -->\n# 介绍\n\n理想的深度学习开发和导出工具，这个项目是为了创建一个新的开发环境，使用docker开发数据科学中的人工智能模型，特别是计算机视觉。\n\n# pull镜像\n\n镜像地址\n[https://hub.docker.com/r/neoneone/neo-ai](https://hub.docker.com/r/neoneone/neo-ai)\n\n## 使用docker\n```\ndocker pull neoneone/neo-ai\n# mirror\ndocker pull registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai\n```\n\n## 使用singularity\n```\nsingularity pull docker://neoneone/neo-ai\n# mirror\nsingularity pull docker://registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai\n```\n\n# 运行docker\n\ndocker运行\n\n```\n# 运行镜像\ndocker run -it --rm --runtime=nvidia -v $(pwd):/workspace -w /workspace -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$DISPLAY -p 8888:8888 -p 6006:6006 registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai:latest\n# 查看运行的容器\ndocker ps -a\n# shell访问容器\ndocker exec -it a1d1dd53a7ba /bin/bash\n```\nsingularity运行\n```\nsingularity shell --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg \n```\n\n# 测试程序yolo\n\n代码地址[https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/restructure/yolo](https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/restructure/yolo)\n\n在`yolo/apps/trt-yolo`目录下的CMakeLists.txt的36行修改cuda版本\n```cmake\nfind_package(CUDA 10.1 EXACT REQUIRED cudart cublas curand)\n```\n\n在`data/test_images.txt`修改测试图片路径\n\n执行`prebuild.sh`安装依赖和下载模型\n\nyolo目录下执行\n```shell\n$ cd apps/trt-yolo\n$ mkdir build && cd build\n$ cmake -D CMAKE_BUILD_TYPE=Release .. \n$ make && cp trt-yolo-app ../../..\n$ cd ../../../\n$ trt-yolo-app --flagfile=config/yolov3-tiny.txt\n\n```\n\n测试输出\n```\nBuilding complete!\nSerializing the TensorRT Engine...\nSerialized plan file cached at location : data/yolov3-kFLOAT-kGPU-batch4.engine\nLoading TRT Engine...\nUNKNOWN: Deserialize required 1818080 microseconds.\nLoading Complete!\nTotal number of images used for inference : 6\n[======================================================================] 100 %\nNetwork Type : yolov3 Precision : kFLOAT Batch Size : 4 Inference time per image : 75.239 ms\n```\n\n# 备份恢复docker镜像\n\n查看本地镜像\n```\ndocker images\n```\n\n备份\n\n```\ndocker save -o ~/container-backup.tar container-backup\n```\n\n恢复\n```\ndocker load -i ~/container-backup.tar\n```\n","slug":"neo-ai-lab","published":1,"updated":"2019-11-28T02:00:47.111Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3i2nlh20008axsirj5sjywm","content":"<p>随着深度学习新技术的出现，cuda版本越来越高，升级导致之前编译过的程序不可用。本文介绍个人修改的docker，基于nvidia的tensorrt镜像cuda10.1版本，添加opencv+contrib3.4.8，添加常用机器学习框架，添加simpledet版的mxnet等。</p>\n<a id=\"more\"></a>\n<h1 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h1><p>理想的深度学习开发和导出工具，这个项目是为了创建一个新的开发环境，使用docker开发数据科学中的人工智能模型，特别是计算机视觉。</p>\n<h1 id=\"pull镜像\"><a href=\"#pull镜像\" class=\"headerlink\" title=\"pull镜像\"></a>pull镜像</h1><p>镜像地址<br><a href=\"https://hub.docker.com/r/neoneone/neo-ai\" target=\"_blank\" rel=\"noopener\">https://hub.docker.com/r/neoneone/neo-ai</a></p>\n<h2 id=\"使用docker\"><a href=\"#使用docker\" class=\"headerlink\" title=\"使用docker\"></a>使用docker</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull neoneone/neo-ai</span><br><span class=\"line\"># mirror</span><br><span class=\"line\">docker pull registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用singularity\"><a href=\"#使用singularity\" class=\"headerlink\" title=\"使用singularity\"></a>使用singularity</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">singularity pull docker://neoneone/neo-ai</span><br><span class=\"line\"># mirror</span><br><span class=\"line\">singularity pull docker://registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai</span><br></pre></td></tr></table></figure>\n<h1 id=\"运行docker\"><a href=\"#运行docker\" class=\"headerlink\" title=\"运行docker\"></a>运行docker</h1><p>docker运行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 运行镜像</span><br><span class=\"line\">docker run -it --rm --runtime=nvidia -v $(pwd):/workspace -w /workspace -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$DISPLAY -p 8888:8888 -p 6006:6006 registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai:latest</span><br><span class=\"line\"># 查看运行的容器</span><br><span class=\"line\">docker ps -a</span><br><span class=\"line\"># shell访问容器</span><br><span class=\"line\">docker exec -it a1d1dd53a7ba /bin/bash</span><br></pre></td></tr></table></figure>\n<p>singularity运行<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">singularity shell --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"测试程序yolo\"><a href=\"#测试程序yolo\" class=\"headerlink\" title=\"测试程序yolo\"></a>测试程序yolo</h1><p>代码地址<a href=\"https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/restructure/yolo\" target=\"_blank\" rel=\"noopener\">https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/restructure/yolo</a></p>\n<p>在<code>yolo/apps/trt-yolo</code>目录下的CMakeLists.txt的36行修改cuda版本<br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(CUDA <span class=\"number\">10.1</span> EXACT REQUIRED cudart cublas curand)</span><br></pre></td></tr></table></figure></p>\n<p>在<code>data/test_images.txt</code>修改测试图片路径</p>\n<p>执行<code>prebuild.sh</code>安装依赖和下载模型</p>\n<p>yolo目录下执行<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> apps/trt-yolo</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> mkdir build &amp;&amp; <span class=\"built_in\">cd</span> build</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> cmake -D CMAKE_BUILD_TYPE=Release .. </span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> make &amp;&amp; cp trt-yolo-app ../../..</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> ../../../</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> trt-yolo-app --flagfile=config/yolov3-tiny.txt</span></span><br></pre></td></tr></table></figure></p>\n<p>测试输出<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Building complete!</span><br><span class=\"line\">Serializing the TensorRT Engine...</span><br><span class=\"line\">Serialized plan file cached at location : data/yolov3-kFLOAT-kGPU-batch4.engine</span><br><span class=\"line\">Loading TRT Engine...</span><br><span class=\"line\">UNKNOWN: Deserialize required 1818080 microseconds.</span><br><span class=\"line\">Loading Complete!</span><br><span class=\"line\">Total number of images used for inference : 6</span><br><span class=\"line\">[======================================================================] 100 %</span><br><span class=\"line\">Network Type : yolov3 Precision : kFLOAT Batch Size : 4 Inference time per image : 75.239 ms</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"备份恢复docker镜像\"><a href=\"#备份恢复docker镜像\" class=\"headerlink\" title=\"备份恢复docker镜像\"></a>备份恢复docker镜像</h1><p>查看本地镜像<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker images</span><br></pre></td></tr></table></figure></p>\n<p>备份</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker save -o ~/container-backup.tar container-backup</span><br></pre></td></tr></table></figure>\n<p>恢复<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker load -i ~/container-backup.tar</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>随着深度学习新技术的出现，cuda版本越来越高，升级导致之前编译过的程序不可用。本文介绍个人修改的docker，基于nvidia的tensorrt镜像cuda10.1版本，添加opencv+contrib3.4.8，添加常用机器学习框架，添加simpledet版的mxnet等。</p>","more":"<h1 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h1><p>理想的深度学习开发和导出工具，这个项目是为了创建一个新的开发环境，使用docker开发数据科学中的人工智能模型，特别是计算机视觉。</p>\n<h1 id=\"pull镜像\"><a href=\"#pull镜像\" class=\"headerlink\" title=\"pull镜像\"></a>pull镜像</h1><p>镜像地址<br><a href=\"https://hub.docker.com/r/neoneone/neo-ai\" target=\"_blank\" rel=\"noopener\">https://hub.docker.com/r/neoneone/neo-ai</a></p>\n<h2 id=\"使用docker\"><a href=\"#使用docker\" class=\"headerlink\" title=\"使用docker\"></a>使用docker</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull neoneone/neo-ai</span><br><span class=\"line\"># mirror</span><br><span class=\"line\">docker pull registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用singularity\"><a href=\"#使用singularity\" class=\"headerlink\" title=\"使用singularity\"></a>使用singularity</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">singularity pull docker://neoneone/neo-ai</span><br><span class=\"line\"># mirror</span><br><span class=\"line\">singularity pull docker://registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai</span><br></pre></td></tr></table></figure>\n<h1 id=\"运行docker\"><a href=\"#运行docker\" class=\"headerlink\" title=\"运行docker\"></a>运行docker</h1><p>docker运行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 运行镜像</span><br><span class=\"line\">docker run -it --rm --runtime=nvidia -v $(pwd):/workspace -w /workspace -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$DISPLAY -p 8888:8888 -p 6006:6006 registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai:latest</span><br><span class=\"line\"># 查看运行的容器</span><br><span class=\"line\">docker ps -a</span><br><span class=\"line\"># shell访问容器</span><br><span class=\"line\">docker exec -it a1d1dd53a7ba /bin/bash</span><br></pre></td></tr></table></figure>\n<p>singularity运行<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">singularity shell --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"测试程序yolo\"><a href=\"#测试程序yolo\" class=\"headerlink\" title=\"测试程序yolo\"></a>测试程序yolo</h1><p>代码地址<a href=\"https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/restructure/yolo\" target=\"_blank\" rel=\"noopener\">https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps/tree/restructure/yolo</a></p>\n<p>在<code>yolo/apps/trt-yolo</code>目录下的CMakeLists.txt的36行修改cuda版本<br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">find_package</span>(CUDA <span class=\"number\">10.1</span> EXACT REQUIRED cudart cublas curand)</span><br></pre></td></tr></table></figure></p>\n<p>在<code>data/test_images.txt</code>修改测试图片路径</p>\n<p>执行<code>prebuild.sh</code>安装依赖和下载模型</p>\n<p>yolo目录下执行<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> apps/trt-yolo</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> mkdir build &amp;&amp; <span class=\"built_in\">cd</span> build</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> cmake -D CMAKE_BUILD_TYPE=Release .. </span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> make &amp;&amp; cp trt-yolo-app ../../..</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> ../../../</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> trt-yolo-app --flagfile=config/yolov3-tiny.txt</span></span><br></pre></td></tr></table></figure></p>\n<p>测试输出<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Building complete!</span><br><span class=\"line\">Serializing the TensorRT Engine...</span><br><span class=\"line\">Serialized plan file cached at location : data/yolov3-kFLOAT-kGPU-batch4.engine</span><br><span class=\"line\">Loading TRT Engine...</span><br><span class=\"line\">UNKNOWN: Deserialize required 1818080 microseconds.</span><br><span class=\"line\">Loading Complete!</span><br><span class=\"line\">Total number of images used for inference : 6</span><br><span class=\"line\">[======================================================================] 100 %</span><br><span class=\"line\">Network Type : yolov3 Precision : kFLOAT Batch Size : 4 Inference time per image : 75.239 ms</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"备份恢复docker镜像\"><a href=\"#备份恢复docker镜像\" class=\"headerlink\" title=\"备份恢复docker镜像\"></a>备份恢复docker镜像</h1><p>查看本地镜像<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker images</span><br></pre></td></tr></table></figure></p>\n<p>备份</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker save -o ~/container-backup.tar container-backup</span><br></pre></td></tr></table></figure>\n<p>恢复<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker load -i ~/container-backup.tar</span><br></pre></td></tr></table></figure></p>"},{"title":"一种便携式容器","date":"2019-11-23T12:53:11.000Z","_content":"内网环境安装docker和nvidia docker繁琐，本文介绍一种便携式容器singularity，安装简便（主要是2版本），仓库就可以直接安装。本文并介绍如何将docker镜像转换到singularity部署。\n\n<!-- more -->\n# 基本使用\n\n```\nUSAGE: singularity [global options...] <command> [command options...] ...\n\nGLOBAL OPTIONS:\n    -d|--debug    打印调试信息\n    -h|--help     显示使用帮助\n    -s|--silent   仅打印错误\n    -q|--quiet    关闭输出信息\n       --version  显示应用版本\n    -v|--verbose  啰嗦模式\n    -x|--sh-debug 打印shell调试信息\n\nGENERAL COMMANDS:\n    help       Show additional help for a command or container    \n    selftest   Run some self tests for singularity install         \n\nCONTAINER USAGE COMMANDS:\n    exec       执行容器中的命令     \n    run        运行容器中预设命令  \n    shell      在容器中运行shell    \n    test       运行容器中test脚本   \n\nCONTAINER MANAGEMENT COMMANDS:\n    apps       List available apps within a container       \n    bootstrap  *Deprecated* use build instead     \n    build      Build a new Singularity container \n    check      Perform container lint checks \n    inspect    Display container's metadata          \n    pull       Pull a Singularity/Docker container to $PWD  \n\nCOMMAND GROUPS:\n    image      Container image command group \n    instance   Persistent instance command group      \n\n\nCONTAINER USAGE OPTIONS:\n    see singularity help <command>\n\nFor any additional help or support visit the Singularity\nwebsite: http://singularity.lbl.gov/\n\n```\n# 转换docker镜像到singularity\n\n转换支持本地docker镜像，查看本地镜像列表通过`docker images`命令，其中quay.io/singularity/docker2singularity版本根据实际使用版本修改\n```bash\nmkdir /tmp/test\n# convert ubuntu:14.04\ndocker run -v /var/run/docker.sock:/var/run/docker.sock \\\n-v /tmp/test:/output \\\n--privileged -t --rm \\\nquay.io/singularity/docker2singularity:v2.4 \\\nubuntu:14.04\n# convert neo-ai\ndocker run -v /var/run/docker.sock:/var/run/docker.sock \\\n-v /tmp/test:/output \\\n--privileged -t --rm \\\nquay.io/singularity/docker2singularity:v2.4 \\\nregistry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai\n\n```\n\nsingularity运行镜像内jupyter程序\n```bash\nLANGUAGE=en sudo singularity run --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg \n```","source":"_posts/singularity-base.md","raw":"---\ntitle: 一种便携式容器\ndate: 2019-11-23 20:53:11\ntags: [容器,docker,singularity]\ncategories: 深度学习\n---\n内网环境安装docker和nvidia docker繁琐，本文介绍一种便携式容器singularity，安装简便（主要是2版本），仓库就可以直接安装。本文并介绍如何将docker镜像转换到singularity部署。\n\n<!-- more -->\n# 基本使用\n\n```\nUSAGE: singularity [global options...] <command> [command options...] ...\n\nGLOBAL OPTIONS:\n    -d|--debug    打印调试信息\n    -h|--help     显示使用帮助\n    -s|--silent   仅打印错误\n    -q|--quiet    关闭输出信息\n       --version  显示应用版本\n    -v|--verbose  啰嗦模式\n    -x|--sh-debug 打印shell调试信息\n\nGENERAL COMMANDS:\n    help       Show additional help for a command or container    \n    selftest   Run some self tests for singularity install         \n\nCONTAINER USAGE COMMANDS:\n    exec       执行容器中的命令     \n    run        运行容器中预设命令  \n    shell      在容器中运行shell    \n    test       运行容器中test脚本   \n\nCONTAINER MANAGEMENT COMMANDS:\n    apps       List available apps within a container       \n    bootstrap  *Deprecated* use build instead     \n    build      Build a new Singularity container \n    check      Perform container lint checks \n    inspect    Display container's metadata          \n    pull       Pull a Singularity/Docker container to $PWD  \n\nCOMMAND GROUPS:\n    image      Container image command group \n    instance   Persistent instance command group      \n\n\nCONTAINER USAGE OPTIONS:\n    see singularity help <command>\n\nFor any additional help or support visit the Singularity\nwebsite: http://singularity.lbl.gov/\n\n```\n# 转换docker镜像到singularity\n\n转换支持本地docker镜像，查看本地镜像列表通过`docker images`命令，其中quay.io/singularity/docker2singularity版本根据实际使用版本修改\n```bash\nmkdir /tmp/test\n# convert ubuntu:14.04\ndocker run -v /var/run/docker.sock:/var/run/docker.sock \\\n-v /tmp/test:/output \\\n--privileged -t --rm \\\nquay.io/singularity/docker2singularity:v2.4 \\\nubuntu:14.04\n# convert neo-ai\ndocker run -v /var/run/docker.sock:/var/run/docker.sock \\\n-v /tmp/test:/output \\\n--privileged -t --rm \\\nquay.io/singularity/docker2singularity:v2.4 \\\nregistry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai\n\n```\n\nsingularity运行镜像内jupyter程序\n```bash\nLANGUAGE=en sudo singularity run --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg \n```","slug":"singularity-base","published":1,"updated":"2019-11-28T01:47:31.383Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3i2nlh30009axsi61ckl19v","content":"<p>内网环境安装docker和nvidia docker繁琐，本文介绍一种便携式容器singularity，安装简便（主要是2版本），仓库就可以直接安装。本文并介绍如何将docker镜像转换到singularity部署。</p>\n<a id=\"more\"></a>\n<h1 id=\"基本使用\"><a href=\"#基本使用\" class=\"headerlink\" title=\"基本使用\"></a>基本使用</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">USAGE: singularity [global options...] &lt;command&gt; [command options...] ...</span><br><span class=\"line\"></span><br><span class=\"line\">GLOBAL OPTIONS:</span><br><span class=\"line\">    -d|--debug    打印调试信息</span><br><span class=\"line\">    -h|--help     显示使用帮助</span><br><span class=\"line\">    -s|--silent   仅打印错误</span><br><span class=\"line\">    -q|--quiet    关闭输出信息</span><br><span class=\"line\">       --version  显示应用版本</span><br><span class=\"line\">    -v|--verbose  啰嗦模式</span><br><span class=\"line\">    -x|--sh-debug 打印shell调试信息</span><br><span class=\"line\"></span><br><span class=\"line\">GENERAL COMMANDS:</span><br><span class=\"line\">    help       Show additional help for a command or container    </span><br><span class=\"line\">    selftest   Run some self tests for singularity install         </span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER USAGE COMMANDS:</span><br><span class=\"line\">    exec       执行容器中的命令     </span><br><span class=\"line\">    run        运行容器中预设命令  </span><br><span class=\"line\">    shell      在容器中运行shell    </span><br><span class=\"line\">    test       运行容器中test脚本   </span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER MANAGEMENT COMMANDS:</span><br><span class=\"line\">    apps       List available apps within a container       </span><br><span class=\"line\">    bootstrap  *Deprecated* use build instead     </span><br><span class=\"line\">    build      Build a new Singularity container </span><br><span class=\"line\">    check      Perform container lint checks </span><br><span class=\"line\">    inspect    Display container&apos;s metadata          </span><br><span class=\"line\">    pull       Pull a Singularity/Docker container to $PWD  </span><br><span class=\"line\"></span><br><span class=\"line\">COMMAND GROUPS:</span><br><span class=\"line\">    image      Container image command group </span><br><span class=\"line\">    instance   Persistent instance command group      </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER USAGE OPTIONS:</span><br><span class=\"line\">    see singularity help &lt;command&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">For any additional help or support visit the Singularity</span><br><span class=\"line\">website: http://singularity.lbl.gov/</span><br></pre></td></tr></table></figure>\n<h1 id=\"转换docker镜像到singularity\"><a href=\"#转换docker镜像到singularity\" class=\"headerlink\" title=\"转换docker镜像到singularity\"></a>转换docker镜像到singularity</h1><p>转换支持本地docker镜像，查看本地镜像列表通过<code>docker images</code>命令，其中quay.io/singularity/docker2singularity版本根据实际使用版本修改<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir /tmp/<span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\"># convert ubuntu:14.04</span></span><br><span class=\"line\">docker run -v /var/run/docker.sock:/var/run/docker.sock \\</span><br><span class=\"line\">-v /tmp/<span class=\"built_in\">test</span>:/output \\</span><br><span class=\"line\">--privileged -t --rm \\</span><br><span class=\"line\">quay.io/singularity/docker2singularity:v2.4 \\</span><br><span class=\"line\">ubuntu:14.04</span><br><span class=\"line\"><span class=\"comment\"># convert neo-ai</span></span><br><span class=\"line\">docker run -v /var/run/docker.sock:/var/run/docker.sock \\</span><br><span class=\"line\">-v /tmp/<span class=\"built_in\">test</span>:/output \\</span><br><span class=\"line\">--privileged -t --rm \\</span><br><span class=\"line\">quay.io/singularity/docker2singularity:v2.4 \\</span><br><span class=\"line\">registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai</span><br></pre></td></tr></table></figure></p>\n<p>singularity运行镜像内jupyter程序<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LANGUAGE=en sudo singularity run --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>内网环境安装docker和nvidia docker繁琐，本文介绍一种便携式容器singularity，安装简便（主要是2版本），仓库就可以直接安装。本文并介绍如何将docker镜像转换到singularity部署。</p>","more":"<h1 id=\"基本使用\"><a href=\"#基本使用\" class=\"headerlink\" title=\"基本使用\"></a>基本使用</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">USAGE: singularity [global options...] &lt;command&gt; [command options...] ...</span><br><span class=\"line\"></span><br><span class=\"line\">GLOBAL OPTIONS:</span><br><span class=\"line\">    -d|--debug    打印调试信息</span><br><span class=\"line\">    -h|--help     显示使用帮助</span><br><span class=\"line\">    -s|--silent   仅打印错误</span><br><span class=\"line\">    -q|--quiet    关闭输出信息</span><br><span class=\"line\">       --version  显示应用版本</span><br><span class=\"line\">    -v|--verbose  啰嗦模式</span><br><span class=\"line\">    -x|--sh-debug 打印shell调试信息</span><br><span class=\"line\"></span><br><span class=\"line\">GENERAL COMMANDS:</span><br><span class=\"line\">    help       Show additional help for a command or container    </span><br><span class=\"line\">    selftest   Run some self tests for singularity install         </span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER USAGE COMMANDS:</span><br><span class=\"line\">    exec       执行容器中的命令     </span><br><span class=\"line\">    run        运行容器中预设命令  </span><br><span class=\"line\">    shell      在容器中运行shell    </span><br><span class=\"line\">    test       运行容器中test脚本   </span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER MANAGEMENT COMMANDS:</span><br><span class=\"line\">    apps       List available apps within a container       </span><br><span class=\"line\">    bootstrap  *Deprecated* use build instead     </span><br><span class=\"line\">    build      Build a new Singularity container </span><br><span class=\"line\">    check      Perform container lint checks </span><br><span class=\"line\">    inspect    Display container&apos;s metadata          </span><br><span class=\"line\">    pull       Pull a Singularity/Docker container to $PWD  </span><br><span class=\"line\"></span><br><span class=\"line\">COMMAND GROUPS:</span><br><span class=\"line\">    image      Container image command group </span><br><span class=\"line\">    instance   Persistent instance command group      </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER USAGE OPTIONS:</span><br><span class=\"line\">    see singularity help &lt;command&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">For any additional help or support visit the Singularity</span><br><span class=\"line\">website: http://singularity.lbl.gov/</span><br></pre></td></tr></table></figure>\n<h1 id=\"转换docker镜像到singularity\"><a href=\"#转换docker镜像到singularity\" class=\"headerlink\" title=\"转换docker镜像到singularity\"></a>转换docker镜像到singularity</h1><p>转换支持本地docker镜像，查看本地镜像列表通过<code>docker images</code>命令，其中quay.io/singularity/docker2singularity版本根据实际使用版本修改<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir /tmp/<span class=\"built_in\">test</span></span><br><span class=\"line\"><span class=\"comment\"># convert ubuntu:14.04</span></span><br><span class=\"line\">docker run -v /var/run/docker.sock:/var/run/docker.sock \\</span><br><span class=\"line\">-v /tmp/<span class=\"built_in\">test</span>:/output \\</span><br><span class=\"line\">--privileged -t --rm \\</span><br><span class=\"line\">quay.io/singularity/docker2singularity:v2.4 \\</span><br><span class=\"line\">ubuntu:14.04</span><br><span class=\"line\"><span class=\"comment\"># convert neo-ai</span></span><br><span class=\"line\">docker run -v /var/run/docker.sock:/var/run/docker.sock \\</span><br><span class=\"line\">-v /tmp/<span class=\"built_in\">test</span>:/output \\</span><br><span class=\"line\">--privileged -t --rm \\</span><br><span class=\"line\">quay.io/singularity/docker2singularity:v2.4 \\</span><br><span class=\"line\">registry.cn-shenzhen.aliyuncs.com/neoneone/neo-ai</span><br></pre></td></tr></table></figure></p>\n<p>singularity运行镜像内jupyter程序<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LANGUAGE=en sudo singularity run --nv registry.cn-shenzhen.aliyuncs.com_neoneone_neo-ai-2019-11-23-331a86220733.simg</span><br></pre></td></tr></table></figure></p>"},{"title":"图像视频标注工具","date":"2019-11-06T12:23:11.000Z","_content":"网上开源的标注工具很多，但总是缺少很多功能。在生成中造成极大的困惑，本贴提供可标注矩形、点、线、多边形等的标注工具，具有缩放平移等功能。\n\n<!-- more -->\n[vott](https://github.com/Microsoft/VoTT)是微软旗下的标注工具，众所周知，微软大刀总会砍向好的项目，在步入2.0版本时候，开了倒车，没有增加图像缩放功能，还把多边形标注功能砍了。\n\n我在1.7.2版本上添加了图像缩放功能，增加了多组标签功能，增加标签编辑和搜索功能。\n\n1.7.2.2版本更新日志\n\n```\n添加标签编辑窗口，按E键编辑，按tab键切换标签\n按alt键可以使选中框外的其他框锁定\n修正图像缩放功能，能够标注一些小目标\n添加画人车3D功能，可调整大小\n修正鼠标停在目标区域导致下一张不能创建标注的问题\n点下一张图会自动保存，当前图s或者ctl+s保存\n多段线功能将原矩形拖动改为线条拖动，多边形将原矩形拖动改为多边形内部\n将原有的着色改为：1.默认为线条加0.5透明的边沿；2.鼠标悬停为0.8透明矩形；3.线条选中仅显示多段线\n多标签问题：由于Pascal导出只能使用一个类别，为了更加直观，以标注颜色为统一，选对应颜色的那个类别，为靠前的类别\n还存在的bug: Ctrl点击锚点会删除该点，要移动任意一点才能保存\n```\n![](/imgs/2019-11-07-vott-test.png)\n\n在线演示[github](https://neophack.github.io/vott-ct/test/)\n\n下载链接[Windows版本](https://www.lanzous.com/i77ui8f)\n","source":"_posts/vott-neon.md","raw":"---\ntitle: 图像视频标注工具\ndate: 2019-11-06 20:23:11\ntags: 标注\ncategories: 深度学习\n---\n网上开源的标注工具很多，但总是缺少很多功能。在生成中造成极大的困惑，本贴提供可标注矩形、点、线、多边形等的标注工具，具有缩放平移等功能。\n\n<!-- more -->\n[vott](https://github.com/Microsoft/VoTT)是微软旗下的标注工具，众所周知，微软大刀总会砍向好的项目，在步入2.0版本时候，开了倒车，没有增加图像缩放功能，还把多边形标注功能砍了。\n\n我在1.7.2版本上添加了图像缩放功能，增加了多组标签功能，增加标签编辑和搜索功能。\n\n1.7.2.2版本更新日志\n\n```\n添加标签编辑窗口，按E键编辑，按tab键切换标签\n按alt键可以使选中框外的其他框锁定\n修正图像缩放功能，能够标注一些小目标\n添加画人车3D功能，可调整大小\n修正鼠标停在目标区域导致下一张不能创建标注的问题\n点下一张图会自动保存，当前图s或者ctl+s保存\n多段线功能将原矩形拖动改为线条拖动，多边形将原矩形拖动改为多边形内部\n将原有的着色改为：1.默认为线条加0.5透明的边沿；2.鼠标悬停为0.8透明矩形；3.线条选中仅显示多段线\n多标签问题：由于Pascal导出只能使用一个类别，为了更加直观，以标注颜色为统一，选对应颜色的那个类别，为靠前的类别\n还存在的bug: Ctrl点击锚点会删除该点，要移动任意一点才能保存\n```\n![](/imgs/2019-11-07-vott-test.png)\n\n在线演示[github](https://neophack.github.io/vott-ct/test/)\n\n下载链接[Windows版本](https://www.lanzous.com/i77ui8f)\n","slug":"vott-neon","published":1,"updated":"2019-11-07T07:59:27.801Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3i2nlh6000daxsifb4a6vnd","content":"<p>网上开源的标注工具很多，但总是缺少很多功能。在生成中造成极大的困惑，本贴提供可标注矩形、点、线、多边形等的标注工具，具有缩放平移等功能。</p>\n<a id=\"more\"></a>\n<p><a href=\"https://github.com/Microsoft/VoTT\" target=\"_blank\" rel=\"noopener\">vott</a>是微软旗下的标注工具，众所周知，微软大刀总会砍向好的项目，在步入2.0版本时候，开了倒车，没有增加图像缩放功能，还把多边形标注功能砍了。</p>\n<p>我在1.7.2版本上添加了图像缩放功能，增加了多组标签功能，增加标签编辑和搜索功能。</p>\n<p>1.7.2.2版本更新日志</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">添加标签编辑窗口，按E键编辑，按tab键切换标签</span><br><span class=\"line\">按alt键可以使选中框外的其他框锁定</span><br><span class=\"line\">修正图像缩放功能，能够标注一些小目标</span><br><span class=\"line\">添加画人车3D功能，可调整大小</span><br><span class=\"line\">修正鼠标停在目标区域导致下一张不能创建标注的问题</span><br><span class=\"line\">点下一张图会自动保存，当前图s或者ctl+s保存</span><br><span class=\"line\">多段线功能将原矩形拖动改为线条拖动，多边形将原矩形拖动改为多边形内部</span><br><span class=\"line\">将原有的着色改为：1.默认为线条加0.5透明的边沿；2.鼠标悬停为0.8透明矩形；3.线条选中仅显示多段线</span><br><span class=\"line\">多标签问题：由于Pascal导出只能使用一个类别，为了更加直观，以标注颜色为统一，选对应颜色的那个类别，为靠前的类别</span><br><span class=\"line\">还存在的bug: Ctrl点击锚点会删除该点，要移动任意一点才能保存</span><br></pre></td></tr></table></figure>\n<figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"/imgs/2019-11-07-vott-test.png\" alt title>\n                </div>\n                <div class=\"image-caption\"></div>\n            </figure>\n<p>在线演示<a href=\"https://neophack.github.io/vott-ct/test/\" target=\"_blank\" rel=\"noopener\">github</a></p>\n<p>下载链接<a href=\"https://www.lanzous.com/i77ui8f\" target=\"_blank\" rel=\"noopener\">Windows版本</a></p>\n","site":{"data":{}},"excerpt":"<p>网上开源的标注工具很多，但总是缺少很多功能。在生成中造成极大的困惑，本贴提供可标注矩形、点、线、多边形等的标注工具，具有缩放平移等功能。</p>","more":"<p><a href=\"https://github.com/Microsoft/VoTT\" target=\"_blank\" rel=\"noopener\">vott</a>是微软旗下的标注工具，众所周知，微软大刀总会砍向好的项目，在步入2.0版本时候，开了倒车，没有增加图像缩放功能，还把多边形标注功能砍了。</p>\n<p>我在1.7.2版本上添加了图像缩放功能，增加了多组标签功能，增加标签编辑和搜索功能。</p>\n<p>1.7.2.2版本更新日志</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">添加标签编辑窗口，按E键编辑，按tab键切换标签</span><br><span class=\"line\">按alt键可以使选中框外的其他框锁定</span><br><span class=\"line\">修正图像缩放功能，能够标注一些小目标</span><br><span class=\"line\">添加画人车3D功能，可调整大小</span><br><span class=\"line\">修正鼠标停在目标区域导致下一张不能创建标注的问题</span><br><span class=\"line\">点下一张图会自动保存，当前图s或者ctl+s保存</span><br><span class=\"line\">多段线功能将原矩形拖动改为线条拖动，多边形将原矩形拖动改为多边形内部</span><br><span class=\"line\">将原有的着色改为：1.默认为线条加0.5透明的边沿；2.鼠标悬停为0.8透明矩形；3.线条选中仅显示多段线</span><br><span class=\"line\">多标签问题：由于Pascal导出只能使用一个类别，为了更加直观，以标注颜色为统一，选对应颜色的那个类别，为靠前的类别</span><br><span class=\"line\">还存在的bug: Ctrl点击锚点会删除该点，要移动任意一点才能保存</span><br></pre></td></tr></table></figure>\n<figure class=\"image-bubble\">\n                <div class=\"img-lightbox\">\n                    <div class=\"overlay\"></div>\n                    <img src=\"/imgs/2019-11-07-vott-test.png\" alt title>\n                </div>\n                <div class=\"image-caption\"></div>\n            </figure>\n<p>在线演示<a href=\"https://neophack.github.io/vott-ct/test/\" target=\"_blank\" rel=\"noopener\">github</a></p>\n<p>下载链接<a href=\"https://www.lanzous.com/i77ui8f\" target=\"_blank\" rel=\"noopener\">Windows版本</a></p>"},{"title":"yolo训练经验","date":"2018-09-17T11:25:51.000Z","_content":"yolo太难训练了啊，动不动就nan，超参选择对模型是否收敛影响挺大的，本文分享我在训练yolo的一些经验\n\n<!-- more -->\n\n## YOLOv3为例\n\n先说yolov3首先要有张8GB以上的显卡，否则很难收敛。tiny-yolov3建议4G以上显存。\n\n将batch设为64，subdivisions设为16，真实的batchsize为batch/subdivisions=4。显存主要是和真实的batchsize挂钩，设置大了要担心显存是否够用，但训练初期能够很好的收敛。\n\nlearning_rate设置过大训练会很快发散，在fine_tune模型时learning_rate为配置文件所设置的值，不是fine_tune模型时learning_rate为最大的学习率，训练过程真实的学习率会慢慢变大直到等于所设值。在训练一段时间后，loss值在很长的一段时间都在某个值附近徘徊，需要将learning_rate设置更小的值。总结learning_rate的值应该先增大再减小，可以通过steps和scales配置比率。\n\n训练观察是否收敛，loss很快变小再在某个值附近徘徊；obj先变小后变大最后趋近1；召回率.5R会变大直到1，接着.75R也会有很多1；class和IOU会慢慢接近1。\n\n训练测试\n```\n.\\darknet detector map .\\data\\voc.data .\\cfg\\yolov3.cfg .\\backup\\yolov3_271604.weights\n```\n结果包含每个类别的AP值，mAP值、精度、召回率、TP数量、FP数量、FN数量、平均IOU等。\n\n模型输入图像尺寸和mask、anchors参数要对应，根据训练数据实际框大小的分布来确定值。在训练时候不会在某个尺度的框一直出现count:0的结果，才能最大化利用其尺度信息。\n\n如果觉得三个scale不够用，可以将最后增加一个尺度，模仿原始模型文件写即可，注意合并要用第11层。mask、anchors参数也要添加更多的数据，9->12。\n\n\n声明：如有错误或者侵权请邮箱联系我","source":"_posts/yolo-train.md","raw":"---\ntitle: yolo训练经验\ndate: 2018-09-17 19:25:51\ntags: yolo\ncategories: 深度学习\n---\nyolo太难训练了啊，动不动就nan，超参选择对模型是否收敛影响挺大的，本文分享我在训练yolo的一些经验\n\n<!-- more -->\n\n## YOLOv3为例\n\n先说yolov3首先要有张8GB以上的显卡，否则很难收敛。tiny-yolov3建议4G以上显存。\n\n将batch设为64，subdivisions设为16，真实的batchsize为batch/subdivisions=4。显存主要是和真实的batchsize挂钩，设置大了要担心显存是否够用，但训练初期能够很好的收敛。\n\nlearning_rate设置过大训练会很快发散，在fine_tune模型时learning_rate为配置文件所设置的值，不是fine_tune模型时learning_rate为最大的学习率，训练过程真实的学习率会慢慢变大直到等于所设值。在训练一段时间后，loss值在很长的一段时间都在某个值附近徘徊，需要将learning_rate设置更小的值。总结learning_rate的值应该先增大再减小，可以通过steps和scales配置比率。\n\n训练观察是否收敛，loss很快变小再在某个值附近徘徊；obj先变小后变大最后趋近1；召回率.5R会变大直到1，接着.75R也会有很多1；class和IOU会慢慢接近1。\n\n训练测试\n```\n.\\darknet detector map .\\data\\voc.data .\\cfg\\yolov3.cfg .\\backup\\yolov3_271604.weights\n```\n结果包含每个类别的AP值，mAP值、精度、召回率、TP数量、FP数量、FN数量、平均IOU等。\n\n模型输入图像尺寸和mask、anchors参数要对应，根据训练数据实际框大小的分布来确定值。在训练时候不会在某个尺度的框一直出现count:0的结果，才能最大化利用其尺度信息。\n\n如果觉得三个scale不够用，可以将最后增加一个尺度，模仿原始模型文件写即可，注意合并要用第11层。mask、anchors参数也要添加更多的数据，9->12。\n\n\n声明：如有错误或者侵权请邮箱联系我","slug":"yolo-train","published":1,"updated":"2019-04-13T01:52:14.044Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3i2nlhb000eaxsi3okalijn","content":"<p>yolo太难训练了啊，动不动就nan，超参选择对模型是否收敛影响挺大的，本文分享我在训练yolo的一些经验</p>\n<a id=\"more\"></a>\n<h2 id=\"YOLOv3为例\"><a href=\"#YOLOv3为例\" class=\"headerlink\" title=\"YOLOv3为例\"></a>YOLOv3为例</h2><p>先说yolov3首先要有张8GB以上的显卡，否则很难收敛。tiny-yolov3建议4G以上显存。</p>\n<p>将batch设为64，subdivisions设为16，真实的batchsize为batch/subdivisions=4。显存主要是和真实的batchsize挂钩，设置大了要担心显存是否够用，但训练初期能够很好的收敛。</p>\n<p>learning_rate设置过大训练会很快发散，在fine_tune模型时learning_rate为配置文件所设置的值，不是fine_tune模型时learning_rate为最大的学习率，训练过程真实的学习率会慢慢变大直到等于所设值。在训练一段时间后，loss值在很长的一段时间都在某个值附近徘徊，需要将learning_rate设置更小的值。总结learning_rate的值应该先增大再减小，可以通过steps和scales配置比率。</p>\n<p>训练观察是否收敛，loss很快变小再在某个值附近徘徊；obj先变小后变大最后趋近1；召回率.5R会变大直到1，接着.75R也会有很多1；class和IOU会慢慢接近1。</p>\n<p>训练测试<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.\\darknet detector map .\\data\\voc.data .\\cfg\\yolov3.cfg .\\backup\\yolov3_271604.weights</span><br></pre></td></tr></table></figure></p>\n<p>结果包含每个类别的AP值，mAP值、精度、召回率、TP数量、FP数量、FN数量、平均IOU等。</p>\n<p>模型输入图像尺寸和mask、anchors参数要对应，根据训练数据实际框大小的分布来确定值。在训练时候不会在某个尺度的框一直出现count:0的结果，才能最大化利用其尺度信息。</p>\n<p>如果觉得三个scale不够用，可以将最后增加一个尺度，模仿原始模型文件写即可，注意合并要用第11层。mask、anchors参数也要添加更多的数据，9-&gt;12。</p>\n<p>声明：如有错误或者侵权请邮箱联系我</p>\n","site":{"data":{}},"excerpt":"<p>yolo太难训练了啊，动不动就nan，超参选择对模型是否收敛影响挺大的，本文分享我在训练yolo的一些经验</p>","more":"<h2 id=\"YOLOv3为例\"><a href=\"#YOLOv3为例\" class=\"headerlink\" title=\"YOLOv3为例\"></a>YOLOv3为例</h2><p>先说yolov3首先要有张8GB以上的显卡，否则很难收敛。tiny-yolov3建议4G以上显存。</p>\n<p>将batch设为64，subdivisions设为16，真实的batchsize为batch/subdivisions=4。显存主要是和真实的batchsize挂钩，设置大了要担心显存是否够用，但训练初期能够很好的收敛。</p>\n<p>learning_rate设置过大训练会很快发散，在fine_tune模型时learning_rate为配置文件所设置的值，不是fine_tune模型时learning_rate为最大的学习率，训练过程真实的学习率会慢慢变大直到等于所设值。在训练一段时间后，loss值在很长的一段时间都在某个值附近徘徊，需要将learning_rate设置更小的值。总结learning_rate的值应该先增大再减小，可以通过steps和scales配置比率。</p>\n<p>训练观察是否收敛，loss很快变小再在某个值附近徘徊；obj先变小后变大最后趋近1；召回率.5R会变大直到1，接着.75R也会有很多1；class和IOU会慢慢接近1。</p>\n<p>训练测试<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.\\darknet detector map .\\data\\voc.data .\\cfg\\yolov3.cfg .\\backup\\yolov3_271604.weights</span><br></pre></td></tr></table></figure></p>\n<p>结果包含每个类别的AP值，mAP值、精度、召回率、TP数量、FP数量、FN数量、平均IOU等。</p>\n<p>模型输入图像尺寸和mask、anchors参数要对应，根据训练数据实际框大小的分布来确定值。在训练时候不会在某个尺度的框一直出现count:0的结果，才能最大化利用其尺度信息。</p>\n<p>如果觉得三个scale不够用，可以将最后增加一个尺度，模仿原始模型文件写即可，注意合并要用第11层。mask、anchors参数也要添加更多的数据，9-&gt;12。</p>\n<p>声明：如有错误或者侵权请邮箱联系我</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"ck3i2nlh20008axsirj5sjywm","category_id":"ck3i2nlgx0004axsiu4x9k9bw","_id":"ck3i2nlhl000faxsi5uvfovu1"},{"post_id":"ck3i2nlgo0000axsitfcc39n6","category_id":"ck3i2nlgx0004axsiu4x9k9bw","_id":"ck3i2nlhm000iaxsij1vx2z9i"},{"post_id":"ck3i2nlh30009axsi61ckl19v","category_id":"ck3i2nlgx0004axsiu4x9k9bw","_id":"ck3i2nlhm000kaxsipv7b5ent"},{"post_id":"ck3i2nlh6000daxsifb4a6vnd","category_id":"ck3i2nlgx0004axsiu4x9k9bw","_id":"ck3i2nlhn000maxsigyco9hi6"},{"post_id":"ck3i2nlgu0002axsiy8ydk8t7","category_id":"ck3i2nlgx0004axsiu4x9k9bw","_id":"ck3i2nlho000oaxsigcqx4pg3"},{"post_id":"ck3i2nlhb000eaxsi3okalijn","category_id":"ck3i2nlgx0004axsiu4x9k9bw","_id":"ck3i2nlho000qaxsifjdysxcb"},{"post_id":"ck3i2nlgz0006axsittiz6awh","category_id":"ck3i2nlhl000gaxsib6vcl3my","_id":"ck3i2nlho000raxsibwr8xyrb"}],"PostTag":[{"post_id":"ck3i2nlgo0000axsitfcc39n6","tag_id":"ck3i2nlgz0005axsi10d865bw","_id":"ck3i2nlh6000caxsiccdbjsp1"},{"post_id":"ck3i2nlgu0002axsiy8ydk8t7","tag_id":"ck3i2nlh4000baxsivngyfrcl","_id":"ck3i2nlhm000jaxsii9515pqx"},{"post_id":"ck3i2nlgz0006axsittiz6awh","tag_id":"ck3i2nlhl000haxsi41sroelj","_id":"ck3i2nlhn000naxsibfyjikuu"},{"post_id":"ck3i2nlh20008axsirj5sjywm","tag_id":"ck3i2nlhn000laxsi68kpwb8v","_id":"ck3i2nlhp000taxsie920lh95"},{"post_id":"ck3i2nlh20008axsirj5sjywm","tag_id":"ck3i2nlho000paxsi99mkewqg","_id":"ck3i2nlhp000uaxsi0u801ba3"},{"post_id":"ck3i2nlh30009axsi61ckl19v","tag_id":"ck3i2nlhp000saxsi5xocg3gv","_id":"ck3i2nlhs000yaxsi1wdw9v7e"},{"post_id":"ck3i2nlh30009axsi61ckl19v","tag_id":"ck3i2nlho000paxsi99mkewqg","_id":"ck3i2nlhs000zaxsiuq4eapgy"},{"post_id":"ck3i2nlh30009axsi61ckl19v","tag_id":"ck3i2nlhr000waxsid5t9rrb5","_id":"ck3i2nlhs0011axsidvmtxbib"},{"post_id":"ck3i2nlh6000daxsifb4a6vnd","tag_id":"ck3i2nlhr000xaxsii5av250j","_id":"ck3i2nlht0012axsiitbz3pu4"},{"post_id":"ck3i2nlhb000eaxsi3okalijn","tag_id":"ck3i2nlhs0010axsi7n7u5kes","_id":"ck3i2nlht0013axsin6jxuxkv"}],"Tag":[{"name":"caffe配置","_id":"ck3i2nlgz0005axsi10d865bw"},{"name":"标签转换","_id":"ck3i2nlh4000baxsivngyfrcl"},{"name":"原网站","_id":"ck3i2nlhl000haxsi41sroelj"},{"name":"镜像","_id":"ck3i2nlhn000laxsi68kpwb8v"},{"name":"docker","_id":"ck3i2nlho000paxsi99mkewqg"},{"name":"容器","_id":"ck3i2nlhp000saxsi5xocg3gv"},{"name":"singularity","_id":"ck3i2nlhr000waxsid5t9rrb5"},{"name":"标注","_id":"ck3i2nlhr000xaxsii5av250j"},{"name":"yolo","_id":"ck3i2nlhs0010axsi7n7u5kes"}]}}